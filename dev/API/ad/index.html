<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Automatic Differentiation Construction Choice Recommendations · Optimization.jl</title><meta name="title" content="Automatic Differentiation Construction Choice Recommendations · Optimization.jl"/><meta property="og:title" content="Automatic Differentiation Construction Choice Recommendations · Optimization.jl"/><meta property="twitter:title" content="Automatic Differentiation Construction Choice Recommendations · Optimization.jl"/><meta name="description" content="Documentation for Optimization.jl."/><meta property="og:description" content="Documentation for Optimization.jl."/><meta property="twitter:description" content="Documentation for Optimization.jl."/><meta property="og:url" content="https://docs.sciml.ai/Optimization/stable/API/ad/"/><meta property="twitter:url" content="https://docs.sciml.ai/Optimization/stable/API/ad/"/><link rel="canonical" href="https://docs.sciml.ai/Optimization/stable/API/ad/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Optimization.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Optimization.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Optimization.jl: A Unified Optimization Package</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started with Optimization.jl</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/certification/">Using SymbolicAnalysis.jl for convexity certificates</a></li><li><a class="tocitem" href="../../tutorials/constraints/">Using Equality and Inequality Constraints</a></li><li><a class="tocitem" href="../../tutorials/ensemble/">Multistart optimization with EnsembleProblem</a></li><li><a class="tocitem" href="../../tutorials/linearandinteger/">Linear and Integer Optimization Problems</a></li><li><a class="tocitem" href="../../tutorials/minibatch/">Data Iterators and Minibatching</a></li><li><a class="tocitem" href="../../tutorials/remakecomposition/">Creating polyalgorithms by chaining solvers using <code>remake</code></a></li><li><a class="tocitem" href="../../tutorials/reusage_interface/">Optimization Problem Reusage and Caching Interface</a></li><li><a class="tocitem" href="../../tutorials/symbolic/">Symbolic Problem Building with ModelingToolkit</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/rosenbrock/">Solving the Rosenbrock Problem in &gt;10 Ways</a></li></ul></li><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../optimization_problem/">Defining OptimizationProblems</a></li><li><a class="tocitem" href="../optimization_function/">OptimizationFunction</a></li><li class="is-active"><a class="tocitem" href>Automatic Differentiation Construction Choice Recommendations</a><ul class="internal"><li><a class="tocitem" href="#Automatic-Differentiation-Choice-API"><span>Automatic Differentiation Choice API</span></a></li></ul></li><li><a class="tocitem" href="../solve/">Common Solver Options (Solve Keyword Arguments)</a></li><li><a class="tocitem" href="../optimization_solution/">Optimization Solutions</a></li><li><a class="tocitem" href="../optimization_state/">OptimizationState</a></li><li><a class="tocitem" href="../optimization_stats/">OptimizationStats</a></li><li><a class="tocitem" href="../modelingtoolkit/">ModelingToolkit Integration</a></li><li><a class="tocitem" href="../FAQ/">Frequently Asked Questions</a></li></ul></li><li><span class="tocitem">Optimizer Packages</span><ul><li><a class="tocitem" href="../../optimization_packages/blackboxoptim/">BlackBoxOptim.jl</a></li><li><a class="tocitem" href="../../optimization_packages/cmaevolutionstrategy/">CMAEvolutionStrategy.jl</a></li><li><a class="tocitem" href="../../optimization_packages/evolutionary/">Evolutionary.jl</a></li><li><a class="tocitem" href="../../optimization_packages/gcmaes/">GCMAES.jl</a></li><li><a class="tocitem" href="../../optimization_packages/ipopt/">Ipopt.jl</a></li><li><a class="tocitem" href="../../optimization_packages/manopt/">Manopt.jl</a></li><li><a class="tocitem" href="../../optimization_packages/mathoptinterface/">MathOptInterface.jl</a></li><li><a class="tocitem" href="../../optimization_packages/metaheuristics/">Metaheuristics.jl</a></li><li><a class="tocitem" href="../../optimization_packages/multistartoptimization/">MultistartOptimization.jl</a></li><li><a class="tocitem" href="../../optimization_packages/nlopt/">NLopt.jl</a></li><li><a class="tocitem" href="../../optimization_packages/nlpmodels/">NLPModels.jl</a></li><li><a class="tocitem" href="../../optimization_packages/nomad/">NOMAD.jl</a></li><li><a class="tocitem" href="../../optimization_packages/optim/">Optim.jl</a></li><li><a class="tocitem" href="../../optimization_packages/optimisers/">Optimisers.jl</a></li><li><a class="tocitem" href="../../optimization_packages/optimization/">Optimization.jl</a></li><li><a class="tocitem" href="../../optimization_packages/polyopt/">Polyalgorithms.jl</a></li><li><a class="tocitem" href="../../optimization_packages/prima/">PRIMA.jl</a></li><li><a class="tocitem" href="../../optimization_packages/pycma/">PyCMA.jl</a></li><li><a class="tocitem" href="../../optimization_packages/quaddirect/">QuadDIRECT.jl</a></li><li><a class="tocitem" href="../../optimization_packages/speedmapping/">SpeedMapping.jl</a></li><li><a class="tocitem" href="../../optimization_packages/scipy/">SciPy.jl</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Basics</a></li><li class="is-active"><a href>Automatic Differentiation Construction Choice Recommendations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Automatic Differentiation Construction Choice Recommendations</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/Optimization.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/Optimization.jl/blob/master/docs/src/API/ad.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="ad"><a class="docs-heading-anchor" href="#ad">Automatic Differentiation Construction Choice Recommendations</a><a id="ad-1"></a><a class="docs-heading-anchor-permalink" href="#ad" title="Permalink"></a></h1><p>The choices for the auto-AD fill-ins with quick descriptions are:</p><ul><li><code>AutoForwardDiff()</code>: The fastest choice for small optimizations</li><li><code>AutoReverseDiff(compile=false)</code>: A fast choice for large scalar optimizations</li><li><code>AutoTracker()</code>: Like ReverseDiff but GPU-compatible</li><li><code>AutoZygote()</code>: The fastest choice for non-mutating array-based (BLAS) functions</li><li><code>AutoFiniteDiff()</code>: Finite differencing, not optimal but always applicable</li><li><code>AutoModelingToolkit()</code>: The fastest choice for large scalar optimizations</li><li><code>AutoEnzyme()</code>: Highly performant AD choice for type stable and optimized code</li><li><code>AutoMooncake()</code>: Like Zygote and ReverseDiff, but supports GPU and mutating code</li></ul><h2 id="Automatic-Differentiation-Choice-API"><a class="docs-heading-anchor" href="#Automatic-Differentiation-Choice-API">Automatic Differentiation Choice API</a><a id="Automatic-Differentiation-Choice-API-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation-Choice-API" title="Permalink"></a></h2><p>The following sections describe the Auto-AD choices in detail.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoForwardDiff" href="#ADTypes.AutoForwardDiff"><code>ADTypes.AutoForwardDiff</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoForwardDiff{chunksize} &lt;: AbstractADType</code></pre><p>An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:</p><pre><code class="language-julia hljs">OptimizationFunction(f, AutoForwardDiff(); kwargs...)</code></pre><p>This uses the <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a> package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most Julia functions which have loose type restrictions. However, because it&#39;s forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization</li><li>Compatible with Hv-based optimization</li><li>Compatible with constraints</li></ul><p>Note that only the unspecified derivative functions are defined. For example, if a <code>hess</code> function is supplied to the <code>OptimizationFunction</code>, then the Hessian is not defined via ForwardDiff.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Optimization.jl/blob/f9e94f7601ab196755eda3c2e1eeb56377741b82/lib/OptimizationBase/src/adtypes.jl#L62-L88">source</a></section><section><div><pre><code class="language-julia hljs">AutoForwardDiff{chunksize,T}</code></pre><p>Struct used to select the <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a> backend for automatic differentiation.</p><p>Defined by <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a>.</p><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AutoForwardDiff(; chunksize=nothing, tag=nothing)</code></pre><p><strong>Type parameters</strong></p><ul><li><code>chunksize</code>: the preferred <a href="https://juliadiff.org/ForwardDiff.jl/stable/user/advanced/#Configuring-Chunk-Size">chunk size</a> to evaluate several derivatives at once</li></ul><p><strong>Fields</strong></p><ul><li><code>tag::T</code>: a <a href="https://juliadiff.org/ForwardDiff.jl/release-0.10/user/advanced.html#Custom-tags-and-tag-checking-1">custom tag</a> to handle nested differentiation calls (usually not necessary)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ADTypes.jl/blob/v1.18.0/src/dense.jl#L176-L194">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoFiniteDiff" href="#ADTypes.AutoFiniteDiff"><code>ADTypes.AutoFiniteDiff</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoFiniteDiff{T1,T2,T3} &lt;: AbstractADType</code></pre><p>An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:</p><pre><code class="language-julia hljs">OptimizationFunction(f, AutoFiniteDiff(); kwargs...)</code></pre><p>This uses <a href="https://github.com/JuliaDiff/FiniteDiff.jl">FiniteDiff.jl</a>. While not necessarily the most efficient, this is the only choice that doesn&#39;t require the <code>f</code> function to be automatically differentiable, which means it applies to any choice. However, because it&#39;s using finite differencing, one needs to be careful as this procedure introduces numerical error into the derivative estimates.</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization</li><li>Compatible with Hv-based optimization</li><li>Compatible with constraint functions</li></ul><p>Note that only the unspecified derivative functions are defined. For example, if a <code>hess</code> function is supplied to the <code>OptimizationFunction</code>, then the Hessian is not defined via FiniteDiff.</p><p><strong>Constructor</strong></p><pre><code class="language-julia hljs">AutoFiniteDiff(; fdtype = Val(:forward)fdjtype = fdtype, fdhtype = Val(:hcentral))</code></pre><ul><li><code>fdtype</code>: the method used for defining the gradient</li><li><code>fdjtype</code>: the method used for defining the Jacobian of constraints.</li><li><code>fdhtype</code>: the method used for defining the Hessian</li></ul><p>For more information on the derivative type specifiers, see the <a href="https://github.com/JuliaDiff/FiniteDiff.jl">FiniteDiff.jl documentation</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Optimization.jl/blob/f9e94f7601ab196755eda3c2e1eeb56377741b82/lib/OptimizationBase/src/adtypes.jl#L21-L59">source</a></section><section><div><pre><code class="language-julia hljs">AutoFiniteDiff{T1,T2,T3}</code></pre><p>Struct used to select the <a href="https://github.com/JuliaDiff/FiniteDiff.jl">FiniteDiff.jl</a> backend for automatic differentiation.</p><p>Defined by <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a>.</p><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AutoFiniteDiff(;
    fdtype=Val(:forward), fdjtype=fdtype, fdhtype=Val(:hcentral),
    relstep=nothing, absstep=nothing, dir=true
)</code></pre><p><strong>Fields</strong></p><ul><li><code>fdtype::T1</code>: finite difference type</li><li><code>fdjtype::T2</code>: finite difference type for the Jacobian</li><li><code>fdhtype::T3</code>: finite difference type for the Hessian</li><li><code>relstep</code>: relative finite difference step size</li><li><code>absstep</code>: absolute finite difference step size</li><li><code>dir</code>: direction of the finite difference step</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ADTypes.jl/blob/v1.18.0/src/dense.jl#L100-L122">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoReverseDiff" href="#ADTypes.AutoReverseDiff"><code>ADTypes.AutoReverseDiff</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoReverseDiff &lt;: AbstractADType</code></pre><p>An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:</p><pre><code class="language-julia hljs">OptimizationFunction(f, AutoReverseDiff(); kwargs...)</code></pre><p>This uses the <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff.jl</a> package. <code>AutoReverseDiff</code> has a default argument, <code>compile</code>, which denotes whether the reverse pass should be compiled. <strong><code>compile</code> should only be set to <code>true</code> if <code>f</code> contains no branches (if statements, while loops) otherwise it can produce incorrect derivatives!</strong></p><p><code>AutoReverseDiff</code> is generally applicable to many pure Julia codes, and with <code>compile=true</code> it is one of the fastest options on code with heavy scalar interactions. Hessian calculations are fast by mixing ForwardDiff with ReverseDiff for forward-over-reverse. However, its performance can falter when <code>compile=false</code>.</p><ul><li>Not compatible with GPUs</li><li>Compatible with Hessian-based optimization by mixing with ForwardDiff</li><li>Compatible with Hv-based optimization by mixing with ForwardDiff</li><li>Not compatible with constraint functions</li></ul><p>Note that only the unspecified derivative functions are defined. For example, if a <code>hess</code> function is supplied to the <code>OptimizationFunction</code>, then the Hessian is not defined via ReverseDiff.</p><p><strong>Constructor</strong></p><pre><code class="language-julia hljs">AutoReverseDiff(; compile = false)</code></pre><p><strong>Note: currently, compilation is not defined/used!</strong></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Optimization.jl/blob/f9e94f7601ab196755eda3c2e1eeb56377741b82/lib/OptimizationBase/src/adtypes.jl#L130-L168">source</a></section><section><div><pre><code class="language-julia hljs">AutoReverseDiff{compile}</code></pre><p>Struct used to select the <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff.jl</a> backend for automatic differentiation.</p><p>Defined by <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a>.</p><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AutoReverseDiff(; compile::Union{Val, Bool} = Val(false))</code></pre><p><strong>Fields</strong></p><ul><li><p><code>compile::Union{Val, Bool}</code>: whether to allow pre-recording and reusing a tape (which speeds up the differentiation process).</p><ul><li>If <code>compile=false</code> or <code>compile=Val(false)</code>, a new tape must be recorded at every call to the differentiation operator.</li><li>If <code>compile=true</code> or <code>compile=Val(true)</code>, a tape can be pre-recorded on an example input and then reused at every differentiation call.</li></ul><p>The boolean version of this keyword argument is taken as the type parameter.</p></li></ul><div class="admonition is-warning" id="Warning-bde3b6cc388698e2"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-bde3b6cc388698e2" title="Permalink"></a></header><div class="admonition-body"><p>Pre-recording a tape only captures the path taken by the differentiated function <em>when executed on the example input</em>. If said function has value-dependent branching behavior, reusing pre-recorded tapes can lead to incorrect results. In such situations, you should keep the default setting <code>compile=Val(false)</code>. For more details, please refer to ReverseDiff&#39;s <a href="https://juliadiff.org/ReverseDiff.jl/dev/api/#The-AbstractTape-API"><code>AbstractTape</code> API documentation</a>.</p></div></div><div class="admonition is-info" id="Info-b305d0e1181bb923"><header class="admonition-header">Info<a class="admonition-anchor" href="#Info-b305d0e1181bb923" title="Permalink"></a></header><div class="admonition-body"><p>Despite what its name may suggest, the <code>compile</code> setting does not prescribe whether or not the tape is compiled with <a href="https://juliadiff.org/ReverseDiff.jl/dev/api/#ReverseDiff.compile"><code>ReverseDiff.compile</code></a> after being recorded. This is left as a private implementation detail.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ADTypes.jl/blob/v1.18.0/src/dense.jl#L385-L416">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoZygote" href="#ADTypes.AutoZygote"><code>ADTypes.AutoZygote</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoZygote &lt;: AbstractADType</code></pre><p>An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:</p><pre><code class="language-julia hljs">OptimizationFunction(f, AutoZygote(); kwargs...)</code></pre><p>This uses the <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a> package. This is the staple reverse-mode AD that handles a large portion of Julia with good efficiency. Hessian construction is fast via forward-over-reverse mixing ForwardDiff.jl with Zygote.jl</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization via ForwardDiff</li><li>Compatible with Hv-based optimization via ForwardDiff</li><li>Not compatible with constraint functions</li></ul><p>Note that only the unspecified derivative functions are defined. For example, if a <code>hess</code> function is supplied to the <code>OptimizationFunction</code>, then the Hessian is not defined via Zygote.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Optimization.jl/blob/f9e94f7601ab196755eda3c2e1eeb56377741b82/lib/OptimizationBase/src/adtypes.jl#L196-L219">source</a></section><section><div><pre><code class="language-julia hljs">AutoZygote</code></pre><p>Struct used to select the <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a> backend for automatic differentiation.</p><p>Defined by <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a>.</p><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AutoZygote()</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ADTypes.jl/blob/v1.18.0/src/dense.jl#L504-L514">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoTracker" href="#ADTypes.AutoTracker"><code>ADTypes.AutoTracker</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoTracker &lt;: AbstractADType</code></pre><p>An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:</p><pre><code class="language-julia hljs">OptimizationFunction(f, AutoTracker(); kwargs...)</code></pre><p>This uses the <a href="https://github.com/FluxML/Tracker.jl">Tracker.jl</a> package. Generally slower than ReverseDiff, it is generally applicable to many pure Julia codes.</p><ul><li>Compatible with GPUs</li><li>Not compatible with Hessian-based optimization</li><li>Not compatible with Hv-based optimization</li><li>Not compatible with constraint functions</li></ul><p>Note that only the unspecified derivative functions are defined. For example, if a <code>hess</code> function is supplied to the <code>OptimizationFunction</code>, then the Hessian is not defined via Tracker.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Optimization.jl/blob/f9e94f7601ab196755eda3c2e1eeb56377741b82/lib/OptimizationBase/src/adtypes.jl#L171-L193">source</a></section><section><div><pre><code class="language-julia hljs">AutoTracker</code></pre><p>Struct used to select the <a href="https://github.com/FluxML/Tracker.jl">Tracker.jl</a> backend for automatic differentiation.</p><p>Defined by <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a>.</p><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AutoTracker()</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ADTypes.jl/blob/v1.18.0/src/dense.jl#L489-L499">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoModelingToolkit" href="#ADTypes.AutoModelingToolkit"><code>ADTypes.AutoModelingToolkit</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoModelingToolkit &lt;: AbstractADType</code></pre><p>An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:</p><pre><code class="language-julia hljs">OptimizationFunction(f, AutoModelingToolkit(); kwargs...)</code></pre><p>This uses the <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a> package&#39;s <code>modelingtookitize</code> functionality to generate the derivatives and other fields of an <code>OptimizationFunction</code>. This backend creates the symbolic expressions for the objective and its derivatives as well as the constraints and their derivatives. Through <code>structural_simplify</code>, it enforces simplifications that can reduce the number of operations needed to compute the derivatives of the constraints. This automatically generates the expression graphs that some solver interfaces through OptimizationMOI like <a href="https://github.com/jump-dev/AmplNLWriter.jl">AmplNLWriter.jl</a> require.</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization</li><li>Compatible with Hv-based optimization</li><li>Compatible with constraints</li></ul><p>Note that only the unspecified derivative functions are defined. For example, if a <code>hess</code> function is supplied to the <code>OptimizationFunction</code>, then the Hessian is not generated via ModelingToolkit.</p><p><strong>Constructor</strong></p><pre><code class="language-julia hljs">AutoModelingToolkit(false, false)</code></pre><ul><li><code>obj_sparse</code>: to indicate whether the objective hessian is sparse.</li><li><code>cons_sparse</code>: to indicate whether the constraints&#39; jacobian and hessian are sparse.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Optimization.jl/blob/f9e94f7601ab196755eda3c2e1eeb56377741b82/lib/OptimizationBase/src/adtypes.jl#L91-L127">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoEnzyme" href="#ADTypes.AutoEnzyme"><code>ADTypes.AutoEnzyme</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoEnzyme &lt;: AbstractADType</code></pre><p>An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:</p><pre><code class="language-julia hljs">OptimizationFunction(f, AutoEnzyme(); kwargs...)</code></pre><p>This uses the <a href="https://github.com/EnzymeAD/Enzyme.jl">Enzyme.jl</a> package. Enzyme performs automatic differentiation on the LLVM IR code generated from julia. It is highly-efficient and its ability perform AD on optimized code allows Enzyme to meet or exceed the performance of state-of-the-art AD tools.</p><ul><li>Compatible with GPUs</li><li>Compatible with Hessian-based optimization</li><li>Compatible with Hv-based optimization</li><li>Compatible with constraints</li></ul><p>Note that only the unspecified derivative functions are defined. For example, if a <code>hess</code> function is supplied to the <code>OptimizationFunction</code>, then the Hessian is not defined via Enzyme.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/Optimization.jl/blob/f9e94f7601ab196755eda3c2e1eeb56377741b82/lib/OptimizationBase/src/adtypes.jl#L1-L18">source</a></section><section><div><pre><code class="language-julia hljs">AutoEnzyme{M,A}</code></pre><p>Struct used to select the <a href="https://github.com/EnzymeAD/Enzyme.jl">Enzyme.jl</a> backend for automatic differentiation.</p><p>Defined by <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a>.</p><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AutoEnzyme(; mode::M=nothing, function_annotation::Type{A}=Nothing)</code></pre><p><strong>Type parameters</strong></p><ul><li><p><code>A</code> determines how the function <code>f</code> to differentiate is passed to Enzyme. It can be:</p><ul><li>a subtype of <code>EnzymeCore.Annotation</code> (like <code>EnzymeCore.Const</code> or <code>EnzymeCore.Duplicated</code>) to enforce a given annotation</li><li><code>Nothing</code> to simply pass <code>f</code> and let Enzyme choose the most appropriate annotation</li></ul></li></ul><p><strong>Fields</strong></p><ul><li><p><code>mode::M</code> determines the autodiff mode (forward or reverse). It can be:</p><ul><li>an object subtyping <code>EnzymeCore.Mode</code> (like <code>EnzymeCore.Forward</code> or <code>EnzymeCore.Reverse</code>) if a specific mode is required</li><li><code>nothing</code> to choose the best mode automatically</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ADTypes.jl/blob/v1.18.0/src/dense.jl#L41-L65">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ADTypes.AutoMooncake" href="#ADTypes.AutoMooncake"><code>ADTypes.AutoMooncake</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoMooncake</code></pre><p>Struct used to select the <a href="https://github.com/compintell/Mooncake.jl">Mooncake.jl</a> backend for automatic differentiation in reverse mode.</p><p>Defined by <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a>.</p><div class="admonition is-info" id="Info-af3ec97a7c18e093"><header class="admonition-header">Info<a class="admonition-anchor" href="#Info-af3ec97a7c18e093" title="Permalink"></a></header><div class="admonition-body"><p>When forward mode became available in Mooncake.jl v0.4.147, another struct called <a href="@ref"><code>AutoMooncakeForward</code></a> was introduced. It was kept separate to avoid a breaking release of ADTypes.jl. <a href="#ADTypes.AutoMooncake"><code>AutoMooncake</code></a> remains for reverse mode only.</p></div></div><p><strong>Constructors</strong></p><pre><code class="nohighlight hljs">AutoMooncake(; config=nothing)</code></pre><p><strong>Fields</strong></p><ul><li><code>config</code>: either <code>nothing</code> or an instance of <code>Mooncake.Config</code> – see the docstring of <code>Mooncake.Config</code> for more information. <code>AutoMooncake(; config=nothing)</code> is equivalent to <code>AutoMooncake(; config=Mooncake.Config())</code>, i.e. the default configuration.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ADTypes.jl/blob/v1.18.0/src/dense.jl#L276-L296">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../optimization_function/">« OptimizationFunction</a><a class="docs-footer-nextpage" href="../solve/">Common Solver Options (Solve Keyword Arguments) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Wednesday 1 October 2025 17:13">Wednesday 1 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
