var documenterSearchIndex = {"docs":
[{"location":"tutorials/minibatch/#Data-Iterators-and-Minibatching","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"It is possible to solve an optimization problem with batches using a MLUtils.DataLoader, which is passed to Optimization.solve with ncycles. All data for the batches need to be passed as a tuple of vectors.\n\nnote: Note\nThis example uses the OptimizationOptimisers.jl package. See the Optimisers.jl page for details on the installation and usage.\n\n\nusing Lux, OptimizationBase, OptimizationOptimisers, OrdinaryDiffEq, SciMLSensitivity, MLUtils,\n      Random, ComponentArrays, ADTypes, Zygote\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k * (temp - temp_m)\nend\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2) / 8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend\n\nmodel = Chain(Dense(1, 32, tanh), Dense(32, 1))\nps, st = Lux.setup(Random.default_rng(), model)\nps_ca = ComponentArray(ps)\nsmodel = StatefulLuxLayer{true}(model, nothing, st)\n\nfunction dudt_(u, p, t)\n    smodel(u, p) .* u\nend\n\nfunction callback(state, l) #callback function to observe training\n    display(l)\n    return false\nend\n\nu0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\n\nt = range(tspan[1], tspan[2], length = datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat = t))\n\nprob = ODEProblem{false}(dudt_, u0, tspan, ps_ca)\n\nfunction predict_adjoint(fullp, time_batch)\n    Array(solve(prob, Tsit5(), p = fullp, saveat = time_batch))\nend\n\nfunction loss_adjoint(fullp, data)\n    batch, time_batch = data\n    pred = predict_adjoint(fullp, time_batch)\n    sum(abs2, batch .- pred)\nend\n\nk = 10\n# Pass the data for the batches as separate vectors wrapped in a tuple\ntrain_loader = MLUtils.DataLoader((ode_data, t), batchsize = k)\n\nnumEpochs = 300\nl1 = loss_adjoint(ps_ca, train_loader.data)[1]\n\noptfun = OptimizationFunction(\n    loss_adjoint,\n    ADTypes.AutoZygote())\noptprob = OptimizationProblem(optfun, ps_ca, train_loader)\nusing IterTools: ncycle\nres1 = solve(\n    optprob, Optimisers.ADAM(0.05); callback = callback, epochs = 1000)","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#CMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"CMAEvolutionStrategy is a Julia package implementing the Covariance Matrix Adaptation Evolution Strategy algorithm.\n\nThe CMAEvolutionStrategy algorithm is called by CMAEvolutionStrategyOpt()","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#Installation:-OptimizationCMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"Installation: OptimizationCMAEvolutionStrategy.jl","text":"To use this package, install the OptimizationCMAEvolutionStrategy package:\n\nimport Pkg;\nPkg.add(\"OptimizationCMAEvolutionStrategy\");","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#Global-Optimizer","page":"CMAEvolutionStrategy.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#Without-Constraint-Equations","page":"CMAEvolutionStrategy.jl","title":"Without Constraint Equations","text":"The method in CMAEvolutionStrategy is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#Example","page":"CMAEvolutionStrategy.jl","title":"Example","text":"The Rosenbrock function can be optimized using the CMAEvolutionStrategyOpt() as follows:\n\nusing Optimization, OptimizationCMAEvolutionStrategy\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, CMAEvolutionStrategyOpt())","category":"section"},{"location":"API/optimization_solution/#solution","page":"Optimization Solutions","title":"Optimization Solutions","text":"","category":"section"},{"location":"API/optimization_solution/#SciMLBase.OptimizationSolution","page":"Optimization Solutions","title":"SciMLBase.OptimizationSolution","text":"struct OptimizationSolution{T, N, uType, C<:SciMLBase.AbstractOptimizationCache, A, OV, O, ST} <: SciMLBase.AbstractOptimizationSolution{T, N}\n\nRepresentation of the solution to a non-linear optimization defined by an OptimizationProblem.\n\nFields\n\nu: the representation of the optimization's solution.\nalg: the algorithm type used by the solver.\nobjective: Objective value of the solution\nretcode: the return code from the solver. Used to determine whether the solver solved successfully or whether it exited due to an error. For more details, see the return code documentation.\noriginal: if the solver is wrapped from a external solver, e.g. Optim.jl, then this is the original return from said solver library.\nstats: statistics of the solver, such as the number of function evaluations required.\n\nInternal Fields\n\ncache::AbstractOptimizationCache: the optimization cache that was solved.\n\nInterface\n\nOptimizationSolution is a SciMLBase.AbstractNoTimeSolution. For more information on the SciML solution interfaces, check out the SciML Solution Interface documentation page\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ad","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Construction Choice Recommendations","text":"The choices for the auto-AD fill-ins with quick descriptions are:\n\nAutoForwardDiff(): The fastest choice for small optimizations\nAutoReverseDiff(compile=false): A fast choice for large scalar optimizations\nAutoTracker(): Like ReverseDiff but GPU-compatible\nAutoZygote(): The fastest choice for non-mutating array-based (BLAS) functions\nAutoFiniteDiff(): Finite differencing, not optimal but always applicable\nAutoSymbolics(): The fastest choice for large scalar optimizations\nAutoEnzyme(): Highly performant AD choice for type stable and optimized code\nAutoMooncake(): Like Zygote and ReverseDiff, but supports GPU and mutating code","category":"section"},{"location":"API/ad/#Automatic-Differentiation-Choice-API","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Choice API","text":"The following sections describe the Auto-AD choices in detail. These types are defined in the ADTypes.jl package.","category":"section"},{"location":"API/ad/#ADTypes.AutoForwardDiff","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoForwardDiff","text":"AutoForwardDiff{chunksize} <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoForwardDiff(); kwargs...)\n\nThis uses the ForwardDiff.jl package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most Julia functions which have loose type restrictions. However, because it's forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraints\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via ForwardDiff.\n\n\n\n\n\nAutoForwardDiff{chunksize,T}\n\nStruct used to select the ForwardDiff.jl backend for automatic differentiation.\n\nDefined by ADTypes.jl.\n\nConstructors\n\nAutoForwardDiff(; chunksize=nothing, tag=nothing)\n\nType parameters\n\nchunksize: the preferred chunk size to evaluate several derivatives at once\n\nFields\n\ntag::T: a custom tag to handle nested differentiation calls (usually not necessary)\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoFiniteDiff","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoFiniteDiff","text":"AutoFiniteDiff{T1,T2,T3} <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoFiniteDiff(); kwargs...)\n\nThis uses FiniteDiff.jl. While not necessarily the most efficient, this is the only choice that doesn't require the f function to be automatically differentiable, which means it applies to any choice. However, because it's using finite differencing, one needs to be careful as this procedure introduces numerical error into the derivative estimates.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via FiniteDiff.\n\nConstructor\n\nAutoFiniteDiff(; fdtype = Val(:forward)fdjtype = fdtype, fdhtype = Val(:hcentral))\n\nfdtype: the method used for defining the gradient\nfdjtype: the method used for defining the Jacobian of constraints.\nfdhtype: the method used for defining the Hessian\n\nFor more information on the derivative type specifiers, see the FiniteDiff.jl documentation.\n\n\n\n\n\nAutoFiniteDiff{T1,T2,T3}\n\nStruct used to select the FiniteDiff.jl backend for automatic differentiation.\n\nDefined by ADTypes.jl.\n\nConstructors\n\nAutoFiniteDiff(;\n    fdtype=Val(:forward), fdjtype=fdtype, fdhtype=Val(:hcentral),\n    relstep=nothing, absstep=nothing, dir=true\n)\n\nFields\n\nfdtype::T1: finite difference type\nfdjtype::T2: finite difference type for the Jacobian\nfdhtype::T3: finite difference type for the Hessian\nrelstep: relative finite difference step size\nabsstep: absolute finite difference step size\ndir: direction of the finite difference step\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoReverseDiff","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoReverseDiff","text":"AutoReverseDiff <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoReverseDiff(); kwargs...)\n\nThis uses the ReverseDiff.jl package. AutoReverseDiff has a default argument, compile, which denotes whether the reverse pass should be compiled. compile should only be set to true if f contains no branches (if statements, while loops) otherwise it can produce incorrect derivatives!\n\nAutoReverseDiff is generally applicable to many pure Julia codes, and with compile=true it is one of the fastest options on code with heavy scalar interactions. Hessian calculations are fast by mixing ForwardDiff with ReverseDiff for forward-over-reverse. However, its performance can falter when compile=false.\n\nNot compatible with GPUs\nCompatible with Hessian-based optimization by mixing with ForwardDiff\nCompatible with Hv-based optimization by mixing with ForwardDiff\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via ReverseDiff.\n\nConstructor\n\nAutoReverseDiff(; compile = false)\n\nNote: currently, compilation is not defined/used!\n\n\n\n\n\nAutoReverseDiff{compile}\n\nStruct used to select the ReverseDiff.jl backend for automatic differentiation.\n\nDefined by ADTypes.jl.\n\nConstructors\n\nAutoReverseDiff(; compile::Union{Val, Bool} = Val(false))\n\nFields\n\ncompile::Union{Val, Bool}: whether to allow pre-recording and reusing a tape (which speeds up the differentiation process).\nIf compile=false or compile=Val(false), a new tape must be recorded at every call to the differentiation operator.\nIf compile=true or compile=Val(true), a tape can be pre-recorded on an example input and then reused at every differentiation call.\nThe boolean version of this keyword argument is taken as the type parameter.\n\nwarning: Warning\nPre-recording a tape only captures the path taken by the differentiated function when executed on the example input. If said function has value-dependent branching behavior, reusing pre-recorded tapes can lead to incorrect results. In such situations, you should keep the default setting compile=Val(false). For more details, please refer to ReverseDiff's AbstractTape API documentation.\n\ninfo: Info\nDespite what its name may suggest, the compile setting does not prescribe whether or not the tape is compiled with ReverseDiff.compile after being recorded. This is left as a private implementation detail.\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoZygote","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoZygote","text":"AutoZygote <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoZygote(); kwargs...)\n\nThis uses the Zygote.jl package. This is the staple reverse-mode AD that handles a large portion of Julia with good efficiency. Hessian construction is fast via forward-over-reverse mixing ForwardDiff.jl with Zygote.jl\n\nCompatible with GPUs\nCompatible with Hessian-based optimization via ForwardDiff\nCompatible with Hv-based optimization via ForwardDiff\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Zygote.\n\n\n\n\n\nAutoZygote\n\nStruct used to select the Zygote.jl backend for automatic differentiation.\n\nDefined by ADTypes.jl.\n\nConstructors\n\nAutoZygote()\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoTracker","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoTracker","text":"AutoTracker <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoTracker(); kwargs...)\n\nThis uses the Tracker.jl package. Generally slower than ReverseDiff, it is generally applicable to many pure Julia codes.\n\nCompatible with GPUs\nNot compatible with Hessian-based optimization\nNot compatible with Hv-based optimization\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Tracker.\n\n\n\n\n\nAutoTracker\n\nStruct used to select the Tracker.jl backend for automatic differentiation.\n\nDefined by ADTypes.jl.\n\nConstructors\n\nAutoTracker()\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoSymbolics","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoSymbolics","text":"AutoSymbolics\n\nStruct used to select the Symbolics.jl backend for automatic differentiation.\n\nDefined by ADTypes.jl.\n\nConstructors\n\nAutoSymbolics()\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoEnzyme","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoEnzyme","text":"AutoEnzyme <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoEnzyme(); kwargs...)\n\nThis uses the Enzyme.jl package. Enzyme performs automatic differentiation on the LLVM IR code generated from julia. It is highly-efficient and its ability perform AD on optimized code allows Enzyme to meet or exceed the performance of state-of-the-art AD tools.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraints\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Enzyme.\n\n\n\n\n\nAutoEnzyme{M,A}\n\nStruct used to select the Enzyme.jl backend for automatic differentiation.\n\nDefined by ADTypes.jl.\n\nConstructors\n\nAutoEnzyme(; mode::M=nothing, function_annotation::Type{A}=Nothing)\n\nType parameters\n\nA determines how the function f to differentiate is passed to Enzyme. It can be:\na subtype of EnzymeCore.Annotation (like EnzymeCore.Const or EnzymeCore.Duplicated) to enforce a given annotation\nNothing to simply pass f and let Enzyme choose the most appropriate annotation\n\nFields\n\nmode::M determines the autodiff mode (forward or reverse). It can be:\nan object subtyping EnzymeCore.Mode (like EnzymeCore.Forward or EnzymeCore.Reverse) if a specific mode is required\nnothing to choose the best mode automatically\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoMooncake","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoMooncake","text":"AutoMooncake\n\nStruct used to select the Mooncake.jl backend for automatic differentiation in reverse mode.\n\nDefined by ADTypes.jl.\n\ninfo: Info\nWhen forward mode became available in Mooncake.jl v0.4.147, another struct called AutoMooncakeForward was introduced. It was kept separate to avoid a breaking release of ADTypes.jl. AutoMooncake remains for reverse mode only.\n\nConstructors\n\nAutoMooncake(; config=nothing)\n\nFields\n\nconfig: either nothing or an instance of Mooncake.Config – see the docstring of Mooncake.Config for more information. AutoMooncake(; config=nothing) is equivalent to AutoMooncake(; config=Mooncake.Config()), i.e. the default configuration.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/ode/#OptimizationODE.jl","page":"OptimizationODE.jl","title":"OptimizationODE.jl","text":"OptimizationODE.jl provides ODE-based optimization methods as a solver plugin for SciML's Optimization.jl. It wraps various ODE solvers to perform gradient-based optimization using continuous-time dynamics.","category":"section"},{"location":"optimization_packages/ode/#Installation","page":"OptimizationODE.jl","title":"Installation","text":"using Pkg\nPkg.add(\"OptimizationODE\")","category":"section"},{"location":"optimization_packages/ode/#Usage","page":"OptimizationODE.jl","title":"Usage","text":"using OptimizationODE, Optimization, ADTypes, SciMLBase\n\nfunction f(x, p)\n    return sum(abs2, x)\nend\n\nfunction g!(g, x, p)\n    @. g = 2 * x\nend\n\nx0 = [2.0, -3.0]\np = []\n\nf_manual = OptimizationFunction(f, SciMLBase.NoAD(); grad = g!)\nprob_manual = OptimizationProblem(f_manual, x0)\n\nopt = ODEGradientDescent(dt=0.01)\nsol = solve(prob_manual, opt; maxiters=50_000)\n\n@show sol.u\n@show sol.objective","category":"section"},{"location":"optimization_packages/ode/#Local-Gradient-based-Optimizers","page":"OptimizationODE.jl","title":"Local Gradient-based Optimizers","text":"All provided optimizers are gradient-based local optimizers that solve optimization problems by integrating gradient-based ODEs to convergence:\n\nODEGradientDescent(dt=...) — performs basic gradient descent using the explicit Euler method. This is a simple and efficient method suitable for small-scale or well-conditioned problems.\nRKChebyshevDescent() — uses the ROCK2 solver, a stabilized explicit Runge-Kutta method suitable for stiff problems. It allows larger step sizes while maintaining stability.\nRKAccelerated() — leverages the Tsit5 method, a 5th-order Runge-Kutta solver that achieves faster convergence for smooth problems by improving integration accuracy.\nHighOrderDescent() — applies Vern7, a high-order (7th-order) explicit Runge-Kutta method for even more accurate integration. This can be beneficial for problems requiring high precision.\n\nYou can also define a custom optimizer using the generic ODEOptimizer(solver; dt=nothing) constructor by supplying any ODE solver supported by OrdinaryDiffEq.jl.","category":"section"},{"location":"optimization_packages/ode/#DAE-based-Optimizers","page":"OptimizationODE.jl","title":"DAE-based Optimizers","text":"warn: Warn\nDAE-based optimizers are still experimental and a research project. Use with caution.\n\nIn addition to ODE-based optimizers, OptimizationODE.jl provides optimizers for differential-algebraic equation (DAE) constrained problems:\n\nDAEMassMatrix() — uses the Rodas5P solver (from OrdinaryDiffEq.jl) for DAE problems with a mass matrix formulation.\nDAEOptimizer(IDA()) — uses the IDA solver (from Sundials.jl) for DAE problems with index variable support (requires using Sundials)\n\nYou can also define a custom optimizer using the generic ODEOptimizer(solver) or DAEOptimizer(solver) constructor by supplying any ODE or DAE solver supported by OrdinaryDiffEq.jl or Sundials.jl.","category":"section"},{"location":"optimization_packages/ode/#Interface-Details","page":"OptimizationODE.jl","title":"Interface Details","text":"All optimizers require gradient information (either via automatic differentiation or manually provided grad!). The optimization is performed by integrating the ODE defined by the negative gradient until a steady state is reached.","category":"section"},{"location":"tutorials/reusage_interface/#Optimization-Problem-Reusage-and-Caching-Interface","page":"Optimization Problem Reusage and Caching Interface","title":"Optimization Problem Reusage and Caching Interface","text":"","category":"section"},{"location":"tutorials/reusage_interface/#Reusing-Optimization-Caches-with-reinit!","page":"Optimization Problem Reusage and Caching Interface","title":"Reusing Optimization Caches with reinit!","text":"The reinit! function allows you to efficiently reuse an existing optimization cache with new parameters or initial values. This is particularly useful when solving similar optimization problems repeatedly with different parameter values, as it avoids the overhead of creating a new cache from scratch.","category":"section"},{"location":"tutorials/reusage_interface/#Basic-Usage","page":"Optimization Problem Reusage and Caching Interface","title":"Basic Usage","text":"# Create initial problem and cache\nusing Optimization, OptimizationOptimJL, ADTypes, ForwardDiff\nrosenbrock(u, p) = (p[1] - u[1])^2 + p[2] * (u[2] - u[1]^2)^2\nu0 = zeros(2)\np = [1.0, 100.0]\n\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = OptimizationProblem(optf, u0, p)\n\n# Initialize cache and solve\ncache = Optimization.init(prob, Optim.BFGS())\nsol = Optimization.solve!(cache)\n\n# Reinitialize cache with new parameters\ncache = Optimization.reinit!(cache; p = [2.0, 50.0])\nsol2 = Optimization.solve!(cache)","category":"section"},{"location":"tutorials/reusage_interface/#Supported-Arguments","page":"Optimization Problem Reusage and Caching Interface","title":"Supported Arguments","text":"The reinit! function supports updating various fields of the optimization cache:\n\nu0: New initial values for the optimization variables\np: New parameter values\nlb: New lower bounds (if applicable)\nub: New upper bounds (if applicable)\nlcons: New lower bounds for constraints (if applicable)\nucons: New upper bounds for constraints (if applicable)","category":"section"},{"location":"tutorials/reusage_interface/#Example:-Parameter-Sweep","page":"Optimization Problem Reusage and Caching Interface","title":"Example: Parameter Sweep","text":"# Solve for multiple parameter values efficiently\nresults = []\np_values = [[1.0, 100.0], [2.0, 100.0], [3.0, 100.0]]\n\n# Create initial cache\ncache = Optimization.init(prob, Optim.BFGS())\n\nfunction sweep(cache, p_values)\n    for p in p_values\n        cache = Optimization.reinit!(cache; p = p)\n        sol = Optimization.solve!(cache)\n        push!(results, (p = p, u = sol.u, objective = sol.objective))\n    end\nend\n\nsweep(cache, p_values)","category":"section"},{"location":"tutorials/reusage_interface/#Example:-Updating-Initial-Values","page":"Optimization Problem Reusage and Caching Interface","title":"Example: Updating Initial Values","text":"# Warm-start optimization from different initial points\nu0_values = [[0.0, 0.0], [0.5, 0.5], [1.0, 1.0]]\n\nfor u0 in u0_values\n    local cache\n    cache = Optimization.reinit!(cache; u0 = u0)\n    sol = Optimization.solve!(cache)\n    println(\"Starting from \", u0, \" converged to \", sol.u)\nend","category":"section"},{"location":"tutorials/reusage_interface/#Performance-Benefits","page":"Optimization Problem Reusage and Caching Interface","title":"Performance Benefits","text":"Using reinit! is more efficient than creating a new problem and cache for each parameter value, especially when:\n\nThe optimization algorithm maintains internal state that can be reused\nThe problem structure remains the same (only parameter values change)","category":"section"},{"location":"tutorials/reusage_interface/#Notes","page":"Optimization Problem Reusage and Caching Interface","title":"Notes","text":"The reinit! function modifies the cache in-place and returns it for convenience\nNot all fields need to be specified; only provide the ones you want to update\nThe function is particularly useful in iterative algorithms, parameter estimation, and when solving families of related optimization problems\nFor creating a new problem with different parameters (rather than modifying a cache), use remake on the OptimizationProblem instead","category":"section"},{"location":"optimization_packages/gcmaes/#GCMAES.jl","page":"GCMAES.jl","title":"GCMAES.jl","text":"GCMAES is a Julia package implementing the Gradient-based Covariance Matrix Adaptation Evolutionary Strategy, which can utilize the gradient information to speed up the optimization process.","category":"section"},{"location":"optimization_packages/gcmaes/#Installation:-OptimizationGCMAES.jl","page":"GCMAES.jl","title":"Installation: OptimizationGCMAES.jl","text":"To use this package, install the OptimizationGCMAES package:\n\nimport Pkg;\nPkg.add(\"OptimizationGCMAES\");","category":"section"},{"location":"optimization_packages/gcmaes/#Global-Optimizer","page":"GCMAES.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/gcmaes/#Without-Constraint-Equations","page":"GCMAES.jl","title":"Without Constraint Equations","text":"The GCMAES algorithm is called by GCMAESOpt() and the initial search variance is set as a keyword argument σ0 (default: σ0 = 0.2)\n\nThe method in GCMAES is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"section"},{"location":"optimization_packages/gcmaes/#Example","page":"GCMAES.jl","title":"Example","text":"The Rosenbrock function can be optimized using the GCMAESOpt() without utilizing the gradient information as follows:\n\nusing Optimization, OptimizationGCMAES\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, GCMAESOpt())\n\nWe can also utilize the gradient information of the optimization problem to aid the optimization as follows:\n\nusing ADTypes, ForwardDiff\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, GCMAESOpt())","category":"section"},{"location":"optimization_packages/evolutionary/#Evolutionary.jl","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary is a Julia package implementing various evolutionary and genetic algorithm.","category":"section"},{"location":"optimization_packages/evolutionary/#Installation:-OptimizationEvolutionary.jl","page":"Evolutionary.jl","title":"Installation: OptimizationEvolutionary.jl","text":"To use this package, install the OptimizationEvolutionary package:\n\nimport Pkg;\nPkg.add(\"OptimizationEvolutionary\");","category":"section"},{"location":"optimization_packages/evolutionary/#Global-Optimizer","page":"Evolutionary.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/evolutionary/#Without-Constraint-Equations","page":"Evolutionary.jl","title":"Without Constraint Equations","text":"The methods in Evolutionary are performing global optimization on problems without constraint equations. These methods work both with and without lower and upper constraints set by lb and ub in the OptimizationProblem.\n\nA Evolutionary algorithm is called by one of the following:\n\nEvolutionary.GA(): Genetic Algorithm optimizer\nEvolutionary.DE(): Differential Evolution optimizer\nEvolutionary.ES(): Evolution Strategy algorithm\nEvolutionary.CMAES(): Covariance Matrix Adaptation Evolution Strategy algorithm\n\nAlgorithm-specific options are defined as kwargs. See the respective documentation for more detail.","category":"section"},{"location":"optimization_packages/evolutionary/#Example","page":"Evolutionary.jl","title":"Example","text":"The Rosenbrock function can be optimized using the Evolutionary.CMAES() as follows:\n\nusing Optimization, OptimizationEvolutionary\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, Evolutionary.CMAES(μ = 40, λ = 100))","category":"section"},{"location":"tutorials/constraints/#constraints","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Multiple optimization packages available with the MathOptInterface and Optim's IPNewton solver can handle non-linear constraints. Optimization.jl provides a simple interface to define the constraint as a Julia function and then specify the bounds for the output in OptimizationFunction to indicate if it's an equality or inequality constraint.\n\nLet's define the rosenbrock function as our objective function and consider the below inequalities as our constraints.\n\nbeginaligned\n\nx_1^2 + x_2^2 leq 08 \n\n-10 leq x_1 * x_2 leq 20\nendaligned\n\nusing OptimizationBase, OptimizationMOI, OptimizationOptimJL, Ipopt\nusing ForwardDiff, ModelingToolkit\nusing DifferentiationInterface, ADTypes\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 1.0]\n\nNext, we define the sum of squares and the product of the optimization variables as our constraint functions.\n\ncons(res, x, p) = (res .= [x[1]^2 + x[2]^2, x[1] * x[2]])\n\nWe'll use the IPNewton solver from Optim to solve the problem.\n\noptprob = OptimizationFunction(rosenbrock, DifferentiationInterface.SecondOrder(ADTypes.AutoForwardDiff(), ADTypes.AutoForwardDiff()), cons = cons)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [-Inf, -1.0], ucons = [0.8, 2.0])\nsol = solve(prob, IPNewton())\n\nLet's check that the constraints are satisfied, and that the objective is lower than at initial values.\n\nres = zeros(2)\ncons(res, sol.u, _p)\nres\n\nprob.f(sol.u, _p)\n\nWe can also use the Ipopt library with the OptimizationMOI package.\n\nsol = solve(prob, Ipopt.Optimizer())\n\nres = zeros(2)\ncons(res, sol.u, _p)\nres\n\nprob.f(sol.u, _p)\n\nWe can also use ModelingToolkit as our AD backend and generate symbolic derivatives and expression graph for the objective and constraints.\n\nLet's modify the bounds to use the function as an equality constraint. The constraint now becomes -\n\nbeginaligned\n\nx_1^2 + x_2^2 = 10 \n\nx_1 * x_2 = 05\nendaligned\n\noptprob = OptimizationFunction(rosenbrock, ADTypes.AutoSymbolics(), cons = cons)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [1.0, 0.5], ucons = [1.0, 0.5])\n\nBelow, the AmplNLWriter.jl package is used with to use the Ipopt library to solve the problem.\n\nusing AmplNLWriter, Ipopt_jll\nsol = solve(prob, AmplNLWriter.Optimizer(Ipopt_jll.amplexe))\n\nThe constraints evaluate to 1.0 and 0.5 respectively, as expected.\n\nres = zeros(2)\ncons(res, sol.u, _p)\nprintln(res)","category":"section"},{"location":"optimization_packages/metaheuristics/#Metaheuristics.jl","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics is a Julia package implementing metaheuristic algorithms for global optimization that does not require for the optimized function to be differentiable.","category":"section"},{"location":"optimization_packages/metaheuristics/#Installation:-OptimizationMetaheuristics.jl","page":"Metaheuristics.jl","title":"Installation: OptimizationMetaheuristics.jl","text":"To use this package, install the OptimizationMetaheuristics package:\n\nimport Pkg;\nPkg.add(\"OptimizationMetaheuristics\");","category":"section"},{"location":"optimization_packages/metaheuristics/#Global-Optimizer","page":"Metaheuristics.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/#Without-Constraint-Equations","page":"Metaheuristics.jl","title":"Without Constraint Equations","text":"A Metaheuristics Single-Objective algorithm is called using one of the following:\n\nEvolutionary Centers Algorithm: ECA()\nDifferential Evolution: DE() with 5 different strategies\nDE(strategy=:rand1) - default strategy\nDE(strategy=:rand2)\nDE(strategy=:best1)\nDE(strategy=:best2)\nDE(strategy=:randToBest1)\nParticle Swarm Optimization: PSO()\nArtificial Bee Colony: ABC()\nGravitational Search Algorithm: CGSA()\nSimulated Annealing: SA()\nWhale Optimization Algorithm: WOA()\n\nMetaheuristics also performs Multiobjective optimization, but this is not yet supported by Optimization.\n\nEach optimizer sets default settings based on the optimization problem, but specific parameters can be set as shown in the original Documentation\n\nAdditionally, Metaheuristics common settings which would be defined by Metaheuristics.Options can be simply passed as special keyword arguments to solve without the need to use the Metaheuristics.Options struct.\n\nLastly, information about the optimization problem such as the true optimum is set via Metaheuristics.Information and passed as part of the optimizer struct to solve e.g., solve(prob, ECA(information=Metaheuristics.Information(f_optimum = 0.0)))\n\nThe currently available algorithms and their parameters are listed here.","category":"section"},{"location":"optimization_packages/metaheuristics/#Notes","page":"Metaheuristics.jl","title":"Notes","text":"The algorithms in Metaheuristics are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"section"},{"location":"optimization_packages/metaheuristics/#Examples","page":"Metaheuristics.jl","title":"Examples","text":"The Rosenbrock function can be optimized using the Evolutionary Centers Algorithm ECA() as follows:\n\nusing Optimization, OptimizationMetaheuristics\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, ECA(), maxiters = 100000, maxtime = 1000.0)\n\nPer default Metaheuristics ignores the initial values x0 set in the OptimizationProblem. In order to for Optimization to use x0 we have to set use_initial=true:\n\nsol = solve(prob, ECA(), use_initial = true, maxiters = 100000, maxtime = 1000.0)","category":"section"},{"location":"optimization_packages/metaheuristics/#With-Constraint-Equations","page":"Metaheuristics.jl","title":"With Constraint Equations","text":"While Metaheuristics.jl supports such constraints, Optimization.jl currently does not relay these constraints.","category":"section"},{"location":"optimization_packages/mathoptinterface/#MathOptInterface.jl","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"MathOptInterface is a Julia abstraction layer to interface with a variety of mathematical optimization solvers.","category":"section"},{"location":"optimization_packages/mathoptinterface/#Installation:-OptimizationMOI.jl","page":"MathOptInterface.jl","title":"Installation: OptimizationMOI.jl","text":"To use this package, install the OptimizationMOI package:\n\nimport Pkg;\nPkg.add(\"OptimizationMOI\");","category":"section"},{"location":"optimization_packages/mathoptinterface/#Details","page":"MathOptInterface.jl","title":"Details","text":"As of now, the Optimization interface to MathOptInterface implements only the maxtime common keyword argument.\n\nOptimizationMOI supports an argument mtkize which takes a boolean (default to false) that allows automatic symbolic expression generation, this allows using any AD backend with solvers or interfaces such as AmplNLWriter that require the expression graph of the objective and constraints. This always happens automatically in the case of the AutoSymbolics adtype.\n\nAn optimizer which supports the MathOptInterface API can be called directly if no optimizer options have to be defined.\n\nFor example, using the Ipopt.jl optimizer:\n\nusing OptimizationMOI, Ipopt\nsol = solve(prob, Ipopt.Optimizer())\n\nThe optimizer options are handled in one of two ways. They can either be set via OptimizationMOI.MOI.OptimizerWithAttributes() or as keyword arguments to solve.\n\nFor example, using the Ipopt.jl optimizer:\n\nusing OptimizationMOI, Ipopt\nopt = OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n    \"option_name\" => option_value, ...)\nsol = solve(prob, opt)\n\nsol = solve(prob, Ipopt.Optimizer(); option_name = option_value, ...)","category":"section"},{"location":"optimization_packages/mathoptinterface/#Optimizers","page":"MathOptInterface.jl","title":"Optimizers","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#Ipopt.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Ipopt.jl (MathOptInterface)","text":"Ipopt.Optimizer\nThe full list of optimizer options can be found in the Ipopt Documentation","category":"section"},{"location":"optimization_packages/mathoptinterface/#KNITRO.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"KNITRO.jl (MathOptInterface)","text":"KNITRO.Optimizer\nThe full list of optimizer options can be found in the KNITRO Documentation","category":"section"},{"location":"optimization_packages/mathoptinterface/#Juniper.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Juniper.jl (MathOptInterface)","text":"Juniper.Optimizer\nJuniper requires a nonlinear optimizer to be set via the nl_solver option, which must be a MathOptInterface-based optimizer. See the Juniper documentation for more detail.\n\nusing Optimization, OptimizationMOI, Juniper, Ipopt, ADTypes, ForwardDiff\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(f, x0, _p)\n\nopt = OptimizationMOI.MOI.OptimizerWithAttributes(Juniper.Optimizer,\n    \"nl_solver\" => OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n        \"print_level\" => 0))\nsol = solve(prob, opt)","category":"section"},{"location":"optimization_packages/mathoptinterface/#Using-Integer-Constraints","page":"MathOptInterface.jl","title":"Using Integer Constraints","text":"The following shows how to use integer linear programming within Optimization. We will solve the classical Knapsack Problem using Juniper.jl.\n\nJuniper.Optimizer\nJuniper requires a nonlinear optimizer to be set via the nl_solver option, which must be a MathOptInterface-based optimizer. See the Juniper documentation for more detail.\nThe integer domain is inferred based on the bounds of the variable:\nSetting the lower bound to zero and the upper bound to one corresponds to MOI.ZeroOne() or a binary decision variable\nProviding other or no bounds corresponds to MOI.Integer()\n\nv = [1.0, 2.0, 4.0, 3.0]\nw = [5.0, 4.0, 3.0, 2.0]\nW = 4.0\nu0 = [0.0, 0.0, 0.0, 1.0]\n\noptfun = OptimizationFunction((u, p) -> -v'u, cons = (res, u, p) -> res .= w'u,\n    ADTypes.AutoForwardDiff())\n\noptprob = OptimizationProblem(optfun, u0; lb = zero.(u0), ub = one.(u0),\n    int = ones(Bool, length(u0)),\n    lcons = [-Inf;], ucons = [W;])\n\nnl_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n    \"print_level\" => 0)\nminlp_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Juniper.Optimizer,\n    \"nl_solver\" => nl_solver)\n\nres = solve(optprob, minlp_solver)","category":"section"},{"location":"optimization_packages/lbfgsb/#OptimizationLBFGSB.jl","page":"OptimizationLBFGSB.jl","title":"OptimizationLBFGSB.jl","text":"OptimizationLBFGSB.jl is a package that wraps the L-BFGS-B fortran routine via the LBFGSB.jl package.","category":"section"},{"location":"optimization_packages/lbfgsb/#Installation","page":"OptimizationLBFGSB.jl","title":"Installation","text":"To use this package, install the OptimizationLBFGSB package:\n\nusing Pkg\nPkg.add(\"OptimizationLBFGSB\")","category":"section"},{"location":"optimization_packages/lbfgsb/#Methods","page":"OptimizationLBFGSB.jl","title":"Methods","text":"LBFGSB: The popular quasi-Newton method that leverages limited memory BFGS approximation of the inverse of the Hessian. It directly supports box-constraints.\nThis can also handle arbitrary non-linear constraints through an Augmented Lagrangian method with bounds constraints described in 17.4 of Numerical Optimization by Nocedal and Wright. Thus serving as a general-purpose nonlinear optimization solver.","category":"section"},{"location":"optimization_packages/lbfgsb/#Examples","page":"OptimizationLBFGSB.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/lbfgsb/#Unconstrained-rosenbrock-problem","page":"OptimizationLBFGSB.jl","title":"Unconstrained rosenbrock problem","text":"using OptimizationBase, OptimizationLBFGSB, ADTypes, Zygote\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\n\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoZygote())\nprob = OptimizationProblem(optf, x0, p)\nsol = solve(prob, LBFGSB())","category":"section"},{"location":"optimization_packages/lbfgsb/#With-nonlinear-and-bounds-constraints","page":"OptimizationLBFGSB.jl","title":"With nonlinear and bounds constraints","text":"function con2_c(res, x, p)\n    res .= [x[1]^2 + x[2]^2, (x[2] * sin(x[1]) + x[1]) - 5]\nend\n\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoZygote(), cons = con2_c)\nprob = OptimizationProblem(optf, x0, p, lcons = [1.0, -Inf],\n    ucons = [1.0, 0.0], lb = [-1.0, -1.0],\n    ub = [1.0, 1.0])\nres = solve(prob, LBFGSB(), maxiters = 100)","category":"section"},{"location":"optimization_packages/lbfgsb/#OptimizationLBFGSB.LBFGSB","page":"OptimizationLBFGSB.jl","title":"OptimizationLBFGSB.LBFGSB","text":"struct LBFGSB\n\nL-BFGS-B Nonlinear Optimization Code from LBFGSB. It is a quasi-Newton optimization algorithm that supports bounds.\n\nReferences\n\nR. H. Byrd, P. Lu and J. Nocedal. A Limited Memory Algorithm for Bound Constrained Optimization, (1995), SIAM Journal on Scientific and Statistical Computing , 16, 5, pp. 1190-1208.\nC. Zhu, R. H. Byrd and J. Nocedal. L-BFGS-B: Algorithm 778: L-BFGS-B, FORTRAN routines for large scale bound constrained optimization (1997), ACM Transactions on Mathematical Software, Vol 23, Num. 4, pp. 550 - 560.\nJ.L. Morales and J. Nocedal. L-BFGS-B: Remark on Algorithm 778: L-BFGS-B, FORTRAN routines for large scale bound constrained optimization (2011), to appear in ACM Transactions on Mathematical Software.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/nlpmodels/#NLPModels.jl","page":"NLPModels.jl","title":"NLPModels.jl","text":"NLPModels, similarly to Optimization.jl itself, provides a standardized modeling interface for representing Non-Linear Programs that facilitates using different solvers on the same problem. The Optimization.jl extension of NLPModels aims to provide a thin translation layer to make NLPModels, the main export of the package, compatible with the optimizers in the Optimization.jl ecosystem.","category":"section"},{"location":"optimization_packages/nlpmodels/#Installation:-NLPModels.jl","page":"NLPModels.jl","title":"Installation: NLPModels.jl","text":"To translate an NLPModel, install the OptimizationNLPModels package:\n\nimport Pkg;\nPkg.add(\"OptimizationNLPModels\")\n\nThe package NLPModels.jl itself contains no optimizers or models. Several packages provide optimization problem (CUTEst.jl, NLPModelsTest.jl) which can then be solved with any optimizer supported by Optimization.jl","category":"section"},{"location":"optimization_packages/nlpmodels/#Usage","page":"NLPModels.jl","title":"Usage","text":"For example, solving a problem defined in NLPModelsTest with Ipopt.jl. First, install the packages like so:\n\nimport Pkg;\nPkg.add(\"NLPModelsTest\", \"Ipopt\")\n\nWe instantiate problem 10 in the Hock–Schittkowski optimization suite available from NLPModelsTest as HS10, then translate it to an OptimizationProblem.\n\nusing OptimizationNLPModels, Optimization, NLPModelsTest, Ipopt\nusing Optimization: OptimizationProblem\nnlpmodel = NLPModelsTest.HS10()\nprob = OptimizationProblem(nlpmodel, AutoForwardDiff())\n\nwhich can now be solved like any other OptimizationProblem:\n\nsol = solve(prob, Ipopt.Optimizer())","category":"section"},{"location":"optimization_packages/nlpmodels/#API","page":"NLPModels.jl","title":"API","text":"Problems represented as NLPModels can be used to create OptimizationProblems and OptimizationFunction.","category":"section"},{"location":"API/optimization_problem/#Defining-OptimizationProblems","page":"Defining OptimizationProblems","title":"Defining OptimizationProblems","text":"","category":"section"},{"location":"API/optimization_problem/#SciMLBase.OptimizationProblem","page":"Defining OptimizationProblems","title":"SciMLBase.OptimizationProblem","text":"Defines an optimization problem. Documentation Page: https://docs.sciml.ai/Optimization/stable/API/optimization_problem/\n\nMathematical Specification of an Optimization Problem\n\nTo define an optimization problem, you need the objective function f which is minimized over the domain of u, the collection of optimization variables:\n\nmin_u f(up)\n\nu₀ is an initial guess for the minimizer. f should be specified as f(u,p) and u₀ should be an AbstractArray whose geometry matches the desired geometry of u. Note that we are not limited to vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher-dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nOptimizationProblem{isinplace}(f, u0, p = SciMLBase.NullParameters(),;\n                        lb = nothing,\n                        ub = nothing,\n                        lcons = nothing,\n                        ucons = nothing,\n                        sense = nothing,\n                        kwargs...)\n\nisinplace optionally sets whether the function is in-place or not. This is determined automatically, but not inferred. Note that for OptimizationProblem, in-place refers to the objective's derivative functions, the constraint function and its derivatives. OptimizationProblem currently only supports in-place.\n\nParameters p are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters.\n\nlb and ub are the upper and lower bounds for box constraints on the optimization variables. They should be an AbstractArray matching the geometry of u, where (lb[i],ub[i]) is the box constraint (lower and upper bounds) for u[i].\n\nlcons and ucons are the upper and lower bounds in case of inequality constraints on the optimization and if they are set to be equal then it represents an equality constraint. They should be an AbstractArray, where (lcons[i],ucons[i]) are the lower and upper bounds for cons[i].\n\nThe f in the OptimizationProblem should typically be an instance of OptimizationFunction to specify the objective function and its derivatives either by passing predefined functions for them or automatically generated using the ADType.\n\nIf f is a standard Julia function, it is automatically transformed into an OptimizationFunction with NoAD(), meaning the derivative functions are not automatically generated.\n\nAny extra keyword arguments are captured to be sent to the optimizers.\n\nFields\n\nf: the function in the problem.\nu0: the initial guess for the optimization variables.\np: Either the constant parameters or fixed data (full batch) used in the objective or a MLUtils DataLoader for minibatching with stochastic optimization solvers. Defaults to NullParameters.\nlb: the lower bounds for the optimization variables u.\nub: the upper bounds for the optimization variables u.\nint: integrality indicator for u. If int[i] == true, then u[i] is an integer variable.   Defaults to nothing, implying no integrality constraints.\nlcons: the vector of lower bounds for the constraints passed to OptimizationFunction.   Defaults to nothing, implying no lower bounds for the constraints (i.e. the constraint bound is -Inf)\nucons: the vector of upper bounds for the constraints passed to OptimizationFunction.   Defaults to nothing, implying no upper bounds for the constraints (i.e. the constraint bound is Inf)\nsense: the objective sense, can take MaxSense or MinSense from Optimization.jl.\nkwargs: the keyword arguments passed on to the solvers.\n\nInequality and Equality Constraints\n\nBoth inequality and equality constraints are defined by the f.cons function in the OptimizationFunction description of the problem structure. This f.cons is given as a function f.cons(u,p) which computes the value of the constraints at u. For example, take f.cons(u,p) = u[1] - u[2]. With these definitions, lcons and ucons define the bounds on the constraint that the solvers try to satisfy. If lcons and ucons are nothing, then there are no constraints bounds, meaning that the constraint is satisfied when -Inf < f.cons < Inf (which of course is always!). If lcons[i] = ucons[i] = 0, then the constraint is satisfied when f.cons(u,p)[i] = 0, and so this implies the equality constraint u[1] = u[2]. If lcons[i] = ucons[i] = a, then u1 - u2 = a is the equality constraint.\n\nInequality constraints are then given by making lcons[i] != ucons[i]. For example, lcons[i] = -Inf and ucons[i] = 0 would imply the inequality constraint u[1] <= u[2] since any f.cons[i] <= 0 satisfies the constraint. Similarly, lcons[i] = -1 and ucons[i] = 1 would imply that -1 <= f.cons[i] <= 1 is required or -1 <= u[1] - u[2] <= 1.\n\nNote that these vectors must be sized to match the number of constraints, with one set of conditions for each constraint.\n\nData handling\n\nAs described above the second argument of the objective definition can take a full batch or a DataLoader object for mini-batching which is useful for stochastic optimization solvers. Thus the data either as an Array or a DataLoader object should be passed as the third argument of the OptimizationProblem constructor. For an example of how to use this data handling, see the Sophia example in the Optimization.jl documentation or the mini-batching tutorial.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/speedmapping/#SpeedMapping.jl","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"SpeedMapping accelerates the convergence of a mapping to a fixed point by the Alternating cyclic extrapolation algorithm which can also perform multivariate optimization based on the gradient function.\n\nThe SpeedMapping algorithm is called by SpeedMappingOpt()","category":"section"},{"location":"optimization_packages/speedmapping/#Installation:-OptimizationSpeedMapping.jl","page":"SpeedMapping.jl","title":"Installation: OptimizationSpeedMapping.jl","text":"To use this package, install the OptimizationSpeedMapping package:\n\nimport Pkg;\nPkg.add(\"OptimizationSpeedMapping\");","category":"section"},{"location":"optimization_packages/speedmapping/#Global-Optimizer","page":"SpeedMapping.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/speedmapping/#Without-Constraint-Equations","page":"SpeedMapping.jl","title":"Without Constraint Equations","text":"The method in SpeedMapping is performing optimization on problems without constraint equations. Lower and upper constraints set by lb and ub in the OptimizationProblem are optional.\n\nIf no AD backend is defined via OptimizationFunction the gradient is calculated via SpeedMapping's ForwardDiff AD backend.\n\nThe Rosenbrock function can be optimized using the SpeedMappingOpt() with and without bound as follows:\n\nusing Optimization, OptimizationSpeedMapping, ADTypes, ForwardDiff\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = OptimizationProblem(f, x0, p)\nsol = solve(prob, SpeedMappingOpt())\n\nprob = OptimizationProblem(f, x0, p; lb = [0.0, 0.0], ub = [1.0, 1.0])\nsol = solve(prob, SpeedMappingOpt())","category":"section"},{"location":"optimization_packages/multistartoptimization/#MultiStartOptimization.jl","page":"MultistartOptimization.jl","title":"MultiStartOptimization.jl","text":"MultistartOptimization is a Julia package implementing a global optimization multistart method which performs local optimization after choosing multiple starting points.\n\nMultistartOptimization requires both a global and local method to be defined. The global multistart method chooses a set of initial starting points from where local the local method starts from.\n\nCurrently, only one global method (TikTak) is implemented and called by MultistartOptimization.TikTak(n) where n is the number of initial Sobol points.","category":"section"},{"location":"optimization_packages/multistartoptimization/#Installation:-OptimizationMultistartOptimization.jl","page":"MultistartOptimization.jl","title":"Installation: OptimizationMultistartOptimization.jl","text":"To use this package, install the OptimizationMultistartOptimization package:\n\nimport Pkg;\nPkg.add(\"OptimizationMultistartOptimization\");\n\nnote: Note\n\n\nYou also need to load the relevant subpackage for the local method of your choice, for example if you plan to use one of the NLopt.jl's optimizers, you'd install and load OptimizationNLopt as described in the NLopt.jl's section.","category":"section"},{"location":"optimization_packages/multistartoptimization/#Global-Optimizer","page":"MultistartOptimization.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/#Without-Constraint-Equations","page":"MultistartOptimization.jl","title":"Without Constraint Equations","text":"The methods in MultistartOptimization are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"section"},{"location":"optimization_packages/multistartoptimization/#Examples","page":"MultistartOptimization.jl","title":"Examples","text":"The Rosenbrock function can be optimized using MultistartOptimization.TikTak() with 100 initial points and the local method NLopt.LD_LBFGS() as follows:\n\nusing Optimization, OptimizationMultistartOptimization, OptimizationNLopt, ADTypes, ForwardDiff\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), NLopt.LD_LBFGS())\n\nYou can use any Optimization optimizers you like. The global method of the MultistartOptimization is a positional argument and followed by the local method. For example, we can perform a multistartoptimization with LBFGS as the optimizer using either the NLopt.jl or Optim.jl implementation as follows. Moreover, this interface allows you to access and adjust all the optimizer settings as you normally would:\n\nusing OptimizationOptimJL\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), LBFGS(), maxiters = 5)","category":"section"},{"location":"optimization_packages/polyopt/#OptimizationPolyalgorithms.jl","page":"Polyalgorithms.jl","title":"OptimizationPolyalgorithms.jl","text":"OptimizationPolyalgorithms.jl is a package for collecting polyalgorithms formed by fusing popular optimization solvers of different characteristics.","category":"section"},{"location":"optimization_packages/polyopt/#Installation:-OptimizationPolyalgorithms","page":"Polyalgorithms.jl","title":"Installation: OptimizationPolyalgorithms","text":"To use this package, install the OptimizationPolyalgorithms package:\n\nimport Pkg;\nPkg.add(\"OptimizationPolyalgorithms\");","category":"section"},{"location":"optimization_packages/polyopt/#Algorithms","page":"Polyalgorithms.jl","title":"Algorithms","text":"Right now we support the following polyalgorithms.\n\nPolyOpt: Runs Adam followed by BFGS for an equal number of iterations. This is useful in scientific machine learning use cases, by exploring the loss surface with the stochastic optimizer and converging to the minima faster with BFGS.\n\nusing Optimization, OptimizationPolyalgorithms, ADTypes, ForwardDiff\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\noptprob = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = OptimizationProblem(optprob, x0, _p)\nsol = Optimization.solve(prob, PolyOpt(), maxiters = 1000)","category":"section"},{"location":"API/optimization_function/#optfunction","page":"OptimizationFunction","title":"OptimizationFunction","text":"","category":"section"},{"location":"API/optimization_function/#SciMLBase.OptimizationFunction","page":"OptimizationFunction","title":"SciMLBase.OptimizationFunction","text":"struct OptimizationFunction{iip, AD, F, G, FG, H, FGH, HV, C, CJ, CJV, CVJ, CH, HP, CJP, CHP, O, EX, CEX, SYS, LH, LHP, HCV, CJCV, CHCV, LHCV, ID} <: SciMLBase.AbstractOptimizationFunction{iip}\n\nA representation of an objective function f, defined by:\n\nmin_u f(up)\n\nand all of its related functions, such as the gradient of f, its Hessian, and more. For all cases, u is the state which in this case are the optimization variables and p are the fixed parameters or data.\n\nConstructor\n\nOptimizationFunction{iip}(f, adtype::AbstractADType = NoAD();\n    grad = nothing, hess = nothing, hv = nothing,\n    cons = nothing, cons_j = nothing, cons_jvp = nothing,\n    cons_vjp = nothing, cons_h = nothing,\n    hess_prototype = nothing,\n    cons_jac_prototype = nothing,\n    cons_hess_prototype = nothing,\n    observed = __has_observed(f) ? f.observed : DEFAULT_OBSERVED_NO_TIME,\n    lag_h = nothing,\n    hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n    cons_jac_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n    cons_hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n    lag_hess_colorvec = nothing,\n    sys = __has_sys(f) ? f.sys : nothing)\n\nPositional Arguments\n\nf(u,p): the function to optimize. u are the optimization variables and p are fixed parameters or data used in the objective, even if no such parameters are used in the objective it should be an argument in the function. For minibatching p can be used to pass in a minibatch, take a look at the tutorial here to see how to do it. This should return a scalar, the loss value, as the return output.\nadtype: see the Defining Optimization Functions via AD section below.\n\nKeyword Arguments\n\ngrad(G,u,p) or G=grad(u,p): the gradient of f with respect to u.\nhess(H,u,p) or H=hess(u,p): the Hessian of f with respect to u.\nhv(Hv,u,v,p) or Hv=hv(u,v,p): the Hessian-vector product (d^2 f  du^2) v.\ncons(res,u,p) or res=cons(u,p) : the constraints function, should mutate the passed res array with value of the ith constraint, evaluated at the current values of variables inside the optimization routine. This takes just the function evaluations and the equality or inequality assertion is applied by the solver based on the constraint bounds passed as lcons and ucons to OptimizationProblem, in case of equality constraints lcons and ucons should be passed equal values.\ncons_j(J,u,p) or J=cons_j(u,p): the Jacobian of the constraints.\ncons_jvp(Jv,u,v,p) or Jv=cons_jvp(u,v,p): the Jacobian-vector product of the constraints.\ncons_vjp(Jv,u,v,p) or Jv=cons_vjp(u,v,p): the Jacobian-vector product of the constraints.\ncons_h(H,u,p) or H=cons_h(u,p): the Hessian of the constraints, provided as an array of Hessians with res[i] being the Hessian with respect to the ith output on cons.\nhess_prototype: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized Hessian matrix can be used as the prototype and optimization solvers will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Hessian. The default is nothing, which means a dense Hessian.\ncons_jac_prototype: a prototype matrix matching the type that matches the constraint Jacobian. The default is nothing, which means a dense constraint Jacobian.\ncons_hess_prototype: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where hess[i] is the Hessian w.r.t. the ith output. For example, if the Hessian is sparse, then hess is a Vector{SparseMatrixCSC}. The default is nothing, which means a dense constraint Hessian.\nlag_h(res,u,sigma,mu,p) or res=lag_h(u,sigma,mu,p): the Hessian of the Lagrangian, where sigma is a multiplier of the cost function and mu are the Lagrange multipliers multiplying the constraints. This can be provided instead of hess and cons_h to solvers that directly use the Hessian of the Lagrangian.\nhess_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the hess_prototype. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\ncons_jac_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_jac_prototype.\ncons_hess_colorvec: an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_hess_prototype.\n\nWhen Symbolic Problem Building with ModelingToolkit interface is used the following arguments are also relevant:\n\nobserved: an algebraic combination of optimization variables that is of interest to the user which will be available in the solution. This can be single or multiple expressions.\nsys: field that stores the OptimizationSystem.\n\nDefining Optimization Functions via AD\n\nWhile using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an OptimizationFunction is by specifying an option from ADTypes.jl which lets the user choose the Automatic Differentiation backend to use for automatically filling in all of the extra functions. For example,\n\nOptimizationFunction(f, AutoForwardDiff())\n\nwill use ForwardDiff.jl to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.\n\nEach of the AD-based constructors are documented separately via their own dispatches below in the Automatic Differentiation Construction Choice Recommendations section.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nspecialize: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the OptimizationFunction type directly match the names of the inputs.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/pycma/#PyCMA.jl","page":"PyCMA.jl","title":"PyCMA.jl","text":"PyCMA is a Python implementation of CMA-ES and a few related numerical optimization tools. OptimizationPyCMA.jl gives access to the CMA-ES optimizer through the unified Optimization.jl interface just like any native Julia optimizer.\n\nOptimizationPyCMA.jl relies on PythonCall. A minimal Python distribution containing PyCMA will be installed automatically on first use, so no manual Python set-up is required.","category":"section"},{"location":"optimization_packages/pycma/#Installation:-OptimizationPyCMA.jl","page":"PyCMA.jl","title":"Installation: OptimizationPyCMA.jl","text":"import Pkg\nPkg.add(\"OptimizationPyCMA\")","category":"section"},{"location":"optimization_packages/pycma/#Methods","page":"PyCMA.jl","title":"Methods","text":"PyCMAOpt supports the usual keyword arguments maxiters, maxtime, abstol, reltol, callback in addition to any PyCMA-specific options (passed verbatim via keyword arguments to solve).","category":"section"},{"location":"optimization_packages/pycma/#Example","page":"PyCMA.jl","title":"Example","text":"using OptimizationPyCMA\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\nl1 = rosenbrock(x0, _p)\nf = OptimizationFunction(rosenbrock)\nprob = OptimizationProblem(f, x0, _p, lb = [-1.0, -1.0], ub = [0.8, 0.8])\nsol = solve(prob, PyCMAOpt())","category":"section"},{"location":"optimization_packages/pycma/#Passing-solver-specific-options","page":"PyCMA.jl","title":"Passing solver-specific options","text":"Any keyword that Optimization.jl does not interpret is forwarded directly to PyCMA.\n\nIn the event an Optimization.jl keyword overlaps with a PyCMA keyword, the Optimization.jl keyword takes precedence.\n\nAn exhaustive list of keyword arguments can be found by running the following python script:\n\nimport cma\noptions = cma.CMAOptions()\nprint(options)\n\nAn example passing the PyCMA keywords \"verbose\" and \"seed\":\n\nsol = solve(prob, PyCMA(), verbose = -9, seed = 42)","category":"section"},{"location":"optimization_packages/pycma/#Troubleshooting","page":"PyCMA.jl","title":"Troubleshooting","text":"The original Python result object is attached to the solution in the original field:\n\nsol = solve(prob, PyCMAOpt())\nprintln(sol.original)","category":"section"},{"location":"optimization_packages/pycma/#Contributing","page":"PyCMA.jl","title":"Contributing","text":"Bug reports and feature requests are welcome in the Optimization.jl issue tracker.  Pull requests that improve either the Julia wrapper or the documentation are highly appreciated.","category":"section"},{"location":"#Optimization.jl:-A-Unified-Optimization-Package","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Optimization.jl provides the easiest way to create an optimization problem and solve it. It enables rapid prototyping and experimentation with minimal syntax overhead by providing a uniform interface to >25 optimization libraries, hence 100+ optimization solvers encompassing almost all classes of optimization algorithms such as global, mixed-integer, non-convex, second-order local, constrained, etc. It allows you to choose an Automatic Differentiation (AD) backend by simply passing an argument to indicate the package to use and automatically generates the efficient derivatives of the objective and constraints while giving you the flexibility to switch between different AD engines as per your problem. Additionally, Optimization.jl takes care of passing problem specific information to solvers that can leverage it such as the sparsity pattern of the hessian or constraint jacobian and the expression graph.\n\nIt extends the common SciML interface making it very easy to use for anyone familiar with the SciML ecosystem. It is also very easy to extend to new solvers and new problem types. The package is actively maintained and new features are added regularly.","category":"section"},{"location":"#Installation","page":"Optimization.jl: A Unified Optimization Package","title":"Installation","text":"Assuming that you already have Julia correctly installed, it suffices to import Optimization.jl in the standard way:\n\nimport Pkg\nPkg.add(\"Optimization\")\n\nThe packages relevant to the core functionality of Optimization.jl will be imported accordingly and, in most cases, you do not have to worry about the manual installation of dependencies. Optimization.jl natively offers a LBFGS solver but for more solver choices (discussed below in Optimization Packages), you will need to add the specific wrapper packages.","category":"section"},{"location":"#Contributing","page":"Optimization.jl: A Unified Optimization Package","title":"Contributing","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"section"},{"location":"#Overview-of-the-solver-packages-in-alphabetical-order","page":"Optimization.jl: A Unified Optimization Package","title":"Overview of the solver packages in alphabetical order","text":"<details>\n  <summary><strong>BlackBoxOptim</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>CMAEvolutionaryStrategy</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>Evolutionary</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n    - Non-linear Constraints\n</details>\n<details>\n  <summary><strong>GCMAES</strong></summary>\n  - <strong>Global Methods</strong>\n    - First order\n    - Box Constraints\n    - Unconstrained\n</details>\n<details>\n  <summary><strong>Manopt</strong></summary>\n  - <strong>Local Methods</strong>\n    - First order\n    - Second order\n    - Zeroth order\n    - Box Constraints\n    - Constrained 🟡\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n</details>\n<details>\n  <summary><strong>MathOptInterface</strong></summary>\n  - <strong>Local Methods</strong>\n    - First order\n    - Second order\n    - Box Constraints\n    - Constrained\n  - <strong>Global Methods</strong>\n    - First order\n    - Second order\n    - Constrained\n</details>\n<details>\n  <summary><strong>MultistartOptimization</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - First order\n    - Second order\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>Metaheuristics</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>NOMAD</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n    - Constrained 🟡\n</details>\n<details>\n  <summary><strong>NLopt</strong></summary>\n  - <strong>Local Methods</strong>\n    - First order\n    - Zeroth order\n    - Second order 🟡\n    - Box Constraints\n    - Local Constrained 🟡\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - First order\n    - Unconstrained\n    - Constrained 🟡\n</details>\n<details>\n  <summary><strong>Optim</strong></summary>\n  - <strong>Local Methods</strong>\n    - Zeroth order\n    - First order\n    - Second order\n    - Box Constraints\n    - Constrained\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>PRIMA</strong></summary>\n  - <strong>Local Methods</strong>\n    - Derivative-Free: ✅\n  - **Constraints**\n    - Box Constraints: ✅\n    - Local Constrained: ✅\n</details>\n<details>\n  <summary><strong>QuadDIRECT</strong></summary>\n  - **Constraints**\n    - Box Constraints: ✅\n  - <strong>Global Methods</strong>\n    - Unconstrained: ✅\n</details>\n\n🟡 = supported in downstream library but not yet implemented in Optimization.jl; PR to add this functionality are welcome","category":"section"},{"location":"#Citation","page":"Optimization.jl: A Unified Optimization Package","title":"Citation","text":"@software{vaibhav_kumar_dixit_2023_7738525,\n\tauthor = {Vaibhav Kumar Dixit and Christopher Rackauckas},\n\tmonth = mar,\n\tpublisher = {Zenodo},\n\ttitle = {Optimization.jl: A Unified Optimization Package},\n\tversion = {v3.12.1},\n\tdoi = {10.5281/zenodo.7738525},\n  \turl = {https://doi.org/10.5281/zenodo.7738525},\n\tyear = 2023}","category":"section"},{"location":"#Reproducibility","page":"Optimization.jl: A Unified Optimization Package","title":"Reproducibility","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>\n\nusing Pkg # hide\nPkg.status() # hide\n\n</details>\n\n<details><summary>and using this machine and Julia version.</summary>\n\nusing InteractiveUtils # hide\nversioninfo() # hide\n\n</details>\n\n<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>\n\nusing Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide\n\n</details>\n\nusing TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"section"},{"location":"optimization_packages/ipopt/#OptimizationIpopt.jl","page":"Ipopt.jl","title":"OptimizationIpopt.jl","text":"OptimizationIpopt.jl is a wrapper package that integrates Ipopt.jl with the Optimization.jl ecosystem. This allows you to use the powerful Ipopt (Interior Point OPTimizer) solver through Optimization.jl's unified interface.\n\nIpopt is a software package for large-scale nonlinear optimization designed to find (local) solutions of mathematical optimization problems of the form:\n\nbeginaligned\nmin_x in mathbbR^n quad  f(x) \ntextst quad  g_L leq g(x) leq g_U \n x_L leq x leq x_U\nendaligned\n\nwhere f(x) mathbbR^n to mathbbR is the objective function, g(x) mathbbR^n to mathbbR^m are the constraint functions, and the vectors g_L and g_U denote the lower and upper bounds on the constraints, and the vectors x_L and x_U are the bounds on the variables x.","category":"section"},{"location":"optimization_packages/ipopt/#Installation:-OptimizationIpopt.jl","page":"Ipopt.jl","title":"Installation: OptimizationIpopt.jl","text":"To use this package, install the OptimizationIpopt package:\n\nimport Pkg;\nPkg.add(\"OptimizationIpopt\");","category":"section"},{"location":"optimization_packages/ipopt/#Methods","page":"Ipopt.jl","title":"Methods","text":"OptimizationIpopt.jl provides the IpoptOptimizer algorithm, which wraps the Ipopt.jl solver for use with Optimization.jl. This is an interior-point algorithm that uses line search filter methods and is particularly effective for:\n\nLarge-scale nonlinear problems\nProblems with nonlinear constraints\nProblems requiring high accuracy solutions","category":"section"},{"location":"optimization_packages/ipopt/#Algorithm-Requirements","page":"Ipopt.jl","title":"Algorithm Requirements","text":"IpoptOptimizer requires:\n\nGradient information (via automatic differentiation or user-provided)\nHessian information (can be approximated or provided)\nConstraint Jacobian (for constrained problems)\nConstraint Hessian (for constrained problems)\n\nThe algorithm supports:\n\nBox constraints via lb and ub in the OptimizationProblem\nGeneral nonlinear equality and inequality constraints via lcons and ucons","category":"section"},{"location":"optimization_packages/ipopt/#Basic-Usage","page":"Ipopt.jl","title":"Basic Usage","text":"using OptimizationBase, OptimizationIpopt\n\n# Create optimizer with default settings\nopt = IpoptOptimizer()\n\n# Or configure Ipopt-specific options\nopt = IpoptOptimizer(\n    acceptable_tol = 1e-8,\n    mu_strategy = \"adaptive\"\n)\n\n# Solve the problem\nsol = solve(prob, opt)","category":"section"},{"location":"optimization_packages/ipopt/#Options-and-Parameters","page":"Ipopt.jl","title":"Options and Parameters","text":"","category":"section"},{"location":"optimization_packages/ipopt/#Common-Interface-Options","page":"Ipopt.jl","title":"Common Interface Options","text":"The following options can be passed as keyword arguments to solve and follow the common Optimization.jl interface:\n\nmaxiters: Maximum number of iterations (overrides Ipopt's max_iter)\nmaxtime: Maximum wall time in seconds (overrides Ipopt's max_wall_time)\nabstol: Absolute tolerance (not directly used by Ipopt)\nreltol: Convergence tolerance (overrides Ipopt's tol)\nverbose: Control output verbosity (overrides Ipopt's print_level)\nfalse or 0: No output\ntrue or 5: Standard output\nInteger values 0-12: Different verbosity levels","category":"section"},{"location":"optimization_packages/ipopt/#IpoptOptimizer-Constructor-Options","page":"Ipopt.jl","title":"IpoptOptimizer Constructor Options","text":"Ipopt-specific options are passed to the IpoptOptimizer constructor. The most commonly used options are available as struct fields:","category":"section"},{"location":"optimization_packages/ipopt/#Termination-Options","page":"Ipopt.jl","title":"Termination Options","text":"acceptable_tol::Float64 = 1e-6: Acceptable convergence tolerance (relative)\nacceptable_iter::Int = 15: Number of acceptable iterations before termination\ndual_inf_tol::Float64 = 1.0: Desired threshold for dual infeasibility\nconstr_viol_tol::Float64 = 1e-4: Desired threshold for constraint violation\ncompl_inf_tol::Float64 = 1e-4: Desired threshold for complementarity conditions","category":"section"},{"location":"optimization_packages/ipopt/#Linear-Solver-Options","page":"Ipopt.jl","title":"Linear Solver Options","text":"linear_solver::String = \"mumps\": Linear solver to use\nDefault: \"mumps\" (included with Ipopt)\nHSL solvers: \"ma27\", \"ma57\", \"ma86\", \"ma97\" (require separate installation)\nOthers: \"pardiso\", \"spral\" (require separate installation)\nlinear_system_scaling::String = \"none\": Method for scaling linear system. Use \"mc19\" for HSL solvers.","category":"section"},{"location":"optimization_packages/ipopt/#NLP-Scaling-Options","page":"Ipopt.jl","title":"NLP Scaling Options","text":"nlp_scaling_method::String = \"gradient-based\": Scaling method for NLP\nOptions: \"none\", \"user-scaling\", \"gradient-based\", \"equilibration-based\"\nnlp_scaling_max_gradient::Float64 = 100.0: Maximum gradient after scaling","category":"section"},{"location":"optimization_packages/ipopt/#Barrier-Parameter-Options","page":"Ipopt.jl","title":"Barrier Parameter Options","text":"mu_strategy::String = \"monotone\": Update strategy for barrier parameter (\"monotone\", \"adaptive\")\nmu_init::Float64 = 0.1: Initial value for barrier parameter\nmu_oracle::String = \"quality-function\": Oracle for adaptive mu strategy","category":"section"},{"location":"optimization_packages/ipopt/#Hessian-Options","page":"Ipopt.jl","title":"Hessian Options","text":"hessian_approximation::String = \"exact\": How to approximate the Hessian\n\"exact\": Use exact Hessian\n\"limited-memory\": Use L-BFGS approximation\nlimited_memory_max_history::Int = 6: History size for L-BFGS\nlimited_memory_update_type::String = \"bfgs\": Quasi-Newton update formula (\"bfgs\", \"sr1\")","category":"section"},{"location":"optimization_packages/ipopt/#Line-Search-Options","page":"Ipopt.jl","title":"Line Search Options","text":"line_search_method::String = \"filter\": Line search method (\"filter\", \"penalty\")\naccept_every_trial_step::String = \"no\": Accept every trial step (disables line search)","category":"section"},{"location":"optimization_packages/ipopt/#Output-Options","page":"Ipopt.jl","title":"Output Options","text":"print_timing_statistics::String = \"no\": Print detailed timing information\nprint_info_string::String = \"no\": Print algorithm info string","category":"section"},{"location":"optimization_packages/ipopt/#Warm-Start-Options","page":"Ipopt.jl","title":"Warm Start Options","text":"warm_start_init_point::String = \"no\": Use warm start from previous solution","category":"section"},{"location":"optimization_packages/ipopt/#Restoration-Phase-Options","page":"Ipopt.jl","title":"Restoration Phase Options","text":"expect_infeasible_problem::String = \"no\": Enable if problem is expected to be infeasible","category":"section"},{"location":"optimization_packages/ipopt/#Additional-Options-Dictionary","page":"Ipopt.jl","title":"Additional Options Dictionary","text":"For Ipopt options not available as struct fields, use the additional_options dictionary:\n\nopt = IpoptOptimizer(\n    linear_solver = \"ma57\",\n    additional_options = Dict(\n        \"derivative_test\" => \"first-order\",\n        \"derivative_test_tol\" => 1e-4,\n        \"fixed_variable_treatment\" => \"make_parameter\",\n        \"alpha_for_y\" => \"primal\"\n    )\n)\n\nThe full list of available options is documented in the Ipopt Options Reference.","category":"section"},{"location":"optimization_packages/ipopt/#Option-Priority","page":"Ipopt.jl","title":"Option Priority","text":"Options follow this priority order (highest to lowest):\n\nCommon interface arguments passed to solve (e.g., reltol, maxiters)\nOptions in additional_options dictionary\nStruct field values in IpoptOptimizer\n\nExample with multiple option sources:\n\nopt = IpoptOptimizer(\n    acceptable_tol = 1e-6,           # Struct field\n    mu_strategy = \"adaptive\",        # Struct field\n    linear_solver = \"ma57\",          # Struct field (needs HSL)\n    print_timing_statistics = \"yes\", # Struct field\n    additional_options = Dict(\n        \"alpha_for_y\" => \"primal\",   # Not a struct field\n        \"max_iter\" => 500            # Will be overridden by maxiters below\n    )\n)\n\nsol = solve(prob, opt;\n    maxiters = 1000,  # Overrides max_iter in additional_options\n    reltol = 1e-8     # Sets Ipopt's tol\n)","category":"section"},{"location":"optimization_packages/ipopt/#Examples","page":"Ipopt.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/ipopt/#Basic-Unconstrained-Optimization","page":"Ipopt.jl","title":"Basic Unconstrained Optimization","text":"The Rosenbrock function can be minimized using IpoptOptimizer:\n\nusing Optimization, OptimizationIpopt\nusing Zygote\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\n\n# Ipopt requires gradient information\noptfunc = OptimizationFunction(rosenbrock, AutoZygote())\nprob = OptimizationProblem(optfunc, x0, p)\nsol = solve(prob, IpoptOptimizer())","category":"section"},{"location":"optimization_packages/ipopt/#Box-Constrained-Optimization","page":"Ipopt.jl","title":"Box-Constrained Optimization","text":"Adding box constraints to limit the search space:\n\nusing Optimization, OptimizationIpopt\nusing Zygote\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\n\noptfunc = OptimizationFunction(rosenbrock, AutoZygote())\nprob = OptimizationProblem(optfunc, x0, p;\n                          lb = [-1.0, -1.0],\n                          ub = [1.5, 1.5])\nsol = solve(prob, IpoptOptimizer())","category":"section"},{"location":"optimization_packages/ipopt/#Nonlinear-Constrained-Optimization","page":"Ipopt.jl","title":"Nonlinear Constrained Optimization","text":"Solving problems with nonlinear equality and inequality constraints:\n\nusing Optimization, OptimizationIpopt\nusing Zygote\n\n# Objective: minimize x[1]^2 + x[2]^2\nobjective(x, p) = x[1]^2 + x[2]^2\n\n# Constraint: x[1]^2 + x[2]^2 - 2*x[1] = 0 (equality)\n# and x[1] + x[2] >= 1 (inequality)\nfunction constraints(res, x, p)\n    res[1] = x[1]^2 + x[2]^2 - 2*x[1]  # equality constraint\n    res[2] = x[1] + x[2]                # inequality constraint\nend\n\nx0 = [0.5, 0.5]\noptfunc = OptimizationFunction(objective, AutoZygote(); cons = constraints)\n\n# First constraint is equality (lcons = ucons = 0)\n# Second constraint is inequality (lcons = 1, ucons = Inf)\nprob = OptimizationProblem(optfunc, x0;\n                          lcons = [0.0, 1.0],\n                          ucons = [0.0, Inf])\n\nsol = solve(prob, IpoptOptimizer())","category":"section"},{"location":"optimization_packages/ipopt/#Using-Limited-Memory-BFGS-Approximation","page":"Ipopt.jl","title":"Using Limited-Memory BFGS Approximation","text":"For large-scale problems where computing the exact Hessian is expensive:\n\nusing Optimization, OptimizationIpopt\nusing Zygote\n\n# Large-scale problem\nn = 100\nrosenbrock_nd(x, p) = sum(p[2] * (x[i+1] - x[i]^2)^2 + (p[1] - x[i])^2 for i in 1:n-1)\n\nx0 = zeros(n)\np = [1.0, 100.0]\n\n# Using automatic differentiation for gradients only\noptfunc = OptimizationFunction(rosenbrock_nd, AutoZygote())\nprob = OptimizationProblem(optfunc, x0, p)\n\n# Use L-BFGS approximation for Hessian\nsol = solve(prob, IpoptOptimizer(\n           hessian_approximation = \"limited-memory\",\n           limited_memory_max_history = 10);\n           maxiters = 1000)","category":"section"},{"location":"optimization_packages/ipopt/#Portfolio-Optimization-Example","page":"Ipopt.jl","title":"Portfolio Optimization Example","text":"A practical example of portfolio optimization with constraints:\n\nusing Optimization, OptimizationIpopt\nusing Zygote\nusing LinearAlgebra\n\n# Portfolio optimization: minimize risk subject to return constraint\nn_assets = 5\nμ = [0.05, 0.10, 0.15, 0.08, 0.12]  # Expected returns\nΣ = [0.05 0.01 0.02 0.01 0.00;      # Covariance matrix\n     0.01 0.10 0.03 0.02 0.01;\n     0.02 0.03 0.15 0.02 0.03;\n     0.01 0.02 0.02 0.08 0.02;\n     0.00 0.01 0.03 0.02 0.06]\n\ntarget_return = 0.10\n\n# Objective: minimize portfolio variance\nportfolio_risk(w, p) = dot(w, Σ * w)\n\n# Constraints: sum of weights = 1, expected return >= target\nfunction portfolio_constraints(res, w, p)\n    res[1] = sum(w) - 1.0                    # Sum to 1 (equality)\n    res[2] = dot(μ, w) - target_return       # Minimum return (inequality)\nend\n\noptfunc = OptimizationFunction(portfolio_risk, AutoZygote();\n                              cons = portfolio_constraints)\nw0 = fill(1.0/n_assets, n_assets)\n\nprob = OptimizationProblem(optfunc, w0;\n                          lb = zeros(n_assets),     # No short selling\n                          ub = ones(n_assets),      # No single asset > 100%\n                          lcons = [0.0, 0.0],       # Equality and inequality constraints\n                          ucons = [0.0, Inf])\n\nsol = solve(prob, IpoptOptimizer();\n           reltol = 1e-8,\n           verbose = 5)\n\nprintln(\"Optimal weights: \", sol.u)\nprintln(\"Expected return: \", dot(μ, sol.u))\nprintln(\"Portfolio variance: \", sol.objective)","category":"section"},{"location":"optimization_packages/ipopt/#Tips-and-Best-Practices","page":"Ipopt.jl","title":"Tips and Best Practices","text":"Scaling: Ipopt performs better when variables and constraints are well-scaled. Consider normalizing your problem if variables have very different magnitudes.\nInitial Points: Provide good initial guesses when possible. Ipopt is a local optimizer and the solution quality depends on the starting point.\nHessian Approximation: For large problems or when Hessian computation is expensive, use hessian_approximation = \"limited-memory\" in the IpoptOptimizer constructor.\nLinear Solver Selection: The choice of linear solver can significantly impact performance. For large problems, consider using HSL solvers (ma27, ma57, ma86, ma97). Note that HSL solvers require separate installation - see the Ipopt.jl documentation for setup instructions. The default MUMPS solver works well for small to medium problems.\nConstraint Formulation: Ipopt handles equality constraints well. When possible, formulate constraints as equalities rather than pairs of inequalities.\nWarm Starting: When solving a sequence of similar problems, use the solution from the previous problem as the initial point for the next. You can enable warm starting with IpoptOptimizer(warm_start_init_point = \"yes\").","category":"section"},{"location":"optimization_packages/ipopt/#References","page":"Ipopt.jl","title":"References","text":"For more detailed information about Ipopt's algorithms and options, consult:\n\nIpopt Documentation\nIpopt Options Reference\nIpopt Implementation Paper","category":"section"},{"location":"optimization_packages/nlopt/#NLopt.jl","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt is Julia package interfacing to the free/open-source NLopt library which implements many optimization methods both global and local NLopt Documentation.","category":"section"},{"location":"optimization_packages/nlopt/#Installation:-OptimizationNLopt.jl","page":"NLopt.jl","title":"Installation: OptimizationNLopt.jl","text":"To use this package, install the OptimizationNLopt package:\n\nimport Pkg;\nPkg.add(\"OptimizationNLopt\");","category":"section"},{"location":"optimization_packages/nlopt/#Methods","page":"NLopt.jl","title":"Methods","text":"NLopt.jl algorithms are chosen either via NLopt.Opt(:algname, nstates) where nstates is the number of states to be optimized, but preferably via NLopt.AlgorithmName() where `AlgorithmName can be one of the following:\n\nNLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.LD_LBFGS()\nNLopt.LN_PRAXIS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.LD_MMA()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LD_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LN_BOBYQA()\nNLopt.GN_ISRES()\nNLopt.AUGLAG()\nNLopt.AUGLAG_EQ()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()\nNLopt.GN_ESCH()\nNLopt.GN_AGS()\n\nSee the NLopt Documentation for more details on each optimizer.\n\nBeyond the common arguments, the following optimizer parameters can be set as kwargs:\n\nstopval\nxtol_rel\nxtol_abs\nconstrtol_abs\ninitial_step\npopulation\nvector_storage","category":"section"},{"location":"optimization_packages/nlopt/#Local-Optimizer","page":"NLopt.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Derivative-Free","page":"NLopt.jl","title":"Derivative-Free","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the OptimizationProblem.\n\nNLopt derivative-free optimizers are:\n\nNLopt.LN_PRAXIS()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LN_BOBYQA()\n\nThe Rosenbrock function can be optimized using the NLopt.LN_NELDERMEAD() as follows:\n\nusing Optimization\nusing OptimizationNLopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.LN_NELDERMEAD())","category":"section"},{"location":"optimization_packages/nlopt/#Gradient-Based","page":"NLopt.jl","title":"Gradient-Based","text":"Gradient-based optimizers are optimizers which utilize the gradient information based on derivatives defined or automatic differentiation.\n\nNLopt gradient-based optimizers are:\n\nNLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.LD_MMA()\nNLopt.LD_AUGLAG()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()\n\nThe Rosenbrock function can be optimized using NLopt.LD_LBFGS() as follows:\n\nusing Optimization, OptimizationNLopt, ADTypes, ForwardDiff\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.LD_LBFGS())","category":"section"},{"location":"optimization_packages/nlopt/#Global-Optimizer","page":"NLopt.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Without-Constraint-Equations","page":"NLopt.jl","title":"Without Constraint Equations","text":"The following algorithms in NLopt are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.\n\nNLopt global optimizers which fall into this category are:\n\nNLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.GN_ESCH()\n\nThe Rosenbrock function can be optimized using NLopt.GN_DIRECT() as follows:\n\nusing Optimization, OptimizationNLopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.GN_DIRECT(), maxtime = 10.0)\n\nAlgorithms such as NLopt.G_MLSL() or NLopt.G_MLSL_LDS() also require a local optimizer to be selected, which via the local_method argument of solve.\n\nThe Rosenbrock function can be optimized using NLopt.G_MLSL_LDS() with NLopt.LN_NELDERMEAD() as the local optimizer. The local optimizer maximum iterations are set via local_maxiters:\n\nusing Optimization, OptimizationNLopt, ADTypes, ForwardDiff\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.G_MLSL_LDS(), local_method = NLopt.LD_LBFGS(), maxtime = 10.0,\n    local_maxiters = 10)","category":"section"},{"location":"optimization_packages/nlopt/#With-Constraint-Equations","page":"NLopt.jl","title":"With Constraint Equations","text":"The following algorithms in NLopt are performing global optimization on problems with constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.\n\nnote: Constraints with NLopt\n\n\nEquality and inequality equation support for NLopt via Optimization is not supported directly. However, you can use the MOI wrapper to use constraints with NLopt optimizers.\n\nNLopt global optimizers which fall into this category are:\n\nNLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GN_ISRES()\nNLopt.GN_AGS()","category":"section"},{"location":"API/solve/#Common-Solver-Options-(Solve-Keyword-Arguments)","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"","category":"section"},{"location":"API/solve/#CommonSolve.solve-Tuple{OptimizationProblem, Any}","page":"Common Solver Options (Solve Keyword Arguments)","title":"CommonSolve.solve","text":"solve(prob::OptimizationProblem, alg::AbstractOptimizationAlgorithm,\n    args...; kwargs...)::OptimizationSolution\n\nFor information about the returned solution object, refer to the documentation for OptimizationSolution\n\nKeyword Arguments\n\nThe arguments to solve are common across all of the optimizers. These common arguments are:\n\nmaxiters: the maximum number of iterations\nmaxtime: the maximum amount of time (typically in seconds) the optimization runs for\nabstol: absolute tolerance in changes of the objective value\nreltol: relative tolerance  in changes of the objective value\ncallback: a callback function\n\nSome optimizer algorithms have special keyword arguments documented in the solver portion of the documentation and their respective documentation. These arguments can be passed as kwargs... to solve. Similarly, the special keyword arguments for the local_method of a global optimizer are passed as a NamedTuple to local_options.\n\nOver time, we hope to cover more of these keyword arguments under the common interface.\n\nA warning will be shown if a common argument is not implemented for an optimizer.\n\nCallback Functions\n\nThe callback function callback is a function that is called after every optimizer step. Its signature is:\n\ncallback = (state, loss_val) -> false\n\nwhere state is an OptimizationState and stores information for the current iteration of the solver and loss_val is loss/objective value. For more information about the fields of the state look at the OptimizationState documentation. The callback should return a Boolean value, and the default should be false, so the optimization stops if it returns true.\n\nCallback Example\n\nHere we show an example of a callback function that plots the prediction at the current value of the optimization variables. For a visualization callback, we would need the prediction at the current parameters i.e. the solution of the ODEProblem prob. So we call the predict function within the callback again.\n\nfunction predict(u)\n    Array(solve(prob, Tsit5(), p = u))\nend\n\nfunction loss(u, p)\n    pred = predict(u)\n    sum(abs2, batch .- pred)\nend\n\ncallback = function (state, l; doplot = false) #callback function to observe training\n    display(l)\n    # plot current prediction against data\n    if doplot\n        pred = predict(state.u)\n        pl = scatter(t, ode_data[1, :], label = \"data\")\n        scatter!(pl, t, pred[1, :], label = \"prediction\")\n        display(plot(pl))\n    end\n    return false\nend\n\nIf the chosen method is a global optimizer that employs a local optimization method, a similar set of common local optimizer arguments exists. Look at MLSL or AUGLAG from NLopt for an example. The common local optimizer arguments are:\n\nlocal_method: optimizer used for local optimization in global method\nlocal_maxiters: the maximum number of iterations\nlocal_maxtime: the maximum amount of time (in seconds) the optimization runs for\nlocal_abstol: absolute tolerance in changes of the objective value\nlocal_reltol: relative tolerance  in changes of the objective value\nlocal_options: NamedTuple of keyword arguments for local optimizer\n\n\n\n\n\n","category":"method"},{"location":"optimization_packages/optim/#optim","page":"Optim.jl","title":"Optim.jl","text":"Optim is Julia package implementing various algorithms to perform univariate and multivariate optimization.","category":"section"},{"location":"optimization_packages/optim/#Installation:-OptimizationOptimJL.jl","page":"Optim.jl","title":"Installation: OptimizationOptimJL.jl","text":"To use this package, install the OptimizationOptimJL package:\n\nimport Pkg;\nPkg.add(\"OptimizationOptimJL\");","category":"section"},{"location":"optimization_packages/optim/#Methods","page":"Optim.jl","title":"Methods","text":"Optim.jl algorithms can be one of the following:\n\nOptim.NelderMead()\nOptim.SimulatedAnnealing()\nOptim.ParticleSwarm()\nOptim.ConjugateGradient()\nOptim.GradientDescent()\nOptim.BFGS()\nOptim.LBFGS()\nOptim.NGMRES()\nOptim.OACCEL()\nOptim.NewtonTrustRegion()\nOptim.Newton()\nOptim.KrylovTrustRegion()\nOptim.ParticleSwarm()\nOptim.SAMIN()\n\nEach optimizer also takes special arguments which are outlined in the sections below.\n\nThe following special keyword arguments which are not covered by the common solve arguments can be used with Optim.jl optimizers:\n\nx_tol: Absolute tolerance in changes of the input vector x, in infinity norm. Defaults to 0.0.\ng_tol: Absolute tolerance in the gradient, in infinity norm. Defaults to 1e-8. For gradient free methods, this will control the main convergence tolerance, which is solver-specific.\nf_calls_limit: A soft upper limit on the number of objective calls. Defaults to 0 (unlimited).\ng_calls_limit: A soft upper limit on the number of gradient calls. Defaults to 0 (unlimited).\nh_calls_limit: A soft upper limit on the number of Hessian calls. Defaults to 0 (unlimited).\nallow_f_increases: Allow steps that increase the objective value. Defaults to false. Note that, when setting this to true, the last iterate will be returned as the minimizer even if the objective increased.\nstore_trace: Should a trace of the optimization algorithm's state be stored? Defaults to false.\nshow_trace: Should a trace of the optimization algorithm's state be shown on stdout? Defaults to false.\nextended_trace: Save additional information. Solver dependent. Defaults to false.\ntrace_simplex: Include the full simplex in the trace for NelderMead. Defaults to false.\nshow_every: Trace output is printed every show_everyth iteration.\n\nFor a more extensive documentation of all the algorithms and options, please consult the Documentation","category":"section"},{"location":"optimization_packages/optim/#Local-Optimizer","page":"Optim.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Local-Constraint","page":"Optim.jl","title":"Local Constraint","text":"Optim.jl implements the following local constraint algorithms:\n\nOptim.IPNewton()\nμ0 specifies the initial barrier penalty coefficient as either a number or :auto\nshow_linesearch is an option to turn on linesearch verbosity.\nDefaults:\nlinesearch::Function = Optim.backtrack_constrained_grad\nμ0::Union{Symbol,Number} = :auto\nshow_linesearch::Bool = false\n\nThe Rosenbrock function with constraints can be optimized using the Optim.IPNewton() as follows:\n\nusing Optimization, OptimizationOptimJL, ADTypes, ForwardDiff\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\ncons = (res, x, p) -> res .= [x[1]^2 + x[2]^2]\nx0 = zeros(2)\np = [1.0, 100.0]\nprob = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff(); cons = cons)\nprob = SciMLBase.OptimizationProblem(prob, x0, p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton())\n\nSee also in the Optim.jl documentation the Nonlinear constrained optimization example using IPNewton.","category":"section"},{"location":"optimization_packages/optim/#Derivative-Free","page":"Optim.jl","title":"Derivative-Free","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the SciMLBase.OptimizationProblem.\n\nOptim.jl implements the following derivative-free algorithms:\n\nOptim.NelderMead(): Nelder-Mead optimizer\nsolve(problem, NelderMead(parameters, initial_simplex))\nparameters = AdaptiveParameters() or parameters = FixedParameters()\ninitial_simplex = AffineSimplexer()\nDefaults:\nparameters = AdaptiveParameters()\ninitial_simplex = AffineSimplexer()\nOptim.SimulatedAnnealing(): Simulated Annealing\nsolve(problem, SimulatedAnnealing(neighbor, T, p))\nneighbor is a mutating function of the current and proposed x\nT is a function of the current iteration that returns a temperature\np is a function of the current temperature\nDefaults:\nneighbor = default_neighbor!\nT = default_temperature\np = kirkpatrick\nOptim.ParticleSwarm()\n\nThe Rosenbrock function can be optimized using the Optim.NelderMead() as follows:\n\nusing Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nprob = SciMLBase.OptimizationProblem(rosenbrock, x0, p)\nsol = solve(prob, Optim.NelderMead())","category":"section"},{"location":"optimization_packages/optim/#Gradient-Based","page":"Optim.jl","title":"Gradient-Based","text":"Gradient-based optimizers are optimizers which utilize the gradient information based on derivatives defined or automatic differentiation.\n\nOptim.jl implements the following gradient-based algorithms:\n\nOptim.ConjugateGradient(): Conjugate Gradient Descent\nsolve(problem, ConjugateGradient(alphaguess, linesearch, eta, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\neta determines the next step direction\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialHagerZhang()\nlinesearch = LineSearches.HagerZhang()\neta = 0.4\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.GradientDescent(): Gradient Descent (a quasi-Newton solver)\nsolve(problem, GradientDescent(alphaguess, linesearch, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialPrevious()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.BFGS(): Broyden-Fletcher-Goldfarb-Shanno algorithm\nsolve(problem, BFGS(alphaguess, linesearch, initial_invH, initial_stepnorm, manifold))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\ninitial_invH specifies an optional initial matrix\ninitial_stepnorm determines that initial_invH is an identity matrix scaled by the value of initial_stepnorm multiplied by the sup-norm of the gradient at the initial point\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\ninitial_invH = nothing\ninitial_stepnorm = nothing\nmanifold = Flat()\nOptim.LBFGS(): Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm\nm is the number of history points\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nscaleinvH0: whether to scale the initial Hessian approximation\nDefaults:\nm = 10\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nmanifold = Flat()\nscaleinvH0::Bool = true && (P isa Nothing)\nOptim.NGMRES()\nOptim.OACCEL()\n\nThe Rosenbrock function can be optimized using the Optim.LBFGS() as follows:\n\nusing Optimization, OptimizationOptimJL, ADTypes, ForwardDiff\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\noptprob = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(optprob, x0, p, lb = [-1.0, -1.0], ub = [0.8, 0.8])\nsol = solve(prob, Optim.LBFGS())","category":"section"},{"location":"optimization_packages/optim/#Hessian-Based-Second-Order","page":"Optim.jl","title":"Hessian-Based Second Order","text":"Hessian-based optimization methods are second order optimization methods which use the direct computation of the Hessian. These can converge faster, but require fast and accurate methods for calculating the Hessian in order to be appropriate.\n\nOptim.jl implements the following hessian-based algorithms:\n\nOptim.NewtonTrustRegion(): Newton Trust Region method\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75\nOptim.Newton(): Newton's method with line search\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\n\nThe Rosenbrock function can be optimized using the Optim.Newton() as follows:\n\nusing Optimization, OptimizationOptimJL, ADTypes, ModelingToolkit, Symbolics\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, ADTypes.AutoSymbolics())\nprob = SciMLBase.OptimizationProblem(f, x0, p)\nsol = solve(prob, Optim.Newton())","category":"section"},{"location":"optimization_packages/optim/#Hessian-Free-Second-Order","page":"Optim.jl","title":"Hessian-Free Second Order","text":"Hessian-free methods are methods which perform second order optimization by direct computation of Hessian-vector products (Hv) without requiring the construction of the full Hessian. As such, these methods can perform well for large second order optimization problems, but can require special case when considering conditioning of the Hessian.\n\nOptim.jl implements the following hessian-free algorithms:\n\nOptim.KrylovTrustRegion(): A Newton-Krylov method with Trust Regions\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75\n\nThe Rosenbrock function can be optimized using the Optim.KrylovTrustRegion() as follows:\n\nusing Optimization, OptimizationOptimJL, ADTypes, ForwardDiff\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\noptprob = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(optprob, x0, p)\nsol = solve(prob, Optim.KrylovTrustRegion())","category":"section"},{"location":"optimization_packages/optim/#Global-Optimizer","page":"Optim.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Without-Constraint-Equations","page":"Optim.jl","title":"Without Constraint Equations","text":"The following method in Optim performs global optimization on problems with or without box constraints. It works both with and without lower and upper bounds set by lb and ub in the SciMLBase.OptimizationProblem.\n\nOptim.ParticleSwarm(): Particle Swarm Optimization\nsolve(problem, ParticleSwarm(lower, upper, n_particles))\nlower/upper are vectors of lower/upper bounds respectively\nn_particles is the number of particles in the swarm\ndefaults to: lower = [], upper = [], n_particles = 0\n\nThe Rosenbrock function can be optimized using the Optim.ParticleSwarm() as follows:\n\nusing Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, Optim.ParticleSwarm(lower = prob.lb, upper = prob.ub, n_particles = 100))","category":"section"},{"location":"optimization_packages/optim/#With-Constraint-Equations","page":"Optim.jl","title":"With Constraint Equations","text":"The following method in Optim performs global optimization on problems with box constraints.\n\nOptim.SAMIN(): Simulated Annealing with bounds\nsolve(problem, SAMIN(nt, ns, rt, neps, f_tol, x_tol, coverage_ok, verbosity))\nDefaults:\nnt = 5\nns = 5\nrt = 0.9\nneps = 5\nf_tol = 1e-12\nx_tol = 1e-6\ncoverage_ok = false\nverbosity = 0\n\nThe Rosenbrock function can be optimized using the Optim.SAMIN() as follows:\n\nusing Optimization, OptimizationOptimJL, ADTypes, ForwardDiff\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, Optim.SAMIN())","category":"section"},{"location":"optimization_packages/sophia/#OptimizationSophia.jl","page":"OptimizationSophia.jl","title":"OptimizationSophia.jl","text":"OptimizationSophia.jl is a package that provides the Sophia optimizer for neural network training.","category":"section"},{"location":"optimization_packages/sophia/#Installation","page":"OptimizationSophia.jl","title":"Installation","text":"To use this package, install the OptimizationSophia package:\n\nusing Pkg\nPkg.add(\"OptimizationSophia\")","category":"section"},{"location":"optimization_packages/sophia/#Methods","page":"OptimizationSophia.jl","title":"Methods","text":"","category":"section"},{"location":"optimization_packages/sophia/#Examples","page":"OptimizationSophia.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/sophia/#Train-NN-with-Sophia","page":"OptimizationSophia.jl","title":"Train NN with Sophia","text":"using OptimizationBase, OptimizationSophia, Lux, ADTypes, Zygote, MLUtils, Statistics, Random, ComponentArrays\n\nx = rand(10000)\ny = sin.(x)\ndata = MLUtils.DataLoader((x, y), batchsize = 100)\n\n# Define the neural network\nmodel = Chain(Dense(1, 32, tanh), Dense(32, 1))\nps, st = Lux.setup(Random.default_rng(), model)\nps_ca = ComponentArray(ps)\nsmodel = StatefulLuxLayer{true}(model, nothing, st)\n\nfunction callback(state, l)\n    state.iter % 25 == 1 && @show \"Iteration: $(state.iter), Loss: $l\"\n    return l < 1e-1 ## Terminate if loss is small\nend\n\nfunction loss(ps, data)\n    x_batch, y_batch = data\n    ypred = [smodel([x_batch[i]], ps)[1] for i in eachindex(x_batch)]\n    return sum(abs2, ypred .- y_batch)\nend\n\noptf = OptimizationFunction(loss, ADTypes.AutoZygote())\nprob = OptimizationProblem(optf, ps_ca, data)\n\nres = solve(prob, OptimizationSophia.Sophia(), callback = callback, epochs = 100)","category":"section"},{"location":"optimization_packages/sophia/#OptimizationSophia.Sophia","page":"OptimizationSophia.jl","title":"OptimizationSophia.Sophia","text":"Sophia(; η = 1e-3, βs = (0.9, 0.999), ϵ = 1e-8, λ = 1e-1, k = 10, ρ = 0.04)\n\nA second-order optimizer that incorporates diagonal Hessian information for faster convergence.\n\nBased on the paper \"Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training\" (https://arxiv.org/abs/2305.14342). Sophia uses an efficient estimate of the diagonal of the Hessian matrix to adaptively adjust the learning rate for each parameter, achieving faster convergence than first-order methods like Adam and SGD while avoiding the computational cost of full second-order methods.\n\nArguments\n\nη::Float64 = 1e-3: Learning rate (step size)\nβs::Tuple{Float64, Float64} = (0.9, 0.999): Exponential decay rates for the first moment (β₁) and diagonal Hessian (β₂) estimates\nϵ::Float64 = 1e-8: Small constant for numerical stability\nλ::Float64 = 1e-1: Weight decay coefficient for L2 regularization\nk::Integer = 10: Frequency of Hessian diagonal estimation (every k iterations)\nρ::Float64 = 0.04: Clipping threshold for the update to maintain stability\n\nExample\n\nusing OptimizationBase, OptimizationSophia\n\n# Define optimization problem\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\noptf = OptimizationFunction(rosenbrock, OptimizationBase.AutoZygote())\nprob = OptimizationProblem(optf, x0)\n\n# Solve with Sophia\nsol = solve(prob, Sophia(η = 0.01, k = 5))\n\nNotes\n\nSophia is particularly effective for:\n\nLarge-scale optimization problems\nNeural network training\nProblems where second-order information can significantly improve convergence\n\nThe algorithm maintains computational efficiency by only estimating the diagonal of the Hessian matrix using a Hutchinson trace estimator with random vectors, making it more scalable than full second-order methods while still leveraging curvature information.\n\n\n\n\n\n","category":"type"},{"location":"API/optimization_stats/#optstats","page":"OptimizationStats","title":"OptimizationStats","text":"","category":"section"},{"location":"API/optimization_stats/#SciMLBase.OptimizationStats","page":"OptimizationStats","title":"SciMLBase.OptimizationStats","text":"struct OptimizationStats\n\nStores the optimization run's statistics that is returned in the stats field of the OptimizationResult.\n\nFields\n\niterations: number of iterations\ntime: time taken to run the solver\nfevals: number of function evaluations\ngevals: number of gradient evaluations\nhevals: number of hessian evaluations\n\nDefault values for all the field are set to 0 and hence even when you might expect non-zero values due to unavilability of the information from the solver it would be 0.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/nomad/#NOMAD.jl","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD is Julia package interfacing to NOMAD, which is a C++ implementation of the Mesh Adaptive Direct Search algorithm (MADS), designed for difficult blackbox optimization problems. These issues occur when the functions defining the objective and constraints are the result of costly computer simulations. NOMAD.jl documentation\n\nThe NOMAD algorithm is called by NOMADOpt()","category":"section"},{"location":"optimization_packages/nomad/#Installation:-OptimizationNOMAD.jl","page":"NOMAD.jl","title":"Installation: OptimizationNOMAD.jl","text":"To use this package, install the OptimizationNOMAD package:\n\nimport Pkg;\nPkg.add(\"OptimizationNOMAD\");","category":"section"},{"location":"optimization_packages/nomad/#Global-Optimizer","page":"NOMAD.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nomad/#Without-Constraint-Equations","page":"NOMAD.jl","title":"Without Constraint Equations","text":"The method in NOMAD is performing global optimization on problems both with and without constraint equations. However, linear and nonlinear constraints defined in Optimization are currently not passed.\n\nNOMAD works both with and without lower and upper box-constraints set by lb and ub in the OptimizationProblem.","category":"section"},{"location":"optimization_packages/nomad/#Examples","page":"NOMAD.jl","title":"Examples","text":"The Rosenbrock function can be optimized using the NOMADOpt() with and without box-constraints as follows:\n\nusing Optimization, OptimizationNOMAD\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\n\nprob = OptimizationProblem(f, x0, p)\nsol = Optimization.solve(prob, NOMADOpt())\n\nprob = OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.5, 1.5])\nsol = Optimization.solve(prob, NOMADOpt())","category":"section"},{"location":"tutorials/symbolic/#Symbolic-Problem-Building-with-ModelingToolkit","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"note: Note\nThis example uses the OptimizationOptimJL.jl package. See the Optim.jl page for details on the installation and usage.\n\nModelingToolkit.jl is a comprehensive system for symbolic modeling in Julia. Allows for doing many manipulations before the solver phase, such as detecting sparsity patterns, analytically solving parts of the model to reduce the solving complexity, and more. One of the types of system types that it supports is OptimizationSystem, i.e., the symbolic counterpart to OptimizationProblem. Let's demonstrate how to use the OptimizationSystem to construct optimized OptimizationProblems.\n\nFirst we need to start by defining our symbolic variables, this is done as follows:\n\nusing ModelingToolkit, OptimizationBase, OptimizationOptimJL\n\n@variables x y\n@parameters a b\n\nWe can now construct the OptimizationSystem by building a symbolic expression for the loss function:\n\nloss = (a - x)^2 + b * (y - x^2)^2\n@named sys = OptimizationSystem(loss, [x, y], [a, b])\n\nTo turn it into a problem for numerical solutions, we need to specify what our parameter values are and the initial conditions. This looks like:\n\nu0 = [x => 1.0\n      y => 2.0]\np = [a => 6.0\n     b => 7.0]\n\nAnd now we solve.\n\nsys = complete(sys)\nprob = OptimizationProblem(sys, u0, p, grad = true, hess = true)\nsolve(prob, Newton())\n\nIt provides many other features like auto-parallelism and sparsification too. Plus, you can hierarchically nest systems to generate huge optimization problems. Check out the ModelingToolkit.jl OptimizationSystem documentation for more information.","category":"section"},{"location":"API/modelingtoolkit/#ModelingToolkit-Integration","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Optimization.jl is heavily integrated with the ModelingToolkit.jl symbolic system for symbolic-numeric optimizations. It provides a front-end for automating the construction, parallelization, and optimization of code. Optimizers can better interface with the extra symbolic information provided by the system.\n\nThere are two ways that the user interacts with ModelingToolkit.jl. One can use OptimizationFunction with AutoSymbolics for automatically transforming numerical codes into symbolic codes. See the OptimizationFunction documentation for more details.\n\nSecondly, one can generate OptimizationProblems for use in Optimization.jl from purely a symbolic front-end. This is the form users will encounter when using ModelingToolkit.jl directly, and it is also the form supplied by domain-specific languages. For more information, see the OptimizationSystem documentation.","category":"section"},{"location":"optimization_packages/optimisers/#optimisers","page":"Optimisers.jl","title":"Optimisers.jl","text":"","category":"section"},{"location":"optimization_packages/optimisers/#Installation:-OptimizationOptimisers.jl","page":"Optimisers.jl","title":"Installation: OptimizationOptimisers.jl","text":"To use this package, install the OptimizationOptimisers package:\n\nimport Pkg;\nPkg.add(\"OptimizationOptimisers\");\n\nIn addition to the optimisation algorithms provided by the Optimisers.jl package this subpackage also provides the Sophia optimisation algorithm.","category":"section"},{"location":"optimization_packages/optimisers/#List-of-optimizers","page":"Optimisers.jl","title":"List of optimizers","text":"Optimisers.Descent: Classic gradient descent optimizer with learning rate\nsolve(problem, Descent(η))\nη is the learning rate\nDefaults:\nη = 0.1\nOptimisers.Momentum: Classic gradient descent optimizer with learning rate and momentum\nsolve(problem, Momentum(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.01\nρ = 0.9\nOptimisers.Nesterov: Gradient descent optimizer with learning rate and Nesterov momentum\nsolve(problem, Nesterov(η, ρ))\nη is the learning rate\nρ is the Nesterov momentum\nDefaults:\nη = 0.01\nρ = 0.9\nOptimisers.RMSProp: RMSProp optimizer\nsolve(problem, RMSProp(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.001\nρ = 0.9\nOptimisers.Adam: Adam optimizer\nsolve(problem, Adam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.RAdam: Rectified Adam optimizer\nsolve(problem, RAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.OAdam: Optimistic Adam optimizer\nsolve(problem, OAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.5, 0.999)\nOptimisers.AdaMax: AdaMax optimizer\nsolve(problem, AdaMax(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.ADAGrad: ADAGrad optimizer\nsolve(problem, ADAGrad(η))\nη is the learning rate\nDefaults:\nη = 0.1\nOptimisers.ADADelta: ADADelta optimizer\nsolve(problem, ADADelta(ρ))\nρ is the gradient decay factor\nDefaults:\nρ = 0.9\nOptimisers.AMSGrad: AMSGrad optimizer\nsolve(problem, AMSGrad(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.NAdam: Nesterov variant of the Adam optimizer\nsolve(problem, NAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.AdamW: AdamW optimizer\nsolve(problem, AdamW(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndecay is the decay to weights\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\ndecay = 0\nOptimisers.ADABelief: ADABelief variant of Adam\nsolve(problem, ADABelief(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)","category":"section"},{"location":"API/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"API/FAQ/#The-Solver-Seems-to-Violate-Constraints-During-the-Optimization,-Causing-DomainErrors,-What-Can-I-Do-About-That?","page":"Frequently Asked Questions","title":"The Solver Seems to Violate Constraints During the Optimization, Causing DomainErrors, What Can I Do About That?","text":"During the optimization, optimizers use slack variables to relax the solution to the constraints. Because of this, there is no guarantee that for an arbitrary optimizer the steps will all satisfy the constraints during the optimization. In many cases, this can cause one's objective function code throw a DomainError if it is evaluated outside of its acceptable zone. For example, log(-1) gives:\n\njulia> log(-1)\nERROR: DomainError with -1.0:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).\n\nTo handle this, one should not assume that the variables will always satisfy the constraints on each step. There are three general ways to handle this better:\n\nUse NaNMath.jl\nProcess variables before domain-restricted calls\nUse a domain transformation\n\nNaNMath.jl gives alternative implementations of standard math functions like log and sqrt in forms that do not throw DomainErrors but rather return NaNs. The optimizers will be able to handle the NaNs gracefully and recover, allowing for many of these cases to be solved without further modification. Note that this is done internally in JuMP.jl, and thus if a case is working with JuMP and not Optimization.jl  this may be the reason for the difference.\n\nAlternatively, one can pre-process the values directly. For example, log(abs(x)) is guaranteed to work. If one does this, there are two things to make note of. One is that the solution will not be transformed, and thus the transformation should be applied on sol.u as well. For example, the solution could find an optima for x = -2, and one should manually change this to x = 2 if the abs version is used within the objective function. Note that many functions for this will introduce a discontinuity in the derivative which can affect the optimization process.\n\nFinally and relatedly, one can write the optimization with domain transformations in order to allow the optimization to take place in the full real set. For example, instead of optimizing x in [0,Inf], one can optimize exp(x) in [0,Inf] and thus x in [-Inf, Inf] is allowed without any bounds. To do this, you would simply add the transformations to the top of the objective function:\n\nfunction my_objective(u)\n    x = exp(u[1])\n    # ... use x\nend\n\nWhen the optimization is done, sol.u[1] will be exp(x) and thus log(sol.u[1]) will be the optimal value for x. There exist packages in the Julia ecosystem which make it easier to keep track of these domain transformations and their inverses for more general domains. See TransformVariables.jl and Bijectors.jl for high level interfaces for this.\n\nWhile this can allow an optimization with constraints to be rewritten as one without constraints, note that this can change the numerical properties of the solve which can either improve or decrease the numerical stability in a case-by-case basis. Thus while a solution, one should be aware that it could make the optimization more difficult in some cases.","category":"section"},{"location":"API/FAQ/#What-are-the-advantages-and-disadvantages-of-using-the-ModelingToolkit.jl-or-other-symbolic-interfaces-(JuMP)?","page":"Frequently Asked Questions","title":"What are the advantages and disadvantages of using the ModelingToolkit.jl or other symbolic interfaces (JuMP)?","text":"The purely numerical function interfaces of Optimization.jl has its pros and cons. The major pro of the direct Optimization.jl interface is that it can take arbitrary Julia programs. If you have an optimization defined over a program, like a Neural ODE or something that calls out to web servers, then these advanced setups rarely work within specialized symbolic environments for optimization. Direct usage of Optimization.jl is thus the preferred route for this kind of problem, and is the popular choice in the Julia ecosystem for these cases due to the simplicity of use.\n\nHowever, symbolic interfaces are smart, and they may know more than you for how to make this optimization faster. And symbolic interfaces are willing to do \"tedious work\" in order to make the optimization more efficient. For example, the ModelingToolkit integration with Optimization.jl will do many simplifications when structural_simplify is called. One of them is tearing on the constraints. To understand the tearing process, assume that we had nonlinear constraints of the form:\n\n    0 ~ u1 - sin(u5) * h,\n    0 ~ u2 - cos(u1),\n    0 ~ u3 - hypot(u1, u2),\n    0 ~ u4 - hypot(u2, u3),\n\nIf these were the constraints, one can write u1 = sin(u5) * h and substitute u1 for this value in the objective function. If this is done, then u1 does not need to be solved for, the optimization has one less state variable and one less constraint. One can continue this process all the way to a bunch of functions:\n\nu1 = f1(u5)\nu2 = f2(u1)\nu3 = f3(u1, u2)\nu4 = f4(u2, u3)\n\nand thus if the objective function was the function of these 5 variables and 4 constraints, ModelingToolkit.jl will transform it into system of 1 variable with no constraints, allowing unconstrained optimization on a smaller system. This will both be faster and numerically easier.\n\nJuMP.jl is another symbolic interface. While it does not include these tearing and symbolic simplification passes, it does include the ability to specialize the solution process. For example, it can treat linear optimization problems, quadratic optimization problem, convex optimization problems, etc. in specific ways that are more efficient than a general nonlinear interface. For more information on the types of special solves that are allowed with JuMP, see this page.","category":"section"},{"location":"optimization_packages/manopt/#Manopt.jl","page":"Manopt.jl","title":"Manopt.jl","text":"Manopt.jl is a package providing solvers for optimization problems defined on Riemannian manifolds. The implementation is based on ManifoldsBase.jl interface and can hence be used for all maniolds defined in Manifolds or any other manifold implemented using the interface.","category":"section"},{"location":"optimization_packages/manopt/#Installation:-OptimizationManopt.jl","page":"Manopt.jl","title":"Installation: OptimizationManopt.jl","text":"To use the Optimization.jl interface to Manopt, install the OptimizationManopt package:\n\nimport Pkg;\nPkg.add(\"OptimizationManopt\");","category":"section"},{"location":"optimization_packages/manopt/#Methods","page":"Manopt.jl","title":"Methods","text":"The following methods are available for the OptimizationManopt package:\n\nGradientDescentOptimizer: Corresponds to the gradient_descent method in Manopt.\nNelderMeadOptimizer : Corresponds to the NelderMead method in Manopt.\nConjugateGradientDescentOptimizer: Corresponds to the conjugate_gradient_descent method in Manopt.\nParticleSwarmOptimizer: Corresponds to the particle_swarm method in Manopt.\nQuasiNewtonOptimizer: Corresponds to the quasi_Newton method in Manopt.\nCMAESOptimizer: Corresponds to the cma_es method in Manopt.\nConvexBundleOptimizer: Corresponds to the convex_bundle_method method in Manopt.\nFrankWolfeOptimizer: Corresponds to the FrankWolfe method in Manopt.\n\nThe common kwargs maxiters, maxtime and abstol are supported by all the optimizers. Solver specific kwargs from Manopt can be passed to the solve function or OptimizationProblem.\n\nnote: Note\nThe OptimizationProblem has to be passed the manifold as the manifold keyword argument.","category":"section"},{"location":"optimization_packages/manopt/#Examples","page":"Manopt.jl","title":"Examples","text":"The Rosenbrock function on the Euclidean manifold can be optimized using the GradientDescentOptimizer as follows:\n\nusing Optimization, OptimizationManopt, Manifolds, LinearAlgebra, ADTypes, Zygote\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\n\nR2 = Euclidean(2)\n\nstepsize = Manopt.ArmijoLinesearch(R2)\nopt = OptimizationManopt.GradientDescentOptimizer()\n\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoZygote())\n\nprob = OptimizationProblem(\n    optf, x0, p; manifold = R2, stepsize = stepsize)\n\nsol = Optimization.solve(prob, opt)\n\nThe box-constrained Karcher mean problem on the SPD manifold with the Frank-Wolfe algorithm can be solved as follows:\n\nM = SymmetricPositiveDefinite(5)\nm = 100\nσ = 0.005\nq = Matrix{Float64}(I, 5, 5) .+ 2.0\ndata2 = [exp(M, q, σ * rand(M; vector_at = q)) for i in 1:m]\n\nf(x, p = nothing) = sum(distance(M, x, data2[i])^2 for i in 1:m)\noptf = OptimizationFunction(f, ADTypes.AutoZygote())\nprob = OptimizationProblem(optf, data2[1]; manifold = M, maxiters = 1000)\n\nfunction closed_form_solution!(M::SymmetricPositiveDefinite, q, L, U, p, X)\n    # extract p^1/2 and p^{-1/2}\n    (p_sqrt_inv, p_sqrt) = Manifolds.spd_sqrt_and_sqrt_inv(p)\n    # Compute D & Q\n    e2 = eigen(p_sqrt_inv * X * p_sqrt_inv) # decompose Sk  = QDQ'\n    D = Diagonal(1.0 .* (e2.values .< 0))\n    Q = e2.vectors\n\n    Uprime = Q' * p_sqrt_inv * U * p_sqrt_inv * Q\n    Lprime = Q' * p_sqrt_inv * L * p_sqrt_inv * Q\n    P = cholesky(Hermitian(Uprime - Lprime))\n    z = P.U' * D * P.U + Lprime\n    copyto!(M, q, p_sqrt * Q * z * Q' * p_sqrt)\n    return q\nend\nN = m\nU = mean(data2)\nL = inv(sum(1 / N * inv(matrix) for matrix in data2))\n\noptf = OptimizationFunction(f, ADTypes.AutoZygote())\nprob = OptimizationProblem(optf, U; manifold = M, maxiters = 1000)\n\nsol = Optimization.solve(\n    prob, opt, sub_problem = (M, q, p, X) -> closed_form_solution!(M, q, L, U, p, X))\n\nThis example is based on the example in the Manopt and Weber and Sra'22.\n\nThe following example is adapted from the Rayleigh Quotient example in ManoptExamples.jl. We solve the Rayleigh quotient problem on the Sphere manifold:\n\nusing Optimization, OptimizationManopt\nusing Manifolds, LinearAlgebra\nusing Manopt\n\nn = 1000\nA = Symmetric(randn(n, n) / n)\nmanifold = Sphere(n - 1)\n\ncost(x, p = nothing) = -x' * A * x\negrad(G, x, p = nothing) = (G .= -2 * A * x)\n\noptf = OptimizationFunction(cost, grad = egrad)\nx0 = rand(manifold)\nprob = OptimizationProblem(optf, x0, manifold = manifold)\n\nsol = solve(prob, GradientDescentOptimizer())\n\nLet's check that this indeed corresponds to the minimum eigenvalue of the matrix A.\n\n@show eigmin(A)\n@show sol.objective","category":"section"},{"location":"optimization_packages/optimization/#Optimization.jl","page":"Optimization.jl","title":"Optimization.jl","text":"The Optimization.jl package provides the common interface for defining and solving optimization problems. All optimization solvers are provided through separate wrapper packages that need to be installed independently.\n\nFor a list of available solver packages, see the other pages in this section of the documentation.\n\nSome commonly used solver packages include:\n\nOptimizationLBFGSB.jl - L-BFGS-B quasi-Newton method with box constraints\nOptimizationOptimJL.jl - Wrappers for Optim.jl solvers\nOptimizationMOI.jl - MathOptInterface solvers\nOptimizationSophia.jl - Sophia optimizer for neural network training\n\nFor examples of using these solvers, please refer to their respective documentation pages.","category":"section"},{"location":"optimization_packages/blackboxoptim/#BlackBoxOptim.jl","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"BlackBoxOptim is a Julia package implementing (Meta-)heuristic/stochastic algorithms that do not require differentiability.","category":"section"},{"location":"optimization_packages/blackboxoptim/#Installation:-OptimizationBBO.jl","page":"BlackBoxOptim.jl","title":"Installation: OptimizationBBO.jl","text":"To use this package, install the OptimizationBBO package:\n\nimport Pkg;\nPkg.add(\"OptimizationBBO\");","category":"section"},{"location":"optimization_packages/blackboxoptim/#Global-Optimizers","page":"BlackBoxOptim.jl","title":"Global Optimizers","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/#Without-Constraint-Equations","page":"BlackBoxOptim.jl","title":"Without Constraint Equations","text":"The algorithms in BlackBoxOptim are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.\n\nA BlackBoxOptim algorithm is called by BBO_ prefix followed by the algorithm name:\n\nNatural Evolution Strategies:\nSeparable NES: BBO_separable_nes()\nExponential NES: BBO_xnes()\nDistance-weighted Exponential NES: BBO_dxnes()\nDifferential Evolution optimizers, 5 different:\nAdaptive DE/rand/1/bin: BBO_adaptive_de_rand_1_bin()\nAdaptive DE/rand/1/bin with radius limited sampling: BBO_adaptive_de_rand_1_bin_radiuslimited()\nDE/rand/1/bin: BBO_de_rand_1_bin()\nDE/rand/1/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_1_bin_radiuslimited()\nDE/rand/2/bin: de_rand_2_bin()\nDE/rand/2/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_2_bin_radiuslimited()\nDirect search:\nGenerating set search:\nCompass/coordinate search: BBO_generating_set_search()\nDirect search through probabilistic descent: BBO_probabilistic_descent()\nResampling Memetic Searchers:\nResampling Memetic Search (RS): BBO_resampling_memetic_search()\nResampling Inheritance Memetic Search (RIS): BBO_resampling_inheritance_memetic_search()\nStochastic Approximation:\nSimultaneous Perturbation Stochastic Approximation (SPSA): BBO_simultaneous_perturbation_stochastic_approximation()\nRandomSearch (to compare to): BBO_random_search()\n\nThe recommended optimizer is BBO_adaptive_de_rand_1_bin_radiuslimited()\n\nThe currently available algorithms are listed here","category":"section"},{"location":"optimization_packages/blackboxoptim/#Example","page":"BlackBoxOptim.jl","title":"Example","text":"The Rosenbrock function can be optimized using the BBO_adaptive_de_rand_1_bin_radiuslimited() as follows:\n\nusing Optimization, OptimizationBBO\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited(), maxiters = 100000,\n    maxtime = 1000.0)","category":"section"},{"location":"optimization_packages/prima/#PRIMA.jl","page":"PRIMA.jl","title":"PRIMA.jl","text":"PRIMA.jl is a julia wrapper for the fortran library prima which implements Powell's derivative free optimization methods.","category":"section"},{"location":"optimization_packages/prima/#Installation:-OptimizationPRIMA","page":"PRIMA.jl","title":"Installation: OptimizationPRIMA","text":"To use this package, install the OptimizationPRIMA package:\n\nimport Pkg;\nPkg.add(\"OptimizationPRIMA\");","category":"section"},{"location":"optimization_packages/prima/#Local-Optimizer","page":"PRIMA.jl","title":"Local Optimizer","text":"The five Powell's algorithms of the prima library are provided by the PRIMA.jl package:\n\nUOBYQA: (Unconstrained Optimization BY Quadratic Approximations) is for unconstrained optimization, that is Ω = ℝⁿ.\n\nNEWUOA: is also for unconstrained optimization. According to M.J.D. Powell, newuoa is superior to uobyqa.\n\nBOBYQA: (Bounded Optimization BY Quadratic Approximations) is for simple bound constrained problems, that is Ω = { x ∈ ℝⁿ | xl ≤ x ≤ xu }.\n\nLINCOA: (LINearly Constrained Optimization) is for constrained optimization problems with bound constraints, linear equality constraints, and linear inequality constraints.\n\nCOBYLA: (Constrained Optimization BY Linear Approximations) is for general constrained problems with bound constraints, non-linear constraints, linear equality constraints, and linear inequality constraints.\n\nusing OptimizationBase, OptimizationPRIMA\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\nprob = OptimizationProblem(rosenbrock, x0, _p)\n\nsol = solve(prob, UOBYQA(), maxiters = 1000)\n\nsol = solve(prob, NEWUOA(), maxiters = 1000)\n\nsol = solve(prob, BOBYQA(), maxiters = 1000)\n\nsol = solve(prob, LINCOA(), maxiters = 1000)\n\nfunction con2_c(res, x, p)\n    res .= [x[1] + x[2], x[2] * sin(x[1]) - x[1]]\nend\noptprob = OptimizationFunction(rosenbrock, AutoForwardDiff(), cons = con2_c)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [1, -100], ucons = [1, 100])\nsol = solve(prob, COBYLA(), maxiters = 1000)","category":"section"},{"location":"examples/rosenbrock/#Solving-the-Rosenbrock-Problem-in-10-Ways","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"This example is a demonstration of many different solvers to demonstrate the flexibility of Optimization.jl. This is a gauntlet of many solvers to get a feel for common workflows of the package and give copy-pastable starting points.\n\nnote: Note\nThis example uses many different solvers of Optimization.jl. Each solver subpackage needs to be installed separate. For example, for the details on the installation and usage of OptimizationOptimJL.jl package, see the Optim.jl page.\n\nThe objective of this exercise is to determine the (x y) value pair that minimizes the result of a Rosenbrock function f with some parameter values a and b. The Rosenbrock function is useful for testing because it is known a priori to have a global minimum at (a a^2).\n\nf(xyab) = left(a - xright)^2 + b left(y - x^2right)^2\n\nThe Optimization.jl interface expects functions to be defined with a vector of optimization arguments barx and a vector of parameters barp, i.e.:\n\nf(barxbarp) = left(p_1 - x_1right)^2 + p_2 left(x_2 - x_1^2right)^2\n\nParameters a and b are captured in a vector barp and assigned some arbitrary values to produce a particular Rosenbrock function to be minimized.\n\nbarp = beginbmatrix a  b endbmatrix = beginbmatrix 1  100 endbmatrix\n\nThe original x and y domains are captured in a vector barx.\n\nbarx = beginbmatrix x  y endbmatrix\n\nAn initial estimate barx_0 of the minima location is required to initialize the optimizer.\n\nbarx_0 = beginbmatrix x_0  y_0 endbmatrix = beginbmatrix 0  0 endbmatrix\n\nAn optimization problem can now be defined and solved to estimate the values for barx that minimize the output of this function.\n\n# Define the problem to solve\nusing SciMLBase, OptimizationBase\nusing ADTypes, ForwardDiff, Zygote\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\nf = SciMLBase.OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nl1 = rosenbrock(x0, _p)\nprob = SciMLBase.OptimizationProblem(f, x0, _p)","category":"section"},{"location":"examples/rosenbrock/#Optim.jl-Solvers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Optim.jl Solvers","text":"","category":"section"},{"location":"examples/rosenbrock/#Start-with-some-derivative-free-optimizers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Start with some derivative-free optimizers","text":"using OptimizationOptimJL\nsol = solve(prob, SimulatedAnnealing())\nprob = SciMLBase.OptimizationProblem(f, x0, _p, lb = [-1.0, -1.0], ub = [0.8, 0.8])\nsol = solve(prob, SAMIN())\n\nl1 = rosenbrock(x0, _p)\nprob = SciMLBase.OptimizationProblem(rosenbrock, x0, _p)\nsol = solve(prob, NelderMead())","category":"section"},{"location":"examples/rosenbrock/#Now-a-gradient-based-optimizer-with-forward-mode-automatic-differentiation","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now a gradient-based optimizer with forward-mode automatic differentiation","text":"optf = SciMLBase.OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = SciMLBase.OptimizationProblem(optf, x0, _p)\nsol = solve(prob, BFGS())","category":"section"},{"location":"examples/rosenbrock/#Now-a-second-order-optimizer-using-Hessians-generated-by-forward-mode-automatic-differentiation","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now a second order optimizer using Hessians generated by forward-mode automatic differentiation","text":"sol = solve(prob, Newton())","category":"section"},{"location":"examples/rosenbrock/#Now-a-second-order-Hessian-free-optimizer","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now a second order Hessian-free optimizer","text":"sol = solve(prob, Optim.KrylovTrustRegion())","category":"section"},{"location":"examples/rosenbrock/#Now-derivative-based-optimizers-with-various-constraints","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now derivative-based optimizers with various constraints","text":"cons = (res, x, p) -> res .= [x[1]^2 + x[2]^2]\noptf = SciMLBase.OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff(); cons = cons)\n\nprob = SciMLBase.OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [Inf])\nsol = solve(prob, IPNewton()) # Note that -Inf < x[1]^2 + x[2]^2 < Inf is always true\n\nprob = SciMLBase.OptimizationProblem(optf, x0, _p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton()) # Again, -5.0 < x[1]^2 + x[2]^2 < 10.0\n\nprob = SciMLBase.OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [Inf],\n    lb = [-500.0, -500.0], ub = [50.0, 50.0])\nsol = solve(prob, IPNewton())\n\nprob = SciMLBase.OptimizationProblem(optf, x0, _p, lcons = [0.5], ucons = [0.5],\n    lb = [-500.0, -500.0], ub = [50.0, 50.0])\nsol = solve(prob, IPNewton())\n\n# Notice now that x[1]^2 + x[2]^2 ≈ 0.5:\nres = zeros(1)\ncons(res, sol.u, _p)\nprintln(res)\n\nfunction con_c(res, x, p)\n    res .= [x[1]^2 + x[2]^2]\nend\n\noptf = SciMLBase.OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff(); cons = con_c)\nprob = SciMLBase.OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [0.25^2])\nsol = solve(prob, IPNewton()) # -Inf < cons_circ(sol.u, _p) = 0.25^2","category":"section"},{"location":"examples/rosenbrock/#Evolutionary.jl-Solvers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Evolutionary.jl Solvers","text":"using OptimizationEvolutionary\nsol = solve(prob, CMAES(μ = 40, λ = 100), abstol = 1e-15) # -Inf < cons_circ(sol.u, _p) = 0.25^2","category":"section"},{"location":"examples/rosenbrock/#IPOPT-through-OptimizationMOI","page":"Solving the Rosenbrock Problem in >10 Ways","title":"IPOPT through OptimizationMOI","text":"using OptimizationMOI, Ipopt\n\nfunction con2_c(res, x, p)\n    res .= [x[1]^2 + x[2]^2, x[2] * sin(x[1]) - x[1]]\nend\n\noptf = SciMLBase.OptimizationFunction(rosenbrock, ADTypes.AutoZygote(); cons = con2_c)\nprob = SciMLBase.OptimizationProblem(optf, x0, _p, lcons = [-Inf, -Inf], ucons = [100.0, 100.0])\nsol = solve(prob, Ipopt.Optimizer())","category":"section"},{"location":"examples/rosenbrock/#Now-let's-switch-over-to-OptimizationOptimisers-with-reverse-mode-AD","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now let's switch over to OptimizationOptimisers with reverse-mode AD","text":"import OptimizationOptimisers\noptf = SciMLBase.OptimizationFunction(rosenbrock, ADTypes.AutoZygote())\nprob = SciMLBase.OptimizationProblem(optf, x0, _p)\nsol = solve(prob, OptimizationOptimisers.Adam(0.05), maxiters = 1000, progress = false)","category":"section"},{"location":"examples/rosenbrock/#Try-out-CMAEvolutionStrategy.jl's-evolutionary-methods","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Try out CMAEvolutionStrategy.jl's evolutionary methods","text":"using OptimizationCMAEvolutionStrategy\nsol = solve(prob, CMAEvolutionStrategyOpt())","category":"section"},{"location":"examples/rosenbrock/#Now-try-a-few-NLopt.jl-solvers-with-symbolic-differentiation-via-ModelingToolkit.jl","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now try a few NLopt.jl solvers with symbolic differentiation via ModelingToolkit.jl","text":"using OptimizationNLopt, ModelingToolkit\noptf = SciMLBase.OptimizationFunction(rosenbrock, ADTypes.AutoSymbolics())\nprob = SciMLBase.OptimizationProblem(optf, x0, _p)\n\nsol = solve(prob, Opt(:LN_BOBYQA, 2))\nsol = solve(prob, Opt(:LD_LBFGS, 2))","category":"section"},{"location":"examples/rosenbrock/#Add-some-box-constraints-and-solve-with-a-few-NLopt.jl-methods","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Add some box constraints and solve with a few NLopt.jl methods","text":"prob = SciMLBase.OptimizationProblem(optf, x0, _p, lb = [-1.0, -1.0], ub = [0.8, 0.8])\nsol = solve(prob, Opt(:LD_LBFGS, 2))\nsol = solve(prob, Opt(:G_MLSL_LDS, 2), local_method = Opt(:LD_LBFGS, 2), maxiters = 10000) #a global optimizer with random starts of local optimization","category":"section"},{"location":"examples/rosenbrock/#BlackBoxOptim.jl-Solvers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"BlackBoxOptim.jl Solvers","text":"using OptimizationBBO\nprob = SciMLBase.OptimizationProblem(rosenbrock, [0.0, 0.3], _p, lb = [-1.0, 0.2],\n    ub = [0.8, 0.43])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin()) # -1.0 ≤ x[1] ≤ 0.8, 0.2 ≤ x[2] ≤ 0.43\n\nAnd this is only a small subset of what Optimization.jl has to offer!","category":"section"},{"location":"tutorials/certification/#Using-SymbolicAnalysis.jl-for-convexity-certificates","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"In this tutorial, we will show how to use automatic convexity certification of the optimization problem using SymbolicAnalysis.jl.\n\nThis works with the structural_analysis keyword argument to OptimizationProblem. This tells the package to try to trace through the objective and constraints with symbolic variables (for more details on this look at the Symbolics documentation). This relies on the Disciplined Programming approach hence neccessitates the use of \"atoms\" from the SymbolicAnalysis.jl package.\n\nWe'll use a simple example to illustrate the convexity structure certification process.\n\nusing SymbolicAnalysis, LinearAlgebra, OptimizationBase, OptimizationLBFGSB, ADTypes\n\nfunction f(x, p = nothing)\n    return exp(x[1]) + x[1]^2\nend\n\noptf = OptimizationFunction(f, ADTypes.AutoForwardDiff())\nprob = OptimizationProblem(optf, [0.4], structural_analysis = true)\n\nsol = solve(prob, OptimizationLBFGSB.LBFGSB(), maxiters = 1000)\n\nThe result can be accessed as the analysis_results field of the solution.\n\nsol.cache.analysis_results.objective\n\nRelatedly you can enable structural analysis in Riemannian optimization problems (supported only on the SPD manifold).\n\nWe'll look at the Riemannian center of mass of SPD matrices which is known to be a Geodesically Convex problem on the SPD manifold.\n\nusing OptimizationBase, OptimizationManopt, Symbolics, Manifolds, Random, LinearAlgebra,\n      SymbolicAnalysis, ADTypes\n\nM = SymmetricPositiveDefinite(5)\nm = 100\nσ = 0.005\nq = Matrix{Float64}(LinearAlgebra.I(5)) .+ 2.0\n\ndata2 = [exp(M, q, σ * rand(M; vector_at = q)) for i in 1:m];\n\nf(x, p = nothing) = sum(SymbolicAnalysis.distance(M, data2[i], x)^2 for i in 1:5)\noptf = OptimizationFunction(f, ADTypes.AutoZygote())\nprob = OptimizationProblem(optf, data2[1]; manifold = M, structural_analysis = true)\n\nopt = OptimizationManopt.GradientDescentOptimizer()\nsol = solve(prob, opt, maxiters = 100)","category":"section"},{"location":"optimization_packages/scipy/#SciPy.jl","page":"SciPy.jl","title":"SciPy.jl","text":"SciPy is a mature Python library that offers a rich family of optimization, root–finding and linear‐programming algorithms.  OptimizationSciPy.jl gives access to these routines through the unified Optimization.jl interface just like any native Julia optimizer.\n\nnote: Note\nOptimizationSciPy.jl relies on PythonCall.  A minimal Python distribution containing SciPy will be installed automatically on first use, so no manual Python set-up is required.","category":"section"},{"location":"optimization_packages/scipy/#Installation:-OptimizationSciPy.jl","page":"SciPy.jl","title":"Installation: OptimizationSciPy.jl","text":"import Pkg\nPkg.add(\"OptimizationSciPy\")","category":"section"},{"location":"optimization_packages/scipy/#Methods","page":"SciPy.jl","title":"Methods","text":"Below is a catalogue of the solver families exposed by OptimizationSciPy.jl together with their convenience constructors.  All of them accept the usual keyword arguments maxiters, maxtime, abstol, reltol, callback, progress in addition to any SciPy-specific options (passed verbatim via keyword arguments to solve).","category":"section"},{"location":"optimization_packages/scipy/#Local-Optimizer","page":"SciPy.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/scipy/#Derivative-Free","page":"SciPy.jl","title":"Derivative-Free","text":"ScipyNelderMead() – Simplex Nelder–Mead algorithm\nScipyPowell() – Powell search along conjugate directions\nScipyCOBYLA() – Linear approximation of constraints (supports nonlinear constraints)","category":"section"},{"location":"optimization_packages/scipy/#Gradient-Based","page":"SciPy.jl","title":"Gradient-Based","text":"ScipyCG() – Non-linear conjugate gradient\nScipyBFGS() – Quasi-Newton BFGS\nScipyLBFGSB() – Limited-memory BFGS with simple bounds\nScipyNewtonCG() – Newton-conjugate gradient (requires Hessian-vector products)\nScipyTNC() – Truncated Newton with bounds\nScipySLSQP() – Sequential least-squares programming (supports constraints)\nScipyTrustConstr() – Trust-region method for non-linear constraints","category":"section"},{"location":"optimization_packages/scipy/#Hessian–Based-/-Trust-Region","page":"SciPy.jl","title":"Hessian–Based / Trust-Region","text":"ScipyDogleg(), ScipyTrustNCG(), ScipyTrustKrylov(), ScipyTrustExact() – Trust-region algorithms that optionally use or build Hessian information","category":"section"},{"location":"optimization_packages/scipy/#Global-Optimizer","page":"SciPy.jl","title":"Global Optimizer","text":"ScipyDifferentialEvolution() – Differential evolution (requires bounds)\nScipyBasinhopping() – Basin-hopping with local search\nScipyDualAnnealing() – Dual annealing simulated annealing\nScipyShgo() – Simplicial homology global optimisation (supports constraints)\nScipyDirect() – Deterministic DIRECT algorithm (requires bounds)\nScipyBrute() – Brute-force grid search (requires bounds)","category":"section"},{"location":"optimization_packages/scipy/#Linear-and-Mixed-Integer-Programming","page":"SciPy.jl","title":"Linear & Mixed-Integer Programming","text":"ScipyLinprog(\"highs\") – LP solvers from the HiGHS project and legacy interior-point/simplex methods\nScipyMilp() – Mixed-integer linear programming via HiGHS branch-and-bound","category":"section"},{"location":"optimization_packages/scipy/#Root-Finding-and-Non-Linear-Least-Squares-*(experimental)*","page":"SciPy.jl","title":"Root Finding & Non-Linear Least Squares (experimental)","text":"Support for ScipyRoot, ScipyRootScalar and ScipyLeastSquares is available behind the scenes and will be documented once the APIs stabilise.","category":"section"},{"location":"optimization_packages/scipy/#Examples","page":"SciPy.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/scipy/#Unconstrained-minimisation","page":"SciPy.jl","title":"Unconstrained minimisation","text":"using Optimization, OptimizationSciPy, ADTypes, Zygote\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, ADTypes.AutoZygote())\nprob = OptimizationProblem(f, x0, p)\n\nsol = solve(prob, ScipyBFGS())\n@show sol.objective   # ≈ 0 at optimum","category":"section"},{"location":"optimization_packages/scipy/#Constrained-optimisation-with-COBYLA","page":"SciPy.jl","title":"Constrained optimisation with COBYLA","text":"using Optimization, OptimizationSciPy\n\n# Objective\nobj(x, p) = (x[1] + x[2] - 1)^2\n\n# Single non-linear constraint: x₁² + x₂² ≈ 1 (with small tolerance)\ncons(res, x, p) = (res .= [x[1]^2 + x[2]^2 - 1.0])\n\nx0 = [0.5, 0.5]\nprob = OptimizationProblem(\n    OptimizationFunction(obj; cons = cons),\n    x0, nothing, lcons = [-1e-6], ucons = [1e-6])  # Small tolerance instead of exact equality\n\nsol = solve(prob, ScipyCOBYLA())\n@show sol.u, sol.objective","category":"section"},{"location":"optimization_packages/scipy/#Differential-evolution-(global)-with-custom-options","page":"SciPy.jl","title":"Differential evolution (global) with custom options","text":"using Optimization, OptimizationSciPy, Random, Statistics\nRandom.seed!(123)\n\nackley(x, p) = -20exp(-0.2*sqrt(mean(x .^ 2))) - exp(mean(cos.(2π .* x))) + 20 + ℯ\nx0 = zeros(2)                    # initial guess is ignored by DE\nprob = OptimizationProblem(ackley, x0; lb = [-5.0, -5.0], ub = [5.0, 5.0])\n\nsol = solve(prob, ScipyDifferentialEvolution(); popsize = 20, mutation = (0.5, 1))\n@show sol.objective","category":"section"},{"location":"optimization_packages/scipy/#Passing-solver-specific-options","page":"SciPy.jl","title":"Passing solver-specific options","text":"Any keyword that Optimization.jl does not interpret is forwarded directly to SciPy.  Refer to the SciPy optimisation API for the exhaustive list of options.\n\nsol = solve(prob, ScipyTrustConstr(); verbose = 3, maxiter = 10_000)","category":"section"},{"location":"optimization_packages/scipy/#Troubleshooting","page":"SciPy.jl","title":"Troubleshooting","text":"The original Python result object is attached to the solution in the original field:\n\nsol = solve(prob, ScipyBFGS())\nprintln(sol.original)  # SciPy OptimizeResult\n\nIf SciPy raises an error it is re-thrown as a Julia ErrorException carrying the Python message, so look there first.","category":"section"},{"location":"optimization_packages/scipy/#Contributing","page":"SciPy.jl","title":"Contributing","text":"Bug reports and feature requests are welcome in the Optimization.jl issue tracker.  Pull requests that improve either the Julia wrapper or the documentation are highly appreciated.","category":"section"},{"location":"getting_started/#Getting-Started-with-Optimization.jl","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"In this tutorial, we introduce the basics of Optimization.jl by showing how to easily mix local optimizers and global optimizers on the Rosenbrock equation.\n\nThe Rosenbrock equation is defined as follows:\n\nf(up) = (p_1 - u_1)^2 + p_2 * ( u_2 - u_1^2)^2\n\nThis is a parameterized optimization problem where we want to solve for the vector u s.t. u minimizes f. The simplest copy-pasteable code using a quasi-Newton method (LBFGS) to solve the Rosenbrock problem is the following:\n\n# Import the package and define the problem to optimize\nusing OptimizationBase, OptimizationLBFGSB, ADTypes, Zygote\nrosenbrock(u, p) = (p[1] - u[1])^2 + p[2] * (u[2] - u[1]^2)^2\nu0 = zeros(2)\np = [1.0, 100.0]\n\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoZygote())\nprob = OptimizationProblem(optf, u0, p)\n\nsol = solve(prob, OptimizationLBFGSB.LBFGSB())\n\nsol.u\n\nsol.objective\n\nTada! That's how you do it. Now let's dive in a little more into what each part means and how to customize it all to your needs.","category":"section"},{"location":"getting_started/#Understanding-the-Solution-Object","page":"Getting Started with Optimization.jl","title":"Understanding the Solution Object","text":"The solution object is a SciMLBase.AbstractNoTimeSolution, and thus it follows the SciMLBase Solution Interface for non-timeseries objects and is documented at the solution type page. However, for simplicity let's show a bit of it in action.\n\nAn optimization solution has an array interface so that it acts like the array that it solves for. This array syntax is shorthand for simply grabbing the solution u. For example:\n\nsol[1] == sol.u[1]\n\nArray(sol) == sol.u\n\nsol.objective returns the final cost of the optimization. We can validate this by plugging it into our function:\n\nrosenbrock(sol.u, p)\n\nsol.objective\n\nThe sol.retcode gives us more information about the solution process.\n\nsol.retcode\n\nHere it says ReturnCode.Success which means that the solutuion successfully solved. We can learn more about the different return codes at the ReturnCode part of the SciMLBase documentation.\n\nIf we are interested about some of the statistics of the solving process, for example to help choose a better solver, we can investigate the sol.stats\n\nsol.stats\n\nThat's just a bit of what's in there, check out the other pages for more information but now let's move onto customization.","category":"section"},{"location":"getting_started/#Import-a-different-solver-package-and-solve-the-problem","page":"Getting Started with Optimization.jl","title":"Import a different solver package and solve the problem","text":"OptimizationOptimJL is a wrapper for Optim.jl and OptimizationBBO is a wrapper for BlackBoxOptim.jl.\n\nFirst let's use the NelderMead a derivative free solver from Optim.jl:\n\nusing OptimizationOptimJL\nsol = solve(prob, Optim.NelderMead())\n\nBlackBoxOptim.jl offers derivative-free global optimization solvers that requrie the bounds to be set via lb and ub in the OptimizationProblem. Let's use the BBOadaptivederand1binradiuslimited() solver:\n\nusing OptimizationBBO\nprob = OptimizationProblem(rosenbrock, u0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited())\n\nThe solution from the original solver can always be obtained via original:\n\nsol.original","category":"section"},{"location":"getting_started/#Defining-the-objective-function","page":"Getting Started with Optimization.jl","title":"Defining the objective function","text":"Optimization.jl assumes that your objective function takes two arguments objective(x, p)\n\nThe optimization variables x.\nOther parameters p, such as hyper parameters of the cost function. If you have no “other parameters”, you can  safely disregard this argument. If your objective function is defined by someone else, you can create an anonymous function that just discards the extra parameters like this\n\nobj = (x, p) -> objective(x) # Pass this function into OptimizationFunction","category":"section"},{"location":"getting_started/#Controlling-Gradient-Calculations-(Automatic-Differentiation)","page":"Getting Started with Optimization.jl","title":"Controlling Gradient Calculations (Automatic Differentiation)","text":"Notice that both of the above methods were derivative-free methods, and thus no gradients were required to do the optimization. However, often first order optimization (i.e., using gradients) is much more efficient. Defining gradients can be done in two ways. One way is to manually provide a gradient definition in the OptimizationFunction constructor. However, the more convenient way to obtain gradients is to provide an AD backend type.\n\nFor example, let's now use the OptimizationOptimJL BFGS method to solve the same problem. We will import the forward-mode automatic differentiation library (using ForwardDiff) and then specify in the OptimizationFunction to automatically construct the derivative functions using ForwardDiff.jl. This looks like:\n\nusing ForwardDiff, ADTypes\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = OptimizationProblem(optf, u0, p)\nsol = solve(prob, OptimizationOptimJL.BFGS())\n\nWe can inspect the original to see the statistics on the number of steps required and gradients computed:\n\nsol.original\n\nSure enough, it's a lot less than the derivative-free methods!\n\nHowever, the compute cost of forward-mode automatic differentiation scales via the number of inputs, and thus as our optimization problem grows large it slows down. To counteract this, for larger optimization problems (>100 state variables) one normally would want to use reverse-mode automatic differentiation. One common choice for reverse-mode automatic differentiation is Zygote.jl. We can demonstrate this via:\n\nusing Zygote\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoZygote())\nprob = OptimizationProblem(optf, u0, p)\nsol = solve(prob, OptimizationOptimJL.BFGS())","category":"section"},{"location":"getting_started/#Setting-Box-Constraints","page":"Getting Started with Optimization.jl","title":"Setting Box Constraints","text":"In many cases, one knows the potential bounds on the solution values. In Optimization.jl, these can be supplied as the lb and ub arguments for the lower bounds and upper bounds respectively, supplying a vector of values with one per state variable. Let's now do our gradient-based optimization with box constraints by rebuilding the OptimizationProblem:\n\nprob = OptimizationProblem(optf, u0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, OptimizationOptimJL.BFGS())\n\nFor more information on handling constraints, in particular equality and inequality constraints, take a look at the constraints tutorial.","category":"section"},{"location":"tutorials/linearandinteger/#Linear-and-Integer-Optimization-Problems","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"","category":"section"},{"location":"tutorials/linearandinteger/#Example:-Short-Term-Financing","page":"Linear and Integer Optimization Problems","title":"Example: Short-Term Financing","text":"Below we show how to solve a linear optimization problem using the HiGHS optimizer. This example has been taken from the JuMP documentation.\n\nShort-term cash commitments present an ongoing challenge for corporations. Let's explore an example scenario to understand this better:\n\nConsider the following monthly net cash flow requirements, presented in thousands of dollars:\n\nMonth Jan Feb Mar Apr May Jun\nNet Cash Flow -150 -100 200 -200 50 300\n\nTo address these financial needs, our hypothetical company has access to various funding sources:\n\nA line of credit: The company can utilize a line of credit of up to $100,000, subject to a monthly interest rate of 1%.\nCommercial paper issuance: In any of the first three months, the company has the option to issue 90-day commercial paper with a cumulative interest rate of 2% for the three-month period.\nSurplus fund investment: Any excess funds can be invested, earning a monthly interest rate of 0.3%.\n\nThe objective is to determine the most cost-effective utilization of these funding sources, aiming to maximize the company's available funds by the end of June.\n\nTo model this problem, we introduce the following decision variables:\n\nu_i: The amount drawn from the line of credit in month i.\nv_i: The amount of commercial paper issued in month i.\nw_i: The surplus funds in month i.\n\nWe need to consider the following constraints:\n\nCash inflow must equal cash outflow for each month.\nUpper bounds must be imposed on u_i to ensure compliance with the line of credit limit.\nThe decision variables u_i, v_i, and w_i must be non-negative.\n\nThe ultimate objective is to maximize the company's wealth in June, denoted by the variable m.\n\nusing OptimizationBase, OptimizationMOI, ModelingToolkit, HiGHS, LinearAlgebra, SciMLBase\n\n@variables u[1:5] [bounds = (0.0, 100.0)]\n@variables v[1:3] [bounds = (0.0, Inf)]\n@variables w[1:5] [bounds = (0.0, Inf)]\n@variables m [bounds = (0.0, Inf)]\n\ncons = [u[1] + v[1] - w[1] ~ 150 # January\n        u[2] + v[2] - w[2] - 1.01u[1] + 1.003w[1] ~ 100 # February\n        u[3] + v[3] - w[3] - 1.01u[2] + 1.003w[2] ~ -200 # March\n        u[4] - w[4] - 1.02v[1] - 1.01u[3] + 1.003w[3] ~ 200 # April\n        u[5] - w[5] - 1.02v[2] - 1.01u[4] + 1.003w[4] ~ -50 # May\n        -m - 1.02v[3] - 1.01u[5] + 1.003w[5] ~ -300]\n\n@named optsys = OptimizationSystem(m, [u..., v..., w..., m], [], constraints = cons)\noptsys = complete(optsys)\noptprob = OptimizationProblem(optsys,\n    vcat(fill(0.0, 13), 300.0);\n    grad = true,\n    hess = true,\n    sense = SciMLBase.MaxSense)\nsol = solve(optprob, HiGHS.Optimizer())","category":"section"},{"location":"tutorials/linearandinteger/#Mixed-Integer-Nonlinear-Optimization","page":"Linear and Integer Optimization Problems","title":"Mixed Integer Nonlinear Optimization","text":"We choose an example from the Juniper.jl readme to demonstrate mixed integer nonlinear optimization with Optimization.jl. The problem can be stated as follows:\n\nbeginaligned\n\nv = 1020122342 \nw = 1245122221 \n\ntextmaximize quad  sum_i=1^5 v_i u_i \n\ntextsubject to quad  sum_i=1^5 w_i u_i^2 leq 45 \n\n u_i in 01 quad forall i in 12345\n\nendaligned\n\nwhich implies a maximization problem of binary variables u_i with the objective as the dot product of v and u subject to a quadratic constraint on u.\n\nusing Juniper, Ipopt, ADTypes, Symbolics\n\nv = [10, 20, 12, 23, 42]\nw = [12, 45, 12, 22, 21]\n\nobjective = (u, p) -> (v = p[1:5]; dot(v, u))\n\ncons = (res, u, p) -> (w = p[6:10]; res .= [sum(w[i] * u[i]^2 for i in 1:5)])\n\noptf = OptimizationFunction(objective, ADTypes.AutoSymbolics(), cons = cons)\noptprob = OptimizationProblem(optf,\n    zeros(5),\n    vcat(v, w);\n    sense = SciMLBase.MaxSense,\n    lb = zeros(5),\n    ub = ones(5),\n    lcons = [-Inf],\n    ucons = [45.0],\n    int = fill(true, 5))\n\nnl_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n    \"print_level\" => 0)\nminlp_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Juniper.Optimizer,\n    \"nl_solver\" => nl_solver)\n\nsol = solve(optprob, minlp_solver)","category":"section"},{"location":"API/optimization_state/#optstate","page":"OptimizationState","title":"OptimizationState","text":"","category":"section"},{"location":"API/optimization_state/#OptimizationBase.OptimizationState","page":"OptimizationState","title":"OptimizationBase.OptimizationState","text":"struct OptimizationState{X, O, G, H, S, P}\n\nStores the optimization run's state at the current iteration and is passed to the callback function as the first argument.\n\nFields\n\niter: current iteration\nu: current solution\nobjective: current objective value\ngradient: current gradient\nhessian: current hessian\noriginal: if the solver has its own state object then it is stored here\np: optimization parameters\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/quaddirect/#QuadDIRECT.jl","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"QuadDIRECT is a Julia package implementing QuadDIRECT algorithm (inspired by DIRECT and MCS).\n\nThe QuadDIRECT algorithm is called using QuadDirect().","category":"section"},{"location":"optimization_packages/quaddirect/#Installation:-OptimizationQuadDIRECT.jl","page":"QuadDIRECT.jl","title":"Installation: OptimizationQuadDIRECT.jl","text":"To use this package, install the OptimizationQuadDIRECT package as:\n\nimport Pkg;\nPkg.add(url = \"https://github.com/SciML/Optimization.jl\",\n    subdir = \"lib/OptimizationQuadDIRECT\");\n\nAlso note that QuadDIRECT should (for now) be installed by doing:\n\n] add https://github.com/timholy/QuadDIRECT.jl.git\n\nSince QuadDIRECT is not a registered package in General registry, OptimizationQuadDIRECT is not registered as well, and hence it can't be installed with the traditional command.","category":"section"},{"location":"optimization_packages/quaddirect/#Global-Optimizer","page":"QuadDIRECT.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/quaddirect/#Without-Constraint-Equations","page":"QuadDIRECT.jl","title":"Without Constraint Equations","text":"The algorithm in QuadDIRECT is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.\n\nFurthermore, QuadDirect requires splits which is a list of 3-vectors with initial locations at which to evaluate the function (the values must be in strictly increasing order and lie within the specified bounds) such that solve(problem, QuadDirect(), splits).","category":"section"},{"location":"optimization_packages/quaddirect/#Example","page":"QuadDIRECT.jl","title":"Example","text":"The Rosenbrock function can be optimized using the QuadDirect() as follows:\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = SciMLBase.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsolve(prob, QuadDirect(), splits = ([-0.9, 0, 0.9], [-0.8, 0, 0.8]))","category":"section"},{"location":"tutorials/remakecomposition/#Creating-polyalgorithms-by-chaining-solvers-using-remake","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"The general framework of using multiple solvers to use exploration-convergence alternations is commonly known as polyalgorithms. In the past Optimization.jl has provided a PolyOpt solver in OptimizationPolyalgorithms.jl which combined Adam from Optimisers.jl with BFGS from Optim.jl. With the large number of choices available through the interface unique combinations of solvers can be effective for specific problems.\n\nIn this tutorial we will demonstrate how to use the remake function to chain together solvers to create your own polyalgorithms.\n\nThe SciML interface provides a remake function which allows you to recreate the OptimizationProblem from a previously defined OptimizationProblem with different initial guess for the optimization variables.\n\nLet's look at a 10 dimensional schwefel function in the hypercube x_i in -500 500.\n\nusing OptimizationBase, OptimizationLBFGSB, Random\nusing OptimizationBBO, ADTypes, ReverseDiff\n\nRandom.seed!(122333)\n\nfunction f_schwefel(x, p = [418.9829])\n    result = p[1] * length(x)\n    for i in 1:length(x)\n        result -= x[i] * sin(sqrt(abs(x[i])))\n    end\n    return result\nend\n\noptf = OptimizationFunction(f_schwefel, ADTypes.AutoReverseDiff(compile = true))\n\nx0 = ones(10) .* 200.0\nprob = OptimizationProblem(\n    optf, x0, [418.9829], lb = fill(-500.0, 10), ub = fill(500.0, 10))\n\n@show f_schwefel(x0)\n\nOur polyalgorithm strategy will to use BlackBoxOptim's global optimizers for efficient exploration of the parameter space followed by a quasi-Newton LBFGS method to (hopefully) converge to the global optimum.\n\nres1 = solve(prob, BBO_adaptive_de_rand_1_bin(), maxiters = 4000)\n\n@show res1.objective\n\nThis is a good start can we converge to the global optimum?\n\nprob = remake(prob, u0 = res1.minimizer)\nres2 = solve(prob, OptimizationLBFGSB.LBFGSB(), maxiters = 100)\n\n@show res2.objective\n\nYay! We have found the global optimum (this is known to be at x_i = 4209687).","category":"section"},{"location":"tutorials/ensemble/#Multistart-optimization-with-EnsembleProblem","page":"Multistart optimization with EnsembleProblem","title":"Multistart optimization with EnsembleProblem","text":"The EnsembleProblem in SciML serves as a common interface for running a problem on multiple sets of initializations. In the context of optimization, this is useful for performing multistart optimization.\n\nThis can be useful for complex, low dimensional problems. We demonstrate this, again, on the rosenbrock function.\n\nWe first execute a single local optimization with OptimizationOptimJL.BFGS and maxiters=5:\n\nusing OptimizationBase, OptimizationOptimJL, Random\nusing SciMLBase, ADTypes, ForwardDiff\n\nRandom.seed!(100)\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n\noptf = OptimizationFunction(rosenbrock, ADTypes.AutoForwardDiff())\nprob = OptimizationProblem(optf, x0, [1.0, 100.0])\n@time sol1 = solve(prob, OptimizationOptimJL.BFGS(), maxiters = 5)\n\n@show sol1.objective\n\nThis results is compared to a multistart approach with 4 random initial points:\n\nx0s = [x0, x0 .+ rand(2), x0 .+ rand(2), x0 .+ rand(2)]\nfunction prob_func(prob, i, repeat)\n    remake(prob, u0 = x0s[i])\nend\n\nensembleprob = EnsembleProblem(prob; prob_func)\n@time sol = solve(ensembleprob, OptimizationOptimJL.BFGS(),\n    EnsembleThreads(), trajectories = 4, maxiters = 5)\n@show findmin(i -> sol[i].objective, 1:4)[1]\n\nWith the same number of iterations (5) we get a much lower (1/100th) objective value by using multiple initial points. The initialization strategy used here was a pretty trivial one but approaches based on Quasi-Monte Carlo sampling should be typically more effective.","category":"section"}]
}
