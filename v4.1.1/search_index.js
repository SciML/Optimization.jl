var documenterSearchIndex = {"docs":
[{"location":"optimization_packages/blackboxoptim/#BlackBoxOptim.jl","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"BlackBoxOptim is a Julia package implementing (Meta-)heuristic/stochastic algorithms that do not require differentiability.","category":"page"},{"location":"optimization_packages/blackboxoptim/#Installation:-OptimizationBBO.jl","page":"BlackBoxOptim.jl","title":"Installation: OptimizationBBO.jl","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"To use this package, install the OptimizationBBO package:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"import Pkg;\nPkg.add(\"OptimizationBBO\");","category":"page"},{"location":"optimization_packages/blackboxoptim/#Global-Optimizers","page":"BlackBoxOptim.jl","title":"Global Optimizers","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/#Without-Constraint-Equations","page":"BlackBoxOptim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The algorithms in BlackBoxOptim are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"A BlackBoxOptim algorithm is called by BBO_ prefix followed by the algorithm name:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Natural Evolution Strategies:\nSeparable NES: BBO_separable_nes()\nExponential NES: BBO_xnes()\nDistance-weighted Exponential NES: BBO_dxnes()\nDifferential Evolution optimizers, 5 different:\nAdaptive DE/rand/1/bin: BBO_adaptive_de_rand_1_bin()\nAdaptive DE/rand/1/bin with radius limited sampling: BBO_adaptive_de_rand_1_bin_radiuslimited()\nDE/rand/1/bin: BBO_de_rand_1_bin()\nDE/rand/1/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_1_bin_radiuslimited()\nDE/rand/2/bin: de_rand_2_bin()\nDE/rand/2/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_2_bin_radiuslimited()\nDirect search:\nGenerating set search:\nCompass/coordinate search: BBO_generating_set_search()\nDirect search through probabilistic descent: BBO_probabilistic_descent()\nResampling Memetic Searchers:\nResampling Memetic Search (RS): BBO_resampling_memetic_search()\nResampling Inheritance Memetic Search (RIS): BBO_resampling_inheritance_memetic_search()\nStochastic Approximation:\nSimultaneous Perturbation Stochastic Approximation (SPSA): BBO_simultaneous_perturbation_stochastic_approximation()\nRandomSearch (to compare to): BBO_random_search()","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The recommended optimizer is BBO_adaptive_de_rand_1_bin_radiuslimited()","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The currently available algorithms are listed here","category":"page"},{"location":"optimization_packages/blackboxoptim/#Example","page":"BlackBoxOptim.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The Rosenbrock function can be optimized using the BBO_adaptive_de_rand_1_bin_radiuslimited() as follows:","category":"page"},{"location":"optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"using Optimization, OptimizationBBO\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited(), maxiters = 100000,\n    maxtime = 1000.0)","category":"page"},{"location":"tutorials/remakecomposition/#Creating-polyalgorithms-by-chaining-solvers-using-remake","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"","category":"section"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"The general framework of using multiple solvers to use exploration-convergence alternations is commonly known as polyalgorithms. In the past Optimization.jl has provided a PolyOpt solver in OptimizationPolyalgorithms.jl which combined Adam from Optimisers.jl with BFGS from Optim.jl. With the large number of choices available through the interface unique combinations of solvers can be effective for specific problems.","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"In this tutorial we will demonstrate how to use the remake function to chain together solvers to create your own polyalgorithms.","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"The SciML interface provides a remake function which allows you to recreate the OptimizationProblem from a previously defined OptimizationProblem with different initial guess for the optimization variables.","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"Let's look at a 10 dimensional schwefel function in the hypercube x_i in -500 500.","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"using Optimization, Random\nusing OptimizationBBO, ReverseDiff\n\nRandom.seed!(122333)\n\nfunction f_schwefel(x, p = [418.9829])\n    result = p[1] * length(x)\n    for i in 1:length(x)\n        result -= x[i] * sin(sqrt(abs(x[i])))\n    end\n    return result\nend\n\noptf = OptimizationFunction(f_schwefel, Optimization.AutoReverseDiff(compile = true))\n\nx0 = ones(10) .* 200.0\nprob = OptimizationProblem(\n    optf, x0, [418.9829], lb = fill(-500.0, 10), ub = fill(500.0, 10))\n\n@show f_schwefel(x0)","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"Our polyalgorithm strategy will to use BlackBoxOptim's global optimizers for efficient exploration of the parameter space followed by a quasi-Newton LBFGS method to (hopefully) converge to the global optimum.","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"res1 = solve(prob, BBO_adaptive_de_rand_1_bin(), maxiters = 4000)\n\n@show res1.objective","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"This is a good start can we converge to the global optimum?","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"prob = remake(prob, u0 = res1.minimizer)\nres2 = solve(prob, Optimization.LBFGS(), maxiters = 100)\n\n@show res2.objective","category":"page"},{"location":"tutorials/remakecomposition/","page":"Creating polyalgorithms by chaining solvers using remake","title":"Creating polyalgorithms by chaining solvers using remake","text":"Yay! We have found the global optimum (this is known to be at x_i = 4209687).","category":"page"},{"location":"optimization_packages/nlopt/#NLopt.jl","page":"NLopt.jl","title":"NLopt.jl","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt is Julia package interfacing to the free/open-source NLopt library which implements many optimization methods both global and local NLopt Documentation.","category":"page"},{"location":"optimization_packages/nlopt/#Installation:-OptimizationNLopt.jl","page":"NLopt.jl","title":"Installation: OptimizationNLopt.jl","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"To use this package, install the OptimizationNLopt package:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"import Pkg;\nPkg.add(\"OptimizationNLopt\");","category":"page"},{"location":"optimization_packages/nlopt/#Methods","page":"NLopt.jl","title":"Methods","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.jl algorithms are chosen either via NLopt.Opt(:algname, nstates) where nstates is the number of states to be optimized, but preferably via NLopt.AlgorithmName() where `AlgorithmName can be one of the following:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.LD_LBFGS()\nNLopt.LN_PRAXIS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.LD_MMA()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LD_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LN_BOBYQA()\nNLopt.GN_ISRES()\nNLopt.AUGLAG()\nNLopt.AUGLAG_EQ()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()\nNLopt.GN_ESCH()\nNLopt.GN_AGS()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"See the NLopt Documentation for more details on each optimizer.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Beyond the common arguments, the following optimizer parameters can be set as kwargs:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"stopval\nxtol_rel\nxtol_abs\nconstrtol_abs\ninitial_step\npopulation\nvector_storage","category":"page"},{"location":"optimization_packages/nlopt/#Local-Optimizer","page":"NLopt.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Derivative-Free","page":"NLopt.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt derivative-free optimizers are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LN_PRAXIS()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LN_BOBYQA()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using the NLopt.LN_NELDERMEAD() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization\nusing OptimizationNLopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.LN_NELDERMEAD())","category":"page"},{"location":"optimization_packages/nlopt/#Gradient-Based","page":"NLopt.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Gradient-based optimizers are optimizers which utilize the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt gradient-based optimizers are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.LD_MMA()\nNLopt.LD_AUGLAG()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization, OptimizationNLopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.LD_LBFGS())","category":"page"},{"location":"optimization_packages/nlopt/#Global-Optimizer","page":"NLopt.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nlopt/#Without-Constraint-Equations","page":"NLopt.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.GN_ESCH()","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using NLopt.GN_DIRECT() as follows:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization, OptimizationNLopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.GN_DIRECT(), maxtime = 10.0)","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Algorithms such as NLopt.G_MLSL() or NLopt.G_MLSL_LDS() also require a local optimizer to be selected, which via the local_method argument of solve.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can be optimized using NLopt.G_MLSL_LDS() with NLopt.LN_NELDERMEAD() as the local optimizer. The local optimizer maximum iterations are set via local_maxiters:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"using Optimization, OptimizationNLopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, NLopt.G_MLSL_LDS(), local_method = NLopt.LD_LBFGS(), maxtime = 10.0,\n    local_maxiters = 10)","category":"page"},{"location":"optimization_packages/nlopt/#With-Constraint-Equations","page":"NLopt.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems with constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"note: Constraints with NLopt\n","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Equality and inequality equation support for NLopt via Optimization is not supported directly. However, you can use the MOI wrapper to use constraints with NLopt optimizers.","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GN_ISRES()\nNLopt.GN_AGS()","category":"page"},{"location":"API/solve/#Common-Solver-Options-(Solve-Keyword-Arguments)","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"","category":"section"},{"location":"API/solve/","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"solve(::OptimizationProblem,::Any)","category":"page"},{"location":"API/solve/#CommonSolve.solve-Tuple{OptimizationProblem, Any}","page":"Common Solver Options (Solve Keyword Arguments)","title":"CommonSolve.solve","text":"solve(prob::OptimizationProblem, alg::AbstractOptimizationAlgorithm, args...; kwargs...)\n\nKeyword Arguments\n\nThe arguments to solve are common across all of the optimizers. These common arguments are:\n\nmaxiters: the maximum number of iterations\nmaxtime: the maximum amount of time (typically in seconds) the optimization runs for\nabstol: absolute tolerance in changes of the objective value\nreltol: relative tolerance  in changes of the objective value\ncallback: a callback function\n\nSome optimizer algorithms have special keyword arguments documented in the solver portion of the documentation and their respective documentation. These arguments can be passed as kwargs... to solve. Similarly, the special keyword arguments for the local_method of a global optimizer are passed as a NamedTuple to local_options.\n\nOver time, we hope to cover more of these keyword arguments under the common interface.\n\nA warning will be shown if a common argument is not implemented for an optimizer.\n\nCallback Functions\n\nThe callback function callback is a function that is called after every optimizer step. Its signature is:\n\ncallback = (state, loss_val) -> false\n\nwhere state is an OptimizationState and stores information for the current iteration of the solver and loss_val is loss/objective value. For more information about the fields of the state look at the OptimizationState documentation. The callback should return a Boolean value, and the default should be false, so the optimization stops if it returns true.\n\nCallback Example\n\nHere we show an example of a callback function that plots the prediction at the current value of the optimization variables. For a visualization callback, we would need the prediction at the current parameters i.e. the solution of the ODEProblem prob.  So we call the predict function within the callback again.\n\nfunction predict(u)\n    Array(solve(prob, Tsit5(), p = u))\nend\n\nfunction loss(u, p)\n    pred = predict(u)\n    sum(abs2, batch .- pred)\nend\n\ncallback = function (state, l; doplot = false) #callback function to observe training\n    display(l)\n    # plot current prediction against data\n    if doplot\n        pred = predict(state.u)\n        pl = scatter(t, ode_data[1, :], label = \"data\")\n        scatter!(pl, t, pred[1, :], label = \"prediction\")\n        display(plot(pl))\n    end\n    return false\nend\n\nIf the chosen method is a global optimizer that employs a local optimization method, a similar set of common local optimizer arguments exists. Look at MLSL or AUGLAG from NLopt for an example. The common local optimizer arguments are:\n\nlocal_method: optimizer used for local optimization in global method\nlocal_maxiters: the maximum number of iterations\nlocal_maxtime: the maximum amount of time (in seconds) the optimization runs for\nlocal_abstol: absolute tolerance in changes of the objective value\nlocal_reltol: relative tolerance  in changes of the objective value\nlocal_options: NamedTuple of keyword arguments for local optimizer\n\n\n\n\n\n","category":"method"},{"location":"optimization_packages/metaheuristics/#Metaheuristics.jl","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics is a Julia package implementing metaheuristic algorithms for global optimization that does not require for the optimized function to be differentiable.","category":"page"},{"location":"optimization_packages/metaheuristics/#Installation:-OptimizationMetaheuristics.jl","page":"Metaheuristics.jl","title":"Installation: OptimizationMetaheuristics.jl","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"To use this package, install the OptimizationMetaheuristics package:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"import Pkg;\nPkg.add(\"OptimizationMetaheuristics\");","category":"page"},{"location":"optimization_packages/metaheuristics/#Global-Optimizer","page":"Metaheuristics.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/#Without-Constraint-Equations","page":"Metaheuristics.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"A Metaheuristics Single-Objective algorithm is called using one of the following:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Evolutionary Centers Algorithm: ECA()\nDifferential Evolution: DE() with 5 different strategies\nDE(strategy=:rand1) - default strategy\nDE(strategy=:rand2)\nDE(strategy=:best1)\nDE(strategy=:best2)\nDE(strategy=:randToBest1)\nParticle Swarm Optimization: PSO()\nArtificial Bee Colony: ABC()\nGravitational Search Algorithm: CGSA()\nSimulated Annealing: SA()\nWhale Optimization Algorithm: WOA()","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics also performs Multiobjective optimization, but this is not yet supported by Optimization.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Each optimizer sets default settings based on the optimization problem, but specific parameters can be set as shown in the original Documentation","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Additionally, Metaheuristics common settings which would be defined by Metaheuristics.Options can be simply passed as special keyword arguments to solve without the need to use the Metaheuristics.Options struct.","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Lastly, information about the optimization problem such as the true optimum is set via Metaheuristics.Information and passed as part of the optimizer struct to solve e.g., solve(prob, ECA(information=Metaheuristics.Information(f_optimum = 0.0)))","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The currently available algorithms and their parameters are listed here.","category":"page"},{"location":"optimization_packages/metaheuristics/#Notes","page":"Metaheuristics.jl","title":"Notes","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The algorithms in Metaheuristics are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/metaheuristics/#Examples","page":"Metaheuristics.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The Rosenbrock function can be optimized using the Evolutionary Centers Algorithm ECA() as follows:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"using Optimization, OptimizationMetaheuristics\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, ECA(), maxiters = 100000, maxtime = 1000.0)","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Per default Metaheuristics ignores the initial values x0 set in the OptimizationProblem. In order to for Optimization to use x0 we have to set use_initial=true:","category":"page"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"sol = solve(prob, ECA(), use_initial = true, maxiters = 100000, maxtime = 1000.0)","category":"page"},{"location":"optimization_packages/metaheuristics/#With-Constraint-Equations","page":"Metaheuristics.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"While Metaheuristics.jl supports such constraints, Optimization.jl currently does not relay these constraints.","category":"page"},{"location":"optimization_packages/prima/#PRIMA.jl","page":"PRIMA.jl","title":"PRIMA.jl","text":"","category":"section"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"PRIMA.jl is a julia wrapper for the fortran library prima which implements Powell's derivative free optimization methods.","category":"page"},{"location":"optimization_packages/prima/#Installation:-OptimizationPRIMA","page":"PRIMA.jl","title":"Installation: OptimizationPRIMA","text":"","category":"section"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"To use this package, install the OptimizationPRIMA package:","category":"page"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"import Pkg;\nPkg.add(\"OptimizationPRIMA\");","category":"page"},{"location":"optimization_packages/prima/#Local-Optimizer","page":"PRIMA.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"The five Powell's algorithms of the prima library are provided by the PRIMA.jl package:","category":"page"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"UOBYQA: (Unconstrained Optimization BY Quadratic Approximations) is for unconstrained optimization, that is Ω = ℝⁿ.","category":"page"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"NEWUOA: is also for unconstrained optimization. According to M.J.D. Powell, newuoa is superior to uobyqa.","category":"page"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"BOBYQA: (Bounded Optimization BY Quadratic Approximations) is for simple bound constrained problems, that is Ω = { x ∈ ℝⁿ | xl ≤ x ≤ xu }.","category":"page"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"LINCOA: (LINearly Constrained Optimization) is for constrained optimization problems with bound constraints, linear equality constraints, and linear inequality constraints.","category":"page"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"COBYLA: (Constrained Optimization BY Linear Approximations) is for general constrained problems with bound constraints, non-linear constraints, linear equality constraints, and linear inequality constraints.","category":"page"},{"location":"optimization_packages/prima/","page":"PRIMA.jl","title":"PRIMA.jl","text":"using Optimization, OptimizationPRIMA\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\nprob = OptimizationProblem(rosenbrock, x0, _p)\n\nsol = Optimization.solve(prob, UOBYQA(), maxiters = 1000)\n\nsol = Optimization.solve(prob, NEWUOA(), maxiters = 1000)\n\nsol = Optimization.solve(prob, BOBYQA(), maxiters = 1000)\n\nsol = Optimization.solve(prob, LINCOA(), maxiters = 1000)\n\nfunction con2_c(res, x, p)\n    res .= [x[1] + x[2], x[2] * sin(x[1]) - x[1]]\nend\noptprob = OptimizationFunction(rosenbrock, AutoForwardDiff(), cons = con2_c)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [1, -100], ucons = [1, 100])\nsol = Optimization.solve(prob, COBYLA(), maxiters = 1000)","category":"page"},{"location":"optimization_packages/optim/#optim","page":"Optim.jl","title":"Optim.jl","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim is Julia package implementing various algorithms to perform univariate and multivariate optimization.","category":"page"},{"location":"optimization_packages/optim/#Installation:-OptimizationOptimJL.jl","page":"Optim.jl","title":"Installation: OptimizationOptimJL.jl","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"To use this package, install the OptimizationOptimJL package:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"import Pkg;\nPkg.add(\"OptimizationOptimJL\");","category":"page"},{"location":"optimization_packages/optim/#Methods","page":"Optim.jl","title":"Methods","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl algorithms can be one of the following:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead()\nOptim.SimulatedAnnealing()\nOptim.ParticleSwarm()\nOptim.ConjugateGradient()\nOptim.GradientDescent()\nOptim.BFGS()\nOptim.LBFGS()\nOptim.NGMRES()\nOptim.OACCEL()\nOptim.NewtonTrustRegion()\nOptim.Newton()\nOptim.KrylovTrustRegion()\nOptim.ParticleSwarm()\nOptim.SAMIN()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Each optimizer also takes special arguments which are outlined in the sections below.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following special keyword arguments which are not covered by the common solve arguments can be used with Optim.jl optimizers:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"x_tol: Absolute tolerance in changes of the input vector x, in infinity norm. Defaults to 0.0.\ng_tol: Absolute tolerance in the gradient, in infinity norm. Defaults to 1e-8. For gradient free methods, this will control the main convergence tolerance, which is solver-specific.\nf_calls_limit: A soft upper limit on the number of objective calls. Defaults to 0 (unlimited).\ng_calls_limit: A soft upper limit on the number of gradient calls. Defaults to 0 (unlimited).\nh_calls_limit: A soft upper limit on the number of Hessian calls. Defaults to 0 (unlimited).\nallow_f_increases: Allow steps that increase the objective value. Defaults to false. Note that, when setting this to true, the last iterate will be returned as the minimizer even if the objective increased.\nstore_trace: Should a trace of the optimization algorithm's state be stored? Defaults to false.\nshow_trace: Should a trace of the optimization algorithm's state be shown on stdout? Defaults to false.\nextended_trace: Save additional information. Solver dependent. Defaults to false.\ntrace_simplex: Include the full simplex in the trace for NelderMead. Defaults to false.\nshow_every: Trace output is printed every show_everyth iteration.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"For a more extensive documentation of all the algorithms and options, please consult the Documentation","category":"page"},{"location":"optimization_packages/optim/#Local-Optimizer","page":"Optim.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Local-Constraint","page":"Optim.jl","title":"Local Constraint","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following local constraint algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.IPNewton()\nμ0 specifies the initial barrier penalty coefficient as either a number or :auto\nshow_linesearch is an option to turn on linesearch verbosity.\nDefaults:\nlinesearch::Function = Optim.backtrack_constrained_grad\nμ0::Union{Symbol,Number} = :auto\nshow_linesearch::Bool = false","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function with constraints can be optimized using the Optim.IPNewton() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\ncons = (res, x, p) -> res .= [x[1]^2 + x[2]^2]\nx0 = zeros(2)\np = [1.0, 100.0]\nprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff(); cons = cons)\nprob = Optimization.OptimizationProblem(prob, x0, p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton())","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"See also in the Optim.jl documentation the Nonlinear constrained optimization example using IPNewton.","category":"page"},{"location":"optimization_packages/optim/#Derivative-Free","page":"Optim.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the Optimization.OptimizationProblem.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following derivative-free algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead(): Nelder-Mead optimizer\nsolve(problem, NelderMead(parameters, initial_simplex))\nparameters = AdaptiveParameters() or parameters = FixedParameters()\ninitial_simplex = AffineSimplexer()\nDefaults:\nparameters = AdaptiveParameters()\ninitial_simplex = AffineSimplexer()\nOptim.SimulatedAnnealing(): Simulated Annealing\nsolve(problem, SimulatedAnnealing(neighbor, T, p))\nneighbor is a mutating function of the current and proposed x\nT is a function of the current iteration that returns a temperature\np is a function of the current temperature\nDefaults:\nneighbor = default_neighbor!\nT = default_temperature\np = kirkpatrick\nOptim.ParticleSwarm()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.NelderMead() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nprob = Optimization.OptimizationProblem(rosenbrock, x0, p)\nsol = solve(prob, Optim.NelderMead())","category":"page"},{"location":"optimization_packages/optim/#Gradient-Based","page":"Optim.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Gradient-based optimizers are optimizers which utilize the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following gradient-based algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ConjugateGradient(): Conjugate Gradient Descent\nsolve(problem, ConjugateGradient(alphaguess, linesearch, eta, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\neta determines the next step direction\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialHagerZhang()\nlinesearch = LineSearches.HagerZhang()\neta = 0.4\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.GradientDescent(): Gradient Descent (a quasi-Newton solver)\nsolve(problem, GradientDescent(alphaguess, linesearch, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialPrevious()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.BFGS(): Broyden-Fletcher-Goldfarb-Shanno algorithm\nsolve(problem, BFGS(alphaguess, linesearch, initial_invH, initial_stepnorm, manifold))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\ninitial_invH specifies an optional initial matrix\ninitial_stepnorm determines that initial_invH is an identity matrix scaled by the value of initial_stepnorm multiplied by the sup-norm of the gradient at the initial point\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\ninitial_invH = nothing\ninitial_stepnorm = nothing\nmanifold = Flat()\nOptim.LBFGS(): Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm\nm is the number of history points\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nscaleinvH0: whether to scale the initial Hessian approximation\nDefaults:\nm = 10\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nmanifold = Flat()\nscaleinvH0::Bool = true && (P isa Nothing)\nOptim.NGMRES()\nOptim.OACCEL()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.LBFGS() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(optprob, x0, p, lb = [-1.0, -1.0], ub = [0.8, 0.8])\nsol = solve(prob, Optim.LBFGS())","category":"page"},{"location":"optimization_packages/optim/#Hessian-Based-Second-Order","page":"Optim.jl","title":"Hessian-Based Second Order","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-based optimization methods are second order optimization methods which use the direct computation of the Hessian. These can converge faster, but require fast and accurate methods for calculating the Hessian in order to be appropriate.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-based algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NewtonTrustRegion(): Newton Trust Region method\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75\nOptim.Newton(): Newton's method with line search\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.Newton() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL, ModelingToolkit\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoModelingToolkit())\nprob = Optimization.OptimizationProblem(f, x0, p)\nsol = solve(prob, Optim.Newton())","category":"page"},{"location":"optimization_packages/optim/#Hessian-Free-Second-Order","page":"Optim.jl","title":"Hessian-Free Second Order","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-free methods are methods which perform second order optimization by direct computation of Hessian-vector products (Hv) without requiring the construction of the full Hessian. As such, these methods can perform well for large second order optimization problems, but can require special case when considering conditioning of the Hessian.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-free algorithms:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.KrylovTrustRegion(): A Newton-Krylov method with Trust Regions\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.KrylovTrustRegion() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(optprob, x0, p)\nsol = solve(prob, Optim.KrylovTrustRegion())","category":"page"},{"location":"optimization_packages/optim/#Global-Optimizer","page":"Optim.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/optim/#Without-Constraint-Equations","page":"Optim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim performs global optimization on problems with or without box constraints. It works both with and without lower and upper bounds set by lb and ub in the Optimization.OptimizationProblem.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ParticleSwarm(): Particle Swarm Optimization\nsolve(problem, ParticleSwarm(lower, upper, n_particles))\nlower/upper are vectors of lower/upper bounds respectively\nn_particles is the number of particles in the swarm\ndefaults to: lower = [], upper = [], n_particles = 0","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.ParticleSwarm() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, Optim.ParticleSwarm(lower = prob.lb, upper = prob.ub, n_particles = 100))","category":"page"},{"location":"optimization_packages/optim/#With-Constraint-Equations","page":"Optim.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim performs global optimization on problems with box constraints.","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.SAMIN(): Simulated Annealing with bounds\nsolve(problem, SAMIN(nt, ns, rt, neps, f_tol, x_tol, coverage_ok, verbosity))\nDefaults:\nnt = 5\nns = 5\nrt = 0.9\nneps = 5\nf_tol = 1e-12\nx_tol = 1e-6\ncoverage_ok = false\nverbosity = 0","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can be optimized using the Optim.SAMIN() as follows:","category":"page"},{"location":"optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"using Optimization, OptimizationOptimJL\nrosenbrock(x, p) = (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, Optim.SAMIN())","category":"page"},{"location":"examples/rosenbrock/#Solving-the-Rosenbrock-Problem-in-10-Ways","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"This example is a demonstration of many different solvers to demonstrate the flexibility of Optimization.jl. This is a gauntlet of many solvers to get a feel for common workflows of the package and give copy-pastable starting points.","category":"page"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"note: Note\nThis example uses many different solvers of Optimization.jl. Each solver subpackage needs to be installed separate. For example, for the details on the installation and usage of OptimizationOptimJL.jl package, see the Optim.jl page.","category":"page"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"# Define the problem to solve\nusing Optimization, ForwardDiff, Zygote\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nl1 = rosenbrock(x0, _p)\nprob = OptimizationProblem(f, x0, _p)","category":"page"},{"location":"examples/rosenbrock/#Optim.jl-Solvers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Optim.jl Solvers","text":"","category":"section"},{"location":"examples/rosenbrock/#Start-with-some-derivative-free-optimizers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Start with some derivative-free optimizers","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"using OptimizationOptimJL\nsol = solve(prob, SimulatedAnnealing())\nprob = OptimizationProblem(f, x0, _p, lb = [-1.0, -1.0], ub = [0.8, 0.8])\nsol = solve(prob, SAMIN())\n\nl1 = rosenbrock(x0, _p)\nprob = OptimizationProblem(rosenbrock, x0, _p)\nsol = solve(prob, NelderMead())","category":"page"},{"location":"examples/rosenbrock/#Now-a-gradient-based-optimizer-with-forward-mode-automatic-differentiation","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now a gradient-based optimizer with forward-mode automatic differentiation","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"optf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optf, x0, _p)\nsol = solve(prob, BFGS())","category":"page"},{"location":"examples/rosenbrock/#Now-a-second-order-optimizer-using-Hessians-generated-by-forward-mode-automatic-differentiation","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now a second order optimizer using Hessians generated by forward-mode automatic differentiation","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"sol = solve(prob, Newton())","category":"page"},{"location":"examples/rosenbrock/#Now-a-second-order-Hessian-free-optimizer","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now a second order Hessian-free optimizer","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"sol = solve(prob, Optim.KrylovTrustRegion())","category":"page"},{"location":"examples/rosenbrock/#Now-derivative-based-optimizers-with-various-constraints","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now derivative-based optimizers with various constraints","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"cons = (res, x, p) -> res .= [x[1]^2 + x[2]^2]\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff(); cons = cons)\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [Inf])\nsol = solve(prob, IPNewton()) # Note that -Inf < x[1]^2 + x[2]^2 < Inf is always true\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton()) # Again, -5.0 < x[1]^2 + x[2]^2 < 10.0\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [Inf],\n    lb = [-500.0, -500.0], ub = [50.0, 50.0])\nsol = solve(prob, IPNewton())\n\nprob = OptimizationProblem(optf, x0, _p, lcons = [0.5], ucons = [0.5],\n    lb = [-500.0, -500.0], ub = [50.0, 50.0])\nsol = solve(prob, IPNewton())\n\n# Notice now that x[1]^2 + x[2]^2 ≈ 0.5:\nres = zeros(1)\ncons(res, sol.u, _p)\nprintln(res)","category":"page"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"function con_c(res, x, p)\n    res .= [x[1]^2 + x[2]^2]\nend\n\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff(); cons = con_c)\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf], ucons = [0.25^2])\nsol = solve(prob, IPNewton()) # -Inf < cons_circ(sol.u, _p) = 0.25^2","category":"page"},{"location":"examples/rosenbrock/#Evolutionary.jl-Solvers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Evolutionary.jl Solvers","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"using OptimizationEvolutionary\nsol = solve(prob, CMAES(μ = 40, λ = 100), abstol = 1e-15) # -Inf < cons_circ(sol.u, _p) = 0.25^2","category":"page"},{"location":"examples/rosenbrock/#IPOPT-through-OptimizationMOI","page":"Solving the Rosenbrock Problem in >10 Ways","title":"IPOPT through OptimizationMOI","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"using OptimizationMOI, Ipopt\n\nfunction con2_c(res, x, p)\n    res .= [x[1]^2 + x[2]^2, x[2] * sin(x[1]) - x[1]]\nend\n\noptf = OptimizationFunction(rosenbrock, Optimization.AutoZygote(); cons = con2_c)\nprob = OptimizationProblem(optf, x0, _p, lcons = [-Inf, -Inf], ucons = [100.0, 100.0])\nsol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"examples/rosenbrock/#Now-let's-switch-over-to-OptimizationOptimisers-with-reverse-mode-AD","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now let's switch over to OptimizationOptimisers with reverse-mode AD","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"import OptimizationOptimisers\noptf = OptimizationFunction(rosenbrock, Optimization.AutoZygote())\nprob = OptimizationProblem(optf, x0, _p)\nsol = solve(prob, OptimizationOptimisers.Adam(0.05), maxiters = 1000, progress = false)","category":"page"},{"location":"examples/rosenbrock/#Try-out-CMAEvolutionStrategy.jl's-evolutionary-methods","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Try out CMAEvolutionStrategy.jl's evolutionary methods","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"using OptimizationCMAEvolutionStrategy\nsol = solve(prob, CMAEvolutionStrategyOpt())","category":"page"},{"location":"examples/rosenbrock/#Now-try-a-few-NLopt.jl-solvers-with-symbolic-differentiation-via-ModelingToolkit.jl","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Now try a few NLopt.jl solvers with symbolic differentiation via ModelingToolkit.jl","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"using OptimizationNLopt, ModelingToolkit\noptf = OptimizationFunction(rosenbrock, Optimization.AutoModelingToolkit())\nprob = OptimizationProblem(optf, x0, _p)\n\nsol = solve(prob, Opt(:LN_BOBYQA, 2))\nsol = solve(prob, Opt(:LD_LBFGS, 2))","category":"page"},{"location":"examples/rosenbrock/#Add-some-box-constraints-and-solve-with-a-few-NLopt.jl-methods","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Add some box constraints and solve with a few NLopt.jl methods","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"prob = OptimizationProblem(optf, x0, _p, lb = [-1.0, -1.0], ub = [0.8, 0.8])\nsol = solve(prob, Opt(:LD_LBFGS, 2))\nsol = solve(prob, Opt(:G_MLSL_LDS, 2), local_method = Opt(:LD_LBFGS, 2), maxiters = 10000) #a global optimizer with random starts of local optimization","category":"page"},{"location":"examples/rosenbrock/#BlackBoxOptim.jl-Solvers","page":"Solving the Rosenbrock Problem in >10 Ways","title":"BlackBoxOptim.jl Solvers","text":"","category":"section"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"using OptimizationBBO\nprob = Optimization.OptimizationProblem(rosenbrock, [0.0, 0.3], _p, lb = [-1.0, 0.2],\n    ub = [0.8, 0.43])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin()) # -1.0 ≤ x[1] ≤ 0.8, 0.2 ≤ x[2] ≤ 0.43","category":"page"},{"location":"examples/rosenbrock/","page":"Solving the Rosenbrock Problem in >10 Ways","title":"Solving the Rosenbrock Problem in >10 Ways","text":"And this is only a small subset of what Optimization.jl has to offer!","category":"page"},{"location":"optimization_packages/mathoptinterface/#MathOptInterface.jl","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"MathOptInterface is a Julia abstraction layer to interface with a variety of mathematical optimization solvers.","category":"page"},{"location":"optimization_packages/mathoptinterface/#Installation:-OptimizationMOI.jl","page":"MathOptInterface.jl","title":"Installation: OptimizationMOI.jl","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"To use this package, install the OptimizationMOI package:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"import Pkg;\nPkg.add(\"OptimizationMOI\");","category":"page"},{"location":"optimization_packages/mathoptinterface/#Details","page":"MathOptInterface.jl","title":"Details","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"As of now, the Optimization interface to MathOptInterface implements only the maxtime common keyword argument.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"OptimizationMOI supports an argument mtkize which takes a boolean (default to false) that allows automatic symbolic expression generation, this allows using any AD backend with solvers or interfaces such as AmplNLWriter that require the expression graph of the objective and constraints. This always happens automatically in the case of the AutoModelingToolkit adtype.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"An optimizer which supports the MathOptInterface API can be called directly if no optimizer options have to be defined.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"For example, using the Ipopt.jl optimizer:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using OptimizationMOI, Ipopt\nsol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"The optimizer options are handled in one of two ways. They can either be set via OptimizationMOI.MOI.OptimizerWithAttributes() or as keyword arguments to solve.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"For example, using the Ipopt.jl optimizer:","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using OptimizationMOI, Ipopt\nopt = OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n    \"option_name\" => option_value, ...)\nsol = solve(prob, opt)\n\nsol = solve(prob, Ipopt.Optimizer(); option_name = option_value, ...)","category":"page"},{"location":"optimization_packages/mathoptinterface/#Optimizers","page":"MathOptInterface.jl","title":"Optimizers","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/#Ipopt.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Ipopt.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Ipopt.Optimizer\nThe full list of optimizer options can be found in the Ipopt Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#KNITRO.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"KNITRO.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"KNITRO.Optimizer\nThe full list of optimizer options can be found in the KNITRO Documentation","category":"page"},{"location":"optimization_packages/mathoptinterface/#Juniper.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Juniper.jl (MathOptInterface)","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Juniper.Optimizer\nJuniper requires a nonlinear optimizer to be set via the nl_solver option, which must be a MathOptInterface-based optimizer. See the Juniper documentation for more detail.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using Optimization, OptimizationMOI, Juniper, Ipopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, _p)\n\nopt = OptimizationMOI.MOI.OptimizerWithAttributes(Juniper.Optimizer,\n    \"nl_solver\" => OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n        \"print_level\" => 0))\nsol = solve(prob, opt)","category":"page"},{"location":"optimization_packages/mathoptinterface/#Using-Integer-Constraints","page":"MathOptInterface.jl","title":"Using Integer Constraints","text":"","category":"section"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"The following shows how to use integer linear programming within Optimization. We will solve the classical Knapsack Problem using Juniper.jl.","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Juniper.Optimizer\nJuniper requires a nonlinear optimizer to be set via the nl_solver option, which must be a MathOptInterface-based optimizer. See the Juniper documentation for more detail.\nThe integer domain is inferred based on the bounds of the variable:\nSetting the lower bound to zero and the upper bound to one corresponds to MOI.ZeroOne() or a binary decision variable\nProviding other or no bounds corresponds to MOI.Integer()","category":"page"},{"location":"optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"v = [1.0, 2.0, 4.0, 3.0]\nw = [5.0, 4.0, 3.0, 2.0]\nW = 4.0\nu0 = [0.0, 0.0, 0.0, 1.0]\n\noptfun = OptimizationFunction((u, p) -> -v'u, cons = (res, u, p) -> res .= w'u,\n    Optimization.AutoForwardDiff())\n\noptprob = OptimizationProblem(optfun, u0; lb = zero.(u0), ub = one.(u0),\n    int = ones(Bool, length(u0)),\n    lcons = [-Inf;], ucons = [W;])\n\nnl_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n    \"print_level\" => 0)\nminlp_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Juniper.Optimizer,\n    \"nl_solver\" => nl_solver)\n\nres = solve(optprob, minlp_solver)","category":"page"},{"location":"tutorials/minibatch/#Data-Iterators-and-Minibatching","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"","category":"section"},{"location":"tutorials/minibatch/","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"It is possible to solve an optimization problem with batches using a MLUtils.DataLoader, which is passed to Optimization.solve with ncycles. All data for the batches need to be passed as a tuple of vectors.","category":"page"},{"location":"tutorials/minibatch/","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"note: Note\nThis example uses the OptimizationOptimisers.jl package. See the Optimisers.jl page for details on the installation and usage.","category":"page"},{"location":"tutorials/minibatch/","page":"Data Iterators and Minibatching","title":"Data Iterators and Minibatching","text":"\nusing Lux, Optimization, OptimizationOptimisers, OrdinaryDiffEq, SciMLSensitivity, MLUtils,\n      Random, ComponentArrays\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k * (temp - temp_m)\nend\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2) / 8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend\n\nmodel = Chain(Dense(1, 32, tanh), Dense(32, 1))\nps, st = Lux.setup(Random.default_rng(), model)\nps_ca = ComponentArray(ps)\nsmodel = StatefulLuxLayer{true}(model, nothing, st)\n\nfunction dudt_(u, p, t)\n    smodel(u, p) .* u\nend\n\nfunction callback(state, l) #callback function to observe training\n    display(l)\n    return false\nend\n\nu0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\n\nt = range(tspan[1], tspan[2], length = datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat = t))\n\nprob = ODEProblem{false}(dudt_, u0, tspan, ps_ca)\n\nfunction predict_adjoint(fullp, time_batch)\n    Array(solve(prob, Tsit5(), p = fullp, saveat = time_batch))\nend\n\nfunction loss_adjoint(fullp, data)\n    batch, time_batch = data\n    pred = predict_adjoint(fullp, time_batch)\n    sum(abs2, batch .- pred)\nend\n\nk = 10\n# Pass the data for the batches as separate vectors wrapped in a tuple\ntrain_loader = MLUtils.DataLoader((ode_data, t), batchsize = k)\n\nnumEpochs = 300\nl1 = loss_adjoint(ps_ca, train_loader.data)[1]\n\noptfun = OptimizationFunction(\n    loss_adjoint,\n    Optimization.AutoZygote())\noptprob = OptimizationProblem(optfun, ps_ca, train_loader)\nusing IterTools: ncycle\nres1 = Optimization.solve(\n    optprob, Optimisers.ADAM(0.05); callback = callback, epochs = 1000)","category":"page"},{"location":"API/optimization_stats/#optstats","page":"OptimizationStats","title":"OptimizationStats","text":"","category":"section"},{"location":"API/optimization_stats/","page":"OptimizationStats","title":"OptimizationStats","text":"SciMLBase.OptimizationStats","category":"page"},{"location":"API/optimization_stats/#SciMLBase.OptimizationStats","page":"OptimizationStats","title":"SciMLBase.OptimizationStats","text":"struct OptimizationStats\n\nStores the optimization run's statistics that is returned  in the stats field of the OptimizationResult. \n\nFields\n\niterations: number of iterations\ntime: time taken to run the solver\nfevals: number of function evaluations\ngevals: number of gradient evaluations\nhevals: number of hessian evaluations\n\nDefault values for all the field are set to 0 and hence even when  you might expect non-zero values due to unavilability of the information  from the solver it would be 0.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/nlpmodels/#NLPModels.jl","page":"NLPModels.jl","title":"NLPModels.jl","text":"","category":"section"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"NLPModels, similarly to Optimization.jl itself, provides a standardized modeling interface for representing Non-Linear Programs that facilitates using different solvers on the same problem. The Optimization.jl extension of NLPModels aims to provide a thin translation layer to make NLPModels, the main export of the package, compatible with the optimizers in the Optimization.jl ecosystem.","category":"page"},{"location":"optimization_packages/nlpmodels/#Installation:-NLPModels.jl","page":"NLPModels.jl","title":"Installation: NLPModels.jl","text":"","category":"section"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"To translate an NLPModel, install the OptimizationNLPModels package:","category":"page"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"import Pkg;\nPkg.add(\"OptimizationNLPModels\")","category":"page"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"The package NLPModels.jl itself contains no optimizers or models. Several packages provide optimization problem (CUTEst.jl, NLPModelsTest.jl) which can then be solved with any optimizer supported by Optimization.jl","category":"page"},{"location":"optimization_packages/nlpmodels/#Usage","page":"NLPModels.jl","title":"Usage","text":"","category":"section"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"For example, solving a problem defined in NLPModelsTest with Ipopt.jl. First, install the packages like so:","category":"page"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"import Pkg;\nPkg.add(\"NLPModelsTest\", \"Ipopt\")","category":"page"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"We instantiate problem 10 in the Hock–Schittkowski optimization suite available from NLPModelsTest as HS10, then translate it to an OptimizationProblem.","category":"page"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"using OptimizationNLPModels, Optimization, NLPModelsTest, Ipopt\nusing Optimization: OptimizationProblem\nnlpmodel = NLPModelsTest.HS10()\nprob = OptimizationProblem(nlpmodel, AutoForwardDiff())","category":"page"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"which can now be solved like any other OptimizationProblem:","category":"page"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"sol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"optimization_packages/nlpmodels/#API","page":"NLPModels.jl","title":"API","text":"","category":"section"},{"location":"optimization_packages/nlpmodels/","page":"NLPModels.jl","title":"NLPModels.jl","text":"Problems represented as NLPModels can be used to create OptimizationProblems and OptimizationFunction.","category":"page"},{"location":"tutorials/certification/#Using-SymbolicAnalysis.jl-for-convexity-certificates","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"","category":"section"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"In this tutorial, we will show how to use automatic convexity certification of the optimization problem using SymbolicAnalysis.jl.","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"This works with the structural_analysis keyword argument to OptimizationProblem. This tells the package to try to trace through the objective and constraints with symbolic variables (for more details on this look at the Symbolics documentation). This relies on the Disciplined Programming approach hence neccessitates the use of \"atoms\" from the SymbolicAnalysis.jl package.","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"We'll use a simple example to illustrate the convexity structure certification process.","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"using SymbolicAnalysis, Zygote, LinearAlgebra, Optimization\n\nfunction f(x, p = nothing)\n    return exp(x[1]) + x[1]^2\nend\n\noptf = OptimizationFunction(f, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optf, [0.4], structural_analysis = true)\n\nsol = solve(prob, Optimization.LBFGS(), maxiters = 1000)","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"The result can be accessed as the analysis_results field of the solution.","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"sol.cache.analysis_results.objective","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"Relatedly you can enable structural analysis in Riemannian optimization problems (supported only on the SPD manifold).","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"We'll look at the Riemannian center of mass of SPD matrices which is known to be a Geodesically Convex problem on the SPD manifold.","category":"page"},{"location":"tutorials/certification/","page":"Using SymbolicAnalysis.jl for convexity certificates","title":"Using SymbolicAnalysis.jl for convexity certificates","text":"using Optimization, OptimizationManopt, Symbolics, Manifolds, Random, LinearAlgebra,\n      SymbolicAnalysis\n\nM = SymmetricPositiveDefinite(5)\nm = 100\nσ = 0.005\nq = Matrix{Float64}(LinearAlgebra.I(5)) .+ 2.0\n\ndata2 = [exp(M, q, σ * rand(M; vector_at = q)) for i in 1:m];\n\nf(x, p = nothing) = sum(SymbolicAnalysis.distance(M, data2[i], x)^2 for i in 1:5)\noptf = OptimizationFunction(f, Optimization.AutoZygote())\nprob = OptimizationProblem(optf, data2[1]; manifold = M, structural_analysis = true)\n\nopt = OptimizationManopt.GradientDescentOptimizer()\nsol = solve(prob, opt, maxiters = 100)","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#CMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"CMAEvolutionStrategy is a Julia package implementing the Covariance Matrix Adaptation Evolution Strategy algorithm.","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The CMAEvolutionStrategy algorithm is called by CMAEvolutionStrategyOpt()","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#Installation:-OptimizationCMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"Installation: OptimizationCMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"To use this package, install the OptimizationCMAEvolutionStrategy package:","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"import Pkg;\nPkg.add(\"OptimizationCMAEvolutionStrategy\");","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#Global-Optimizer","page":"CMAEvolutionStrategy.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/#Without-Constraint-Equations","page":"CMAEvolutionStrategy.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The method in CMAEvolutionStrategy is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/#Example","page":"CMAEvolutionStrategy.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The Rosenbrock function can be optimized using the CMAEvolutionStrategyOpt() as follows:","category":"page"},{"location":"optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"using Optimization, OptimizationCMAEvolutionStrategy\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, CMAEvolutionStrategyOpt())","category":"page"},{"location":"API/optimization_solution/#Optimization-Solutions","page":"Optimization Solutions","title":"Optimization Solutions","text":"","category":"section"},{"location":"API/optimization_solution/","page":"Optimization Solutions","title":"Optimization Solutions","text":"SciMLBase.OptimizationSolution","category":"page"},{"location":"API/optimization_solution/#SciMLBase.OptimizationSolution","page":"Optimization Solutions","title":"SciMLBase.OptimizationSolution","text":"struct OptimizationSolution{T, N, uType, C<:SciMLBase.AbstractOptimizationCache, A, OV, O, ST} <: SciMLBase.AbstractOptimizationSolution{T, N}\n\nRepresentation of the solution to a non-linear optimization defined by an OptimizationProblem\n\nFields\n\nu: the representation of the optimization's solution.\ncache::AbstractOptimizationCache: the optimization cache` that was solved.\nalg: the algorithm type used by the solver.\nobjective: Objective value of the solution\nretcode: the return code from the solver. Used to determine whether the solver solved successfully or whether it exited due to an error. For more details, see the return code documentation.\noriginal: if the solver is wrapped from a external solver, e.g. Optim.jl, then this is the original return from said solver library.\nstats: statistics of the solver, such as the number of function evaluations required.\n\n\n\n\n\n","category":"type"},{"location":"API/optimization_problem/#Defining-OptimizationProblems","page":"Defining OptimizationProblems","title":"Defining OptimizationProblems","text":"","category":"section"},{"location":"API/optimization_problem/","page":"Defining OptimizationProblems","title":"Defining OptimizationProblems","text":"SciMLBase.OptimizationProblem","category":"page"},{"location":"API/optimization_problem/#SciMLBase.OptimizationProblem","page":"Defining OptimizationProblems","title":"SciMLBase.OptimizationProblem","text":"Defines an optimization problem. Documentation Page: https://docs.sciml.ai/Optimization/stable/API/optimization_problem/\n\nMathematical Specification of an Optimization Problem\n\nTo define an optimization problem, you need the objective function f which is minimized over the domain of u, the collection of optimization variables:\n\nmin_u f(up)\n\nu₀ is an initial guess for the minimizer. f should be specified as f(u,p) and u₀ should be an AbstractArray whose geometry matches the desired geometry of u. Note that we are not limited to vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher-dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nOptimizationProblem{iip}(f, u0, p = SciMLBase.NullParameters(),;\n                        lb = nothing,\n                        ub = nothing,\n                        lcons = nothing,\n                        ucons = nothing,\n                        sense = nothing,\n                        kwargs...)\n\nisinplace optionally sets whether the function is in-place or not. This is determined automatically, but not inferred. Note that for OptimizationProblem, in-place refers to the objective's derivative functions, the constraint function and its derivatives. OptimizationProblem currently only supports in-place.\n\nParameters p are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters.\n\nlb and ub are the upper and lower bounds for box constraints on the optimization variables. They should be an AbstractArray matching the geometry of u, where (lb[i],ub[i]) is the box constraint (lower and upper bounds) for u[i].\n\nlcons and ucons are the upper and lower bounds in case of inequality constraints on the optimization and if they are set to be equal then it represents an equality constraint. They should be an AbstractArray, where (lcons[i],ucons[i]) are the lower and upper bounds for cons[i].\n\nThe f in the OptimizationProblem should typically be an instance of OptimizationFunction to specify the objective function and its derivatives either by passing predefined functions for them or automatically generated using the ADType.\n\nIf f is a standard Julia function, it is automatically transformed into an OptimizationFunction with NoAD(), meaning the derivative functions are not automatically generated.\n\nAny extra keyword arguments are captured to be sent to the optimizers.\n\nFields\n\nf: the function in the problem.\nu0: the initial guess for the optimization variables.\np: Either the constant parameters or fixed data (full batch) used in the objective or a MLUtils DataLoader for minibatching with stochastic optimization solvers. Defaults to NullParameters.\nlb: the lower bounds for the optimization variables u.\nub: the upper bounds for the optimization variables u.\nint: integrality indicator for u. If int[i] == true, then u[i] is an integer variable.   Defaults to nothing, implying no integrality constraints.\nlcons: the vector of lower bounds for the constraints passed to OptimizationFunction.   Defaults to nothing, implying no lower bounds for the constraints (i.e. the constraint bound is -Inf)\nucons: the vector of upper bounds for the constraints passed to OptimizationFunction.   Defaults to nothing, implying no upper bounds for the constraints (i.e. the constraint bound is Inf)\nsense: the objective sense, can take MaxSense or MinSense from Optimization.jl.\nkwargs: the keyword arguments passed on to the solvers.\n\nInequality and Equality Constraints\n\nBoth inequality and equality constraints are defined by the f.cons function in the OptimizationFunction description of the problem structure. This f.cons is given as a function f.cons(u,p) which computes the value of the constraints at u. For example, take f.cons(u,p) = u[1] - u[2]. With these definitions, lcons and ucons define the bounds on the constraint that the solvers try to satisfy. If lcons and ucons are nothing, then there are no constraints bounds, meaning that the constraint is satisfied when -Inf < f.cons < Inf (which of course is always!). If lcons[i] = ucons[i] = 0, then the constraint is satisfied when f.cons(u,p)[i] = 0, and so this implies the equality constraint u[1] = u[2]. If lcons[i] = ucons[i] = a, then u1 - u2 = a is the equality constraint.\n\nInequality constraints are then given by making lcons[i] != ucons[i]. For example, lcons[i] = -Inf and ucons[i] = 0 would imply the inequality constraint u1 = u2 since any f.cons[i] <= 0 satisfies the constraint. Similarly, lcons[i] = -1 and ucons[i] = 1 would imply that -1 <= f.cons[i] <= 1 is required or -1 = u1 - u2 = 1.\n\nNote that these vectors must be sized to match the number of constraints, with one set of conditions for each constraint.\n\nData handling\n\nAs described above the second argument of the objective definition can take a full batch or a DataLoader object for mini-batching which is useful for stochastic optimization solvers. Thus the data either as an Array or a DataLoader object should be passed as the third argument of the OptimizationProblem constructor. For an example of how to use this data handling, see the Sophia example in the Optimization.jl documentation or the mini-batching tutorial.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/speedmapping/#SpeedMapping.jl","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"SpeedMapping accelerates the convergence of a mapping to a fixed point by the Alternating cyclic extrapolation algorithm which can also perform multivariate optimization based on the gradient function.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The SpeedMapping algorithm is called by SpeedMappingOpt()","category":"page"},{"location":"optimization_packages/speedmapping/#Installation:-OptimizationSpeedMapping.jl","page":"SpeedMapping.jl","title":"Installation: OptimizationSpeedMapping.jl","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"To use this package, install the OptimizationSpeedMapping package:","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"import Pkg;\nPkg.add(\"OptimizationSpeedMapping\");","category":"page"},{"location":"optimization_packages/speedmapping/#Global-Optimizer","page":"SpeedMapping.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/speedmapping/#Without-Constraint-Equations","page":"SpeedMapping.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The method in SpeedMapping is performing optimization on problems without constraint equations. Lower and upper constraints set by lb and ub in the OptimizationProblem are optional.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"If no AD backend is defined via OptimizationFunction the gradient is calculated via SpeedMapping's ForwardDiff AD backend.","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The Rosenbrock function can be optimized using the SpeedMappingOpt() with and without bound as follows:","category":"page"},{"location":"optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"using Optimization, OptimizationSpeedMapping\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(f, x0, p)\nsol = solve(prob, SpeedMappingOpt())\n\nprob = OptimizationProblem(f, x0, p; lb = [0.0, 0.0], ub = [1.0, 1.0])\nsol = solve(prob, SpeedMappingOpt())","category":"page"},{"location":"optimization_packages/nomad/#NOMAD.jl","page":"NOMAD.jl","title":"NOMAD.jl","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD is Julia package interfacing to NOMAD, which is a C++ implementation of the Mesh Adaptive Direct Search algorithm (MADS), designed for difficult blackbox optimization problems. These issues occur when the functions defining the objective and constraints are the result of costly computer simulations. NOMAD.jl documentation","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The NOMAD algorithm is called by NOMADOpt()","category":"page"},{"location":"optimization_packages/nomad/#Installation:-OptimizationNOMAD.jl","page":"NOMAD.jl","title":"Installation: OptimizationNOMAD.jl","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"To use this package, install the OptimizationNOMAD package:","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"import Pkg;\nPkg.add(\"OptimizationNOMAD\");","category":"page"},{"location":"optimization_packages/nomad/#Global-Optimizer","page":"NOMAD.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/nomad/#Without-Constraint-Equations","page":"NOMAD.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The method in NOMAD is performing global optimization on problems both with and without constraint equations. However, linear and nonlinear constraints defined in Optimization are currently not passed.","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD works both with and without lower and upper box-constraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/nomad/#Examples","page":"NOMAD.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The Rosenbrock function can be optimized using the NOMADOpt() with and without box-constraints as follows:","category":"page"},{"location":"optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"using Optimization, OptimizationNOMAD\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\n\nprob = OptimizationProblem(f, x0, p)\nsol = Optimization.solve(prob, NOMADOpt())\n\nprob = OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.5, 1.5])\nsol = Optimization.solve(prob, NOMADOpt())","category":"page"},{"location":"API/ad/#ad","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Construction Choice Recommendations","text":"","category":"section"},{"location":"API/ad/","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Construction Choice Recommendations","text":"The choices for the auto-AD fill-ins with quick descriptions are:","category":"page"},{"location":"API/ad/","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Construction Choice Recommendations","text":"AutoForwardDiff(): The fastest choice for small optimizations\nAutoReverseDiff(compile=false): A fast choice for large scalar optimizations\nAutoTracker(): Like ReverseDiff but GPU-compatible\nAutoZygote(): The fastest choice for non-mutating array-based (BLAS) functions\nAutoFiniteDiff(): Finite differencing, not optimal but always applicable\nAutoModelingToolkit(): The fastest choice for large scalar optimizations\nAutoEnzyme(): Highly performant AD choice for type stable and optimized code","category":"page"},{"location":"API/ad/#Automatic-Differentiation-Choice-API","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Choice API","text":"","category":"section"},{"location":"API/ad/","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Construction Choice Recommendations","text":"The following sections describe the Auto-AD choices in detail.","category":"page"},{"location":"API/ad/","page":"Automatic Differentiation Construction Choice Recommendations","title":"Automatic Differentiation Construction Choice Recommendations","text":"OptimizationBase.AutoForwardDiff\nOptimizationBase.AutoFiniteDiff\nOptimizationBase.AutoReverseDiff\nOptimizationBase.AutoZygote\nOptimizationBase.AutoTracker\nOptimizationBase.AutoModelingToolkit\nOptimizationBase.AutoEnzyme","category":"page"},{"location":"API/ad/#ADTypes.AutoForwardDiff","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoForwardDiff","text":"AutoForwardDiff{chunksize} <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoForwardDiff(); kwargs...)\n\nThis uses the ForwardDiff.jl package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most Julia functions which have loose type restrictions. However, because it's forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraints\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via ForwardDiff.\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoFiniteDiff","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoFiniteDiff","text":"AutoFiniteDiff{T1,T2,T3} <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoFiniteDiff(); kwargs...)\n\nThis uses FiniteDiff.jl. While not necessarily the most efficient, this is the only choice that doesn't require the f function to be automatically differentiable, which means it applies to any choice. However, because it's using finite differencing, one needs to be careful as this procedure introduces numerical error into the derivative estimates.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via FiniteDiff.\n\nConstructor\n\nAutoFiniteDiff(; fdtype = Val(:forward)fdjtype = fdtype, fdhtype = Val(:hcentral))\n\nfdtype: the method used for defining the gradient\nfdjtype: the method used for defining the Jacobian of constraints.\nfdhtype: the method used for defining the Hessian\n\nFor more information on the derivative type specifiers, see the FiniteDiff.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoReverseDiff","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoReverseDiff","text":"AutoReverseDiff <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoReverseDiff(); kwargs...)\n\nThis uses the ReverseDiff.jl package. AutoReverseDiff has a default argument, compile, which denotes whether the reverse pass should be compiled. compile should only be set to true if f contains no branches (if statements, while loops) otherwise it can produce incorrect derivatives!\n\nAutoReverseDiff is generally applicable to many pure Julia codes, and with compile=true it is one of the fastest options on code with heavy scalar interactions. Hessian calculations are fast by mixing ForwardDiff with ReverseDiff for forward-over-reverse. However, its performance can falter when compile=false.\n\nNot compatible with GPUs\nCompatible with Hessian-based optimization by mixing with ForwardDiff\nCompatible with Hv-based optimization by mixing with ForwardDiff\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via ReverseDiff.\n\nConstructor\n\nAutoReverseDiff(; compile = false)\n\nNote: currently, compilation is not defined/used!\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoZygote","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoZygote","text":"AutoZygote <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoZygote(); kwargs...)\n\nThis uses the Zygote.jl package. This is the staple reverse-mode AD that handles a large portion of Julia with good efficiency. Hessian construction is fast via forward-over-reverse mixing ForwardDiff.jl with Zygote.jl\n\nCompatible with GPUs\nCompatible with Hessian-based optimization via ForwardDiff\nCompatible with Hv-based optimization via ForwardDiff\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Zygote.\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoTracker","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoTracker","text":"AutoTracker <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoTracker(); kwargs...)\n\nThis uses the Tracker.jl package. Generally slower than ReverseDiff, it is generally applicable to many pure Julia codes.\n\nCompatible with GPUs\nNot compatible with Hessian-based optimization\nNot compatible with Hv-based optimization\nNot compatible with constraint functions\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Tracker.\n\n\n\n\n\n","category":"type"},{"location":"API/ad/#ADTypes.AutoModelingToolkit","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoModelingToolkit","text":"AutoModelingToolkit <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoModelingToolkit(); kwargs...)\n\nThis uses the ModelingToolkit.jl package's modelingtookitize functionality to generate the derivatives and other fields of an OptimizationFunction. This backend creates the symbolic expressions for the objective and its derivatives as well as the constraints and their derivatives. Through structural_simplify, it enforces simplifications that can reduce the number of operations needed to compute the derivatives of the constraints. This automatically generates the expression graphs that some solver interfaces through OptimizationMOI like AmplNLWriter.jl require.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraints\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not generated via ModelingToolkit.\n\nConstructor\n\nAutoModelingToolkit(false, false)\n\nobj_sparse: to indicate whether the objective hessian is sparse.\ncons_sparse: to indicate whether the constraints' jacobian and hessian are sparse.\n\n\n\n\n\n","category":"function"},{"location":"API/ad/#ADTypes.AutoEnzyme","page":"Automatic Differentiation Construction Choice Recommendations","title":"ADTypes.AutoEnzyme","text":"AutoEnzyme <: AbstractADType\n\nAn AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n\nOptimizationFunction(f, AutoEnzyme(); kwargs...)\n\nThis uses the Enzyme.jl package. Enzyme performs automatic differentiation on the LLVM IR code generated from julia. It is highly-efficient and its ability perform AD on optimized code allows Enzyme to meet or exceed the performance of state-of-the-art AD tools.\n\nCompatible with GPUs\nCompatible with Hessian-based optimization\nCompatible with Hv-based optimization\nCompatible with constraints\n\nNote that only the unspecified derivative functions are defined. For example, if a hess function is supplied to the OptimizationFunction, then the Hessian is not defined via Enzyme.\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/multistartoptimization/#MultiStartOptimization.jl","page":"MultistartOptimization.jl","title":"MultiStartOptimization.jl","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization is a Julia package implementing a global optimization multistart method which performs local optimization after choosing multiple starting points.","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization requires both a global and local method to be defined. The global multistart method chooses a set of initial starting points from where local the local method starts from.","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"Currently, only one global method (TikTak) is implemented and called by MultistartOptimization.TikTak(n) where n is the number of initial Sobol points.","category":"page"},{"location":"optimization_packages/multistartoptimization/#Installation:-OptimizationMultistartOptimization.jl","page":"MultistartOptimization.jl","title":"Installation: OptimizationMultistartOptimization.jl","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"To use this package, install the OptimizationMultistartOptimization package:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"import Pkg;\nPkg.add(\"OptimizationMultistartOptimization\");","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"note: Note\n","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"You also need to load the relevant subpackage for the local method of your choice, for example if you plan to use one of the NLopt.jl's optimizers, you'd install and load OptimizationNLopt as described in the NLopt.jl's section.","category":"page"},{"location":"optimization_packages/multistartoptimization/#Global-Optimizer","page":"MultistartOptimization.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/#Without-Constraint-Equations","page":"MultistartOptimization.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The methods in MultistartOptimization are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/multistartoptimization/#Examples","page":"MultistartOptimization.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The Rosenbrock function can be optimized using MultistartOptimization.TikTak() with 100 initial points and the local method NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"using Optimization, OptimizationMultistartOptimization, OptimizationNLopt\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), NLopt.LD_LBFGS())","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"You can use any Optimization optimizers you like. The global method of the MultistartOptimization is a positional argument and followed by the local method. For example, we can perform a multistartoptimization with LBFGS as the optimizer using either the NLopt.jl or Optim.jl implementation as follows. Moreover, this interface allows you to access and adjust all the optimizer settings as you normally would:","category":"page"},{"location":"optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"using OptimizationOptimJL\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), LBFGS(), maxiters = 5)","category":"page"},{"location":"optimization_packages/polyopt/#OptimizationPolyalgorithms.jl","page":"Polyalgorithms.jl","title":"OptimizationPolyalgorithms.jl","text":"","category":"section"},{"location":"optimization_packages/polyopt/","page":"Polyalgorithms.jl","title":"Polyalgorithms.jl","text":"OptimizationPolyalgorithms.jl is a package for collecting polyalgorithms formed by fusing popular optimization solvers of different characteristics.","category":"page"},{"location":"optimization_packages/polyopt/#Installation:-OptimizationPolyalgorithms","page":"Polyalgorithms.jl","title":"Installation: OptimizationPolyalgorithms","text":"","category":"section"},{"location":"optimization_packages/polyopt/","page":"Polyalgorithms.jl","title":"Polyalgorithms.jl","text":"To use this package, install the OptimizationPolyalgorithms package:","category":"page"},{"location":"optimization_packages/polyopt/","page":"Polyalgorithms.jl","title":"Polyalgorithms.jl","text":"import Pkg;\nPkg.add(\"OptimizationPolyalgorithms\");","category":"page"},{"location":"optimization_packages/polyopt/#Algorithms","page":"Polyalgorithms.jl","title":"Algorithms","text":"","category":"section"},{"location":"optimization_packages/polyopt/","page":"Polyalgorithms.jl","title":"Polyalgorithms.jl","text":"Right now we support the following polyalgorithms.","category":"page"},{"location":"optimization_packages/polyopt/","page":"Polyalgorithms.jl","title":"Polyalgorithms.jl","text":"PolyOpt: Runs Adam followed by BFGS for an equal number of iterations. This is useful in scientific machine learning use cases, by exploring the loss surface with the stochastic optimizer and converging to the minima faster with BFGS.","category":"page"},{"location":"optimization_packages/polyopt/","page":"Polyalgorithms.jl","title":"Polyalgorithms.jl","text":"using Optimization, OptimizationPolyalgorithms\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 100.0]\n\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optprob, x0, _p)\nsol = Optimization.solve(prob, PolyOpt(), maxiters = 1000)","category":"page"},{"location":"API/optimization_function/#optfunction","page":"OptimizationFunction","title":"OptimizationFunction","text":"","category":"section"},{"location":"API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"SciMLBase.OptimizationFunction","category":"page"},{"location":"API/optimization_function/#SciMLBase.OptimizationFunction","page":"OptimizationFunction","title":"SciMLBase.OptimizationFunction","text":"struct OptimizationFunction{iip, AD, F, G, FG, H, FGH, HV, C, CJ, CJV, CVJ, CH, HP, CJP, CHP, O, EX, CEX, SYS, LH, LHP, HCV, CJCV, CHCV, LHCV, ID} <: SciMLBase.AbstractOptimizationFunction{iip}\n\nA representation of an objective function f, defined by:\n\nmin_u f(up)\n\nand all of its related functions, such as the gradient of f, its Hessian, and more. For all cases, u is the state which in this case are the optimization variables and p are the fixed parameters or data.\n\nConstructor\n\nOptimizationFunction{iip}(f, adtype::AbstractADType = NoAD();\n                          grad = nothing, hess = nothing, hv = nothing,\n                          cons = nothing, cons_j = nothing, cons_jvp = nothing,\n                          cons_vjp = nothing, cons_h = nothing,\n                          hess_prototype = nothing,\n                          cons_jac_prototype = nothing,\n                          cons_hess_prototype = nothing,\n                          observed = __has_observed(f) ? f.observed : DEFAULT_OBSERVED_NO_TIME,\n                          lag_h = nothing,\n                          hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n                          cons_jac_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n                          cons_hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n                          lag_hess_colorvec = nothing,\n                          sys = __has_sys(f) ? f.sys : nothing)\n\nPositional Arguments\n\nf(u,p): the function to optimize. u are the optimization variables and p are fixed parameters or data used in the objective,\n\neven if no such parameters are used in the objective it should be an argument in the function. For minibatching p can be used to pass in a minibatch, take a look at the tutorial here to see how to do it. This should return a scalar, the loss value, as the return output.\n\nadtype: see the Defining Optimization Functions via AD section below.\n\nKeyword Arguments\n\ngrad(G,u,p) or G=grad(u,p): the gradient of f with respect to u.\nhess(H,u,p) or H=hess(u,p): the Hessian of f with respect to u.\nhv(Hv,u,v,p) or Hv=hv(u,v,p): the Hessian-vector product (d^2 f  du^2) v.\ncons(res,u,p) or res=cons(u,p) : the constraints function, should mutate the passed res array   with value of the ith constraint, evaluated at the current values of variables   inside the optimization routine. This takes just the function evaluations   and the equality or inequality assertion is applied by the solver based on the constraint   bounds passed as lcons and ucons to OptimizationProblem, in case of equality   constraints lcons and ucons should be passed equal values.\ncons_j(J,u,p) or J=cons_j(u,p): the Jacobian of the constraints.\ncons_jvp(Jv,u,v,p) or Jv=cons_jvp(u,v,p): the Jacobian-vector product of the constraints.\ncons_vjp(Jv,u,v,p) or Jv=cons_vjp(u,v,p): the Jacobian-vector product of the constraints.\ncons_h(H,u,p) or H=cons_h(u,p): the Hessian of the constraints, provided as  an array of Hessians with res[i] being the Hessian with respect to the ith output on cons.\nhess_prototype: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized Hessian matrix can be used as the prototype and optimization solvers will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Hessian. The default is nothing, which means a dense Hessian.\ncons_jac_prototype: a prototype matrix matching the type that matches the constraint Jacobian. The default is nothing, which means a dense constraint Jacobian.\ncons_hess_prototype: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where hess[i] is the Hessian w.r.t. the ith output. For example, if the Hessian is sparse, then hess is a Vector{SparseMatrixCSC}. The default is nothing, which means a dense constraint Hessian.\nlag_h(res,u,sigma,mu,p) or res=lag_h(u,sigma,mu,p): the Hessian of the Lagrangian, where sigma is a multiplier of the cost function and mu are the Lagrange multipliers multiplying the constraints. This can be provided instead of hess and cons_h to solvers that directly use the Hessian of the Lagrangian.\nhess_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the hess_prototype. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\ncons_jac_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_jac_prototype.\ncons_hess_colorvec: an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_hess_prototype.\n\nWhen Symbolic Problem Building with ModelingToolkit interface is used the following arguments are also relevant:\n\nobserved: an algebraic combination of optimization variables that is of interest to the user   which will be available in the solution. This can be single or multiple expressions.\nsys: field that stores the OptimizationSystem.\n\nDefining Optimization Functions via AD\n\nWhile using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an OptimizationFunction is by specifying an option from ADTypes.jl which lets the user choose the Automatic Differentiation backend to use for automatically filling in all of the extra functions. For example,\n\nOptimizationFunction(f,AutoForwardDiff())\n\nwill use ForwardDiff.jl to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.\n\nEach of the AD-based constructors are documented separately via their own dispatches below in the Automatic Differentiation Construction Choice Recommendations section.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nspecialize: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the OptimizationFunction type directly match the names of the inputs.\n\n\n\n\n\n","category":"type"},{"location":"API/modelingtoolkit/#ModelingToolkit-Integration","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"","category":"section"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Optimization.jl is heavily integrated with the ModelingToolkit.jl symbolic system for symbolic-numeric optimizations. It provides a front-end for automating the construction, parallelization, and optimization of code. Optimizers can better interface with the extra symbolic information provided by the system.","category":"page"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"There are two ways that the user interacts with ModelingToolkit.jl. One can use OptimizationFunction with AutoModelingToolkit for automatically transforming numerical codes into symbolic codes. See the OptimizationFunction documentation for more details.","category":"page"},{"location":"API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Secondly, one can generate OptimizationProblems for use in Optimization.jl from purely a symbolic front-end. This is the form users will encounter when using ModelingToolkit.jl directly, and it is also the form supplied by domain-specific languages. For more information, see the OptimizationSystem documentation.","category":"page"},{"location":"tutorials/symbolic/#Symbolic-Problem-Building-with-ModelingToolkit","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"","category":"section"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"note: Note\nThis example uses the OptimizationOptimJL.jl package. See the Optim.jl page for details on the installation and usage.","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"ModelingToolkit.jl is a comprehensive system for symbolic modeling in Julia. Allows for doing many manipulations before the solver phase, such as detecting sparsity patterns, analytically solving parts of the model to reduce the solving complexity, and more. One of the types of system types that it supports is OptimizationSystem, i.e., the symbolic counterpart to OptimizationProblem. Let's demonstrate how to use the OptimizationSystem to construct optimized OptimizationProblems.","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"First we need to start by defining our symbolic variables, this is done as follows:","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"using ModelingToolkit, Optimization, OptimizationOptimJL\n\n@variables x y\n@parameters a b","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"We can now construct the OptimizationSystem by building a symbolic expression for the loss function:","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"loss = (a - x)^2 + b * (y - x^2)^2\n@named sys = OptimizationSystem(loss, [x, y], [a, b])","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"To turn it into a problem for numerical solutions, we need to specify what our parameter values are and the initial conditions. This looks like:","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"u0 = [x => 1.0\n      y => 2.0]\np = [a => 6.0\n     b => 7.0]","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"And now we solve.","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"sys = complete(sys)\nprob = OptimizationProblem(sys, u0, p, grad = true, hess = true)\nsolve(prob, Newton())","category":"page"},{"location":"tutorials/symbolic/","page":"Symbolic Problem Building with ModelingToolkit","title":"Symbolic Problem Building with ModelingToolkit","text":"It provides many other features like auto-parallelism and sparsification too. Plus, you can hierarchically nest systems to generate huge optimization problems. Check out the ModelingToolkit.jl OptimizationSystem documentation for more information.","category":"page"},{"location":"optimization_packages/gcmaes/#GCMAES.jl","page":"GCMAES.jl","title":"GCMAES.jl","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"GCMAES is a Julia package implementing the Gradient-based Covariance Matrix Adaptation Evolutionary Strategy, which can utilize the gradient information to speed up the optimization process.","category":"page"},{"location":"optimization_packages/gcmaes/#Installation:-OptimizationGCMAES.jl","page":"GCMAES.jl","title":"Installation: OptimizationGCMAES.jl","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"To use this package, install the OptimizationGCMAES package:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"import Pkg;\nPkg.add(\"OptimizationGCMAES\");","category":"page"},{"location":"optimization_packages/gcmaes/#Global-Optimizer","page":"GCMAES.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/gcmaes/#Without-Constraint-Equations","page":"GCMAES.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The GCMAES algorithm is called by GCMAESOpt() and the initial search variance is set as a keyword argument σ0 (default: σ0 = 0.2)","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The method in GCMAES is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/gcmaes/#Example","page":"GCMAES.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The Rosenbrock function can be optimized using the GCMAESOpt() without utilizing the gradient information as follows:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"using Optimization, OptimizationGCMAES\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"We can also utilize the gradient information of the optimization problem to aid the optimization as follows:","category":"page"},{"location":"optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"f = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"optimization_packages/optimisers/#optimisers","page":"Optimisers.jl","title":"Optimisers.jl","text":"","category":"section"},{"location":"optimization_packages/optimisers/#Installation:-OptimizationOptimisers.jl","page":"Optimisers.jl","title":"Installation: OptimizationOptimisers.jl","text":"","category":"section"},{"location":"optimization_packages/optimisers/","page":"Optimisers.jl","title":"Optimisers.jl","text":"To use this package, install the OptimizationOptimisers package:","category":"page"},{"location":"optimization_packages/optimisers/","page":"Optimisers.jl","title":"Optimisers.jl","text":"import Pkg;\nPkg.add(\"OptimizationOptimisers\");","category":"page"},{"location":"optimization_packages/optimisers/","page":"Optimisers.jl","title":"Optimisers.jl","text":"In addition to the optimisation algorithms provided by the Optimisers.jl package this subpackage also provides the Sophia optimisation algorithm.","category":"page"},{"location":"optimization_packages/optimisers/#List-of-optimizers","page":"Optimisers.jl","title":"List of optimizers","text":"","category":"section"},{"location":"optimization_packages/optimisers/","page":"Optimisers.jl","title":"Optimisers.jl","text":"Optimisers.Descent: Classic gradient descent optimizer with learning rate\nsolve(problem, Descent(η))\nη is the learning rate\nDefaults:\nη = 0.1\nOptimisers.Momentum: Classic gradient descent optimizer with learning rate and momentum\nsolve(problem, Momentum(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.01\nρ = 0.9\nOptimisers.Nesterov: Gradient descent optimizer with learning rate and Nesterov momentum\nsolve(problem, Nesterov(η, ρ))\nη is the learning rate\nρ is the Nesterov momentum\nDefaults:\nη = 0.01\nρ = 0.9\nOptimisers.RMSProp: RMSProp optimizer\nsolve(problem, RMSProp(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.001\nρ = 0.9\nOptimisers.Adam: Adam optimizer\nsolve(problem, Adam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.RAdam: Rectified Adam optimizer\nsolve(problem, RAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.OAdam: Optimistic Adam optimizer\nsolve(problem, OAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.5, 0.999)\nOptimisers.AdaMax: AdaMax optimizer\nsolve(problem, AdaMax(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.ADAGrad: ADAGrad optimizer\nsolve(problem, ADAGrad(η))\nη is the learning rate\nDefaults:\nη = 0.1\nOptimisers.ADADelta: ADADelta optimizer\nsolve(problem, ADADelta(ρ))\nρ is the gradient decay factor\nDefaults:\nρ = 0.9\nOptimisers.AMSGrad: AMSGrad optimizer\nsolve(problem, AMSGrad(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.NAdam: Nesterov variant of the Adam optimizer\nsolve(problem, NAdam(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nOptimisers.AdamW: AdamW optimizer\nsolve(problem, AdamW(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndecay is the decay to weights\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\ndecay = 0\nOptimisers.ADABelief: ADABelief variant of Adam\nsolve(problem, ADABelief(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)","category":"page"},{"location":"getting_started/#Getting-Started-with-Optimization.jl","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"In this tutorial, we introduce the basics of Optimization.jl by showing how to easily mix local optimizers and global optimizers on the Rosenbrock equation. The simplest copy-pasteable code using a quasi-Newton method (LBFGS) to solve the Rosenbrock problem is the following:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"# Import the package and define the problem to optimize\nusing Optimization, Zygote\nrosenbrock(u, p) = (p[1] - u[1])^2 + p[2] * (u[2] - u[1]^2)^2\nu0 = zeros(2)\np = [1.0, 100.0]\n\noptf = OptimizationFunction(rosenbrock, AutoZygote())\nprob = OptimizationProblem(optf, u0, p)\n\nsol = solve(prob, Optimization.LBFGS())","category":"page"},{"location":"getting_started/#Import-a-different-solver-package-and-solve-the-problem","page":"Getting Started with Optimization.jl","title":"Import a different solver package and solve the problem","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"OptimizationOptimJL is a wrapper for Optim.jl and OptimizationBBO is a wrapper for BlackBoxOptim.jl.","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"First let's use the NelderMead a derivative free solver from Optim.jl:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"using OptimizationOptimJL\nsol = solve(prob, Optim.NelderMead())","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"BlackBoxOptim.jl offers derivative-free global optimization solvers that requrie the bounds to be set via lb and ub in the OptimizationProblem. Let's use the BBOadaptivederand1binradiuslimited() solver:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"using OptimizationBBO\nprob = OptimizationProblem(rosenbrock, u0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited())","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"The solution from the original solver can always be obtained via original:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"sol.original","category":"page"},{"location":"getting_started/#Defining-the-objective-function","page":"Getting Started with Optimization.jl","title":"Defining the objective function","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"Optimization.jl assumes that your objective function takes two arguments objective(x, p)","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"The optimization variables x.\nOther parameters p, such as hyper parameters of the cost function. If you have no “other parameters”, you can  safely disregard this argument. If your objective function is defined by someone else, you can create an anonymous function that just discards the extra parameters like this","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"obj = (x, p) -> objective(x) # Pass this function into OptimizationFunction","category":"page"},{"location":"getting_started/#Controlling-Gradient-Calculations-(Automatic-Differentiation)","page":"Getting Started with Optimization.jl","title":"Controlling Gradient Calculations (Automatic Differentiation)","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"Notice that both of the above methods were derivative-free methods, and thus no gradients were required to do the optimization. However, often first order optimization (i.e., using gradients) is much more efficient. Defining gradients can be done in two ways. One way is to manually provide a gradient definition in the OptimizationFunction constructor. However, the more convenient way to obtain gradients is to provide an AD backend type.","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"For example, let's now use the OptimizationOptimJL BFGS method to solve the same problem. We will import the forward-mode automatic differentiation library (using ForwardDiff) and then specify in the OptimizationFunction to automatically construct the derivative functions using ForwardDiff.jl. This looks like:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"using ForwardDiff\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optf, u0, p)\nsol = solve(prob, BFGS())","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"We can inspect the original to see the statistics on the number of steps required and gradients computed:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"sol.original","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"Sure enough, it's a lot less than the derivative-free methods!","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"However, the compute cost of forward-mode automatic differentiation scales via the number of inputs, and thus as our optimization problem grows large it slows down. To counteract this, for larger optimization problems (>100 state variables) one normally would want to use reverse-mode automatic differentiation. One common choice for reverse-mode automatic differentiation is Zygote.jl. We can demonstrate this via:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"using Zygote\noptf = OptimizationFunction(rosenbrock, Optimization.AutoZygote())\nprob = OptimizationProblem(optf, u0, p)\nsol = solve(prob, BFGS())","category":"page"},{"location":"getting_started/#Setting-Box-Constraints","page":"Getting Started with Optimization.jl","title":"Setting Box Constraints","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"In many cases, one knows the potential bounds on the solution values. In Optimization.jl, these can be supplied as the lb and ub arguments for the lower bounds and upper bounds respectively, supplying a vector of values with one per state variable. Let's now do our gradient-based optimization with box constraints by rebuilding the OptimizationProblem:","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"prob = OptimizationProblem(optf, u0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, BFGS())","category":"page"},{"location":"getting_started/","page":"Getting Started with Optimization.jl","title":"Getting Started with Optimization.jl","text":"For more information on handling constraints, in particular equality and inequality constraints, take a look at the constraints tutorial.","category":"page"},{"location":"API/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"API/FAQ/#The-Solver-Seems-to-Violate-Constraints-During-the-Optimization,-Causing-DomainErrors,-What-Can-I-Do-About-That?","page":"Frequently Asked Questions","title":"The Solver Seems to Violate Constraints During the Optimization, Causing DomainErrors, What Can I Do About That?","text":"","category":"section"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"During the optimization, optimizers use slack variables to relax the solution to the constraints. Because of this, there is no guarantee that for an arbitrary optimizer the steps will all satisfy the constraints during the optimization. In many cases, this can cause one's objective function code throw a DomainError if it is evaluated outside of its acceptable zone. For example, log(-1) gives:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"julia> log(-1)\nERROR: DomainError with -1.0:\nlog will only return a complex result if called with a complex argument. Try log(Complex(x)).","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"To handle this, one should not assume that the variables will always satisfy the constraints on each step. There are three general ways to handle this better:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Use NaNMath.jl\nProcess variables before domain-restricted calls\nUse a domain transformation","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"NaNMath.jl gives alternative implementations of standard math functions like log and sqrt in forms that do not throw DomainErrors but rather return NaNs. The optimizers will be able to handle the NaNs gracefully and recover, allowing for many of these cases to be solved without further modification. Note that this is done internally in JuMP.jl, and thus if a case is working with JuMP and not Optimization.jl  this may be the reason for the difference.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Alternatively, one can pre-process the values directly. For example, log(abs(x)) is guaranteed to work. If one does this, there are two things to make note of. One is that the solution will not be transformed, and thus the transformation should be applied on sol.u as well. For example, the solution could find an optima for x = -2, and one should manually change this to x = 2 if the abs version is used within the objective function. Note that many functions for this will introduce a discontinuity in the derivative which can affect the optimization process.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Finally and relatedly, one can write the optimization with domain transformations in order to allow the optimization to take place in the full real set. For example, instead of optimizing x in [0,Inf], one can optimize exp(x) in [0,Inf] and thus x in [-Inf, Inf] is allowed without any bounds. To do this, you would simply add the transformations to the top of the objective function:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"function my_objective(u)\n    x = exp(u[1])\n    # ... use x\nend","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"When the optimization is done, sol.u[1] will be exp(x) and thus log(sol.u[1]) will be the optimal value for x. There exist packages in the Julia ecosystem which make it easier to keep track of these domain transformations and their inverses for more general domains. See TransformVariables.jl and Bijectors.jl for high level interfaces for this.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"While this can allow an optimization with constraints to be rewritten as one without constraints, note that this can change the numerical properties of the solve which can either improve or decrease the numerical stability in a case-by-case basis. Thus while a solution, one should be aware that it could make the optimization more difficult in some cases.","category":"page"},{"location":"API/FAQ/#What-are-the-advantages-and-disadvantages-of-using-the-ModelingToolkit.jl-or-other-symbolic-interfaces-(JuMP)?","page":"Frequently Asked Questions","title":"What are the advantages and disadvantages of using the ModelingToolkit.jl or other symbolic interfaces (JuMP)?","text":"","category":"section"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"The purely numerical function interfaces of Optimization.jl has its pros and cons. The major pro of the direct Optimization.jl interface is that it can take arbitrary Julia programs. If you have an optimization defined over a program, like a Neural ODE or something that calls out to web servers, then these advanced setups rarely work within specialized symbolic environments for optimization. Direct usage of Optimization.jl is thus the preferred route for this kind of problem, and is the popular choice in the Julia ecosystem for these cases due to the simplicity of use.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"However, symbolic interfaces are smart, and they may know more than you for how to make this optimization faster. And symbolic interfaces are willing to do \"tedious work\" in order to make the optimization more efficient. For example, the ModelingToolkit integration with Optimization.jl will do many simplifications when structural_simplify is called. One of them is tearing on the constraints. To understand the tearing process, assume that we had nonlinear constraints of the form:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"    0 ~ u1 - sin(u5) * h,\n    0 ~ u2 - cos(u1),\n    0 ~ u3 - hypot(u1, u2),\n    0 ~ u4 - hypot(u2, u3),","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"If these were the constraints, one can write u1 = sin(u5) * h and substitute u1 for this value in the objective function. If this is done, then u1 does not need to be solved for, the optimization has one less state variable and one less constraint. One can continue this process all the way to a bunch of functions:","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"u1 = f1(u5)\nu2 = f2(u1)\nu3 = f3(u1, u2)\nu4 = f4(u2, u3)","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"and thus if the objective function was the function of these 5 variables and 4 constraints, ModelingToolkit.jl will transform it into system of 1 variable with no constraints, allowing unconstrained optimization on a smaller system. This will both be faster and numerically easier.","category":"page"},{"location":"API/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"JuMP.jl is another symbolic interface. While it does not include these tearing and symbolic simplification passes, it does include the ability to specialize the solution process. For example, it can treat linear optimization problems, quadratic optimization problem, convex optimization problems, etc. in specific ways that are more efficient than a general nonlinear interface. For more information on the types of special solves that are allowed with JuMP, see this page.","category":"page"},{"location":"optimization_packages/manopt/#Manopt.jl","page":"Manopt.jl","title":"Manopt.jl","text":"","category":"section"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"Manopt.jl is a package with implementations of a variety of optimization solvers on manifolds supported by Manifolds.","category":"page"},{"location":"optimization_packages/manopt/#Installation:-OptimizationManopt.jl","page":"Manopt.jl","title":"Installation: OptimizationManopt.jl","text":"","category":"section"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"To use the Optimization.jl interface to Manopt, install the OptimizationManopt package:","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"import Pkg;\nPkg.add(\"OptimizationManopt\");","category":"page"},{"location":"optimization_packages/manopt/#Methods","page":"Manopt.jl","title":"Methods","text":"","category":"section"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"The following methods are available for the OptimizationManopt package:","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"GradientDescentOptimizer: Corresponds to the gradient_descent method in Manopt.\nNelderMeadOptimizer : Corresponds to the NelderMead method in Manopt.\nConjugateGradientDescentOptimizer: Corresponds to the conjugate_gradient_descent method in Manopt.\nParticleSwarmOptimizer: Corresponds to the particle_swarm method in Manopt.\nQuasiNewtonOptimizer: Corresponds to the quasi_Newton method in Manopt.\nCMAESOptimizer: Corresponds to the cma_es method in Manopt.\nConvexBundleOptimizer: Corresponds to the convex_bundle_method method in Manopt.\nFrankWolfeOptimizer: Corresponds to the FrankWolfe method in Manopt.","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"The common kwargs maxiters, maxtime and abstol are supported by all the optimizers. Solver specific kwargs from Manopt can be passed to the solve function or OptimizationProblem.","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"note: Note\nThe OptimizationProblem has to be passed the manifold as the manifold keyword argument.","category":"page"},{"location":"optimization_packages/manopt/#Examples","page":"Manopt.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"The Rosenbrock function on the Euclidean manifold can be optimized using the GradientDescentOptimizer as follows:","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"using Optimization, OptimizationManopt, Manifolds, LinearAlgebra\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\n\nR2 = Euclidean(2)\n\nstepsize = Manopt.ArmijoLinesearch(R2)\nopt = OptimizationManopt.GradientDescentOptimizer()\n\noptf = OptimizationFunction(rosenbrock, Optimization.AutoZygote())\n\nprob = OptimizationProblem(\n    optf, x0, p; manifold = R2, stepsize = stepsize)\n\nsol = Optimization.solve(prob, opt)","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"The box-constrained Karcher mean problem on the SPD manifold with the Frank-Wolfe algorithm can be solved as follows:","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"M = SymmetricPositiveDefinite(5)\nm = 100\nσ = 0.005\nq = Matrix{Float64}(I, 5, 5) .+ 2.0\ndata2 = [exp(M, q, σ * rand(M; vector_at = q)) for i in 1:m]\n\nf(x, p = nothing) = sum(distance(M, x, data2[i])^2 for i in 1:m)\noptf = OptimizationFunction(f, Optimization.AutoZygote())\nprob = OptimizationProblem(optf, data2[1]; manifold = M, maxiters = 1000)\n\nfunction closed_form_solution!(M::SymmetricPositiveDefinite, q, L, U, p, X)\n    # extract p^1/2 and p^{-1/2}\n    (p_sqrt_inv, p_sqrt) = Manifolds.spd_sqrt_and_sqrt_inv(p)\n    # Compute D & Q\n    e2 = eigen(p_sqrt_inv * X * p_sqrt_inv) # decompose Sk  = QDQ'\n    D = Diagonal(1.0 .* (e2.values .< 0))\n    Q = e2.vectors\n\n    Uprime = Q' * p_sqrt_inv * U * p_sqrt_inv * Q\n    Lprime = Q' * p_sqrt_inv * L * p_sqrt_inv * Q\n    P = cholesky(Hermitian(Uprime - Lprime))\n    z = P.U' * D * P.U + Lprime\n    copyto!(M, q, p_sqrt * Q * z * Q' * p_sqrt)\n    return q\nend\nN = m\nU = mean(data2)\nL = inv(sum(1 / N * inv(matrix) for matrix in data2))\n\noptf = OptimizationFunction(f, Optimization.AutoZygote())\nprob = OptimizationProblem(optf, U; manifold = M, maxiters = 1000)\n\nsol = Optimization.solve(\n    prob, opt, sub_problem = (M, q, p, X) -> closed_form_solution!(M, q, L, U, p, X))","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"This example is based on the example in the Manopt and Weber and Sra'22.","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"The following example is adapted from the Rayleigh Quotient example in ManoptExamples.jl. We solve the Rayleigh quotient problem on the Sphere manifold:","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"using Optimization, OptimizationManopt\nusing Manifolds, LinearAlgebra\nusing Manopt\n\nn = 1000\nA = Symmetric(randn(n, n) / n)\nmanifold = Sphere(n - 1)\n\ncost(x, p = nothing) = -x' * A * x\negrad(G, x, p = nothing) = (G .= -2 * A * x)\n\noptf = OptimizationFunction(cost, grad = egrad)\nx0 = rand(manifold)\nprob = OptimizationProblem(optf, x0, manifold = manifold)\n\nsol = solve(prob, GradientDescentOptimizer())","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"Let's check that this indeed corresponds to the minimum eigenvalue of the matrix A.","category":"page"},{"location":"optimization_packages/manopt/","page":"Manopt.jl","title":"Manopt.jl","text":"@show eigmin(A)\n@show sol.objective","category":"page"},{"location":"API/optimization_state/#optstate","page":"OptimizationState","title":"OptimizationState","text":"","category":"section"},{"location":"API/optimization_state/","page":"OptimizationState","title":"OptimizationState","text":"Optimization.OptimizationState","category":"page"},{"location":"API/optimization_state/#Optimization.OptimizationState","page":"OptimizationState","title":"Optimization.OptimizationState","text":"struct OptimizationState{X, O, G, H, S}\n\nStores the optimization run's state at the current iteration  and is passed to the callback function as the first argument.\n\nFields\n\niter: current iteration\nu: current solution\nobjective: current objective value\ngradient: current gradient\nhessian: current hessian\noriginal: if the solver has its own state object then it is stored here\n\n\n\n\n\n","category":"type"},{"location":"optimization_packages/evolutionary/#Evolutionary.jl","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary is a Julia package implementing various evolutionary and genetic algorithm.","category":"page"},{"location":"optimization_packages/evolutionary/#Installation:-OptimizationEvolutionary.jl","page":"Evolutionary.jl","title":"Installation: OptimizationEvolutionary.jl","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"To use this package, install the OptimizationEvolutionary package:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"import Pkg;\nPkg.add(\"OptimizationEvolutionary\");","category":"page"},{"location":"optimization_packages/evolutionary/#Global-Optimizer","page":"Evolutionary.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/evolutionary/#Without-Constraint-Equations","page":"Evolutionary.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The methods in Evolutionary are performing global optimization on problems without constraint equations. These methods work both with and without lower and upper constraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"A Evolutionary algorithm is called by one of the following:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary.GA(): Genetic Algorithm optimizer\nEvolutionary.DE(): Differential Evolution optimizer\nEvolutionary.ES(): Evolution Strategy algorithm\nEvolutionary.CMAES(): Covariance Matrix Adaptation Evolution Strategy algorithm","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Algorithm-specific options are defined as kwargs. See the respective documentation for more detail.","category":"page"},{"location":"optimization_packages/evolutionary/#Example","page":"Evolutionary.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The Rosenbrock function can be optimized using the Evolutionary.CMAES() as follows:","category":"page"},{"location":"optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"using Optimization, OptimizationEvolutionary\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsol = solve(prob, Evolutionary.CMAES(μ = 40, λ = 100))","category":"page"},{"location":"optimization_packages/optimization/#Optimization.jl","page":"Optimization.jl","title":"Optimization.jl","text":"","category":"section"},{"location":"optimization_packages/optimization/","page":"Optimization.jl","title":"Optimization.jl","text":"There are some solvers that are available in the Optimization.jl package directly without the need to install any of the solver wrappers.","category":"page"},{"location":"optimization_packages/optimization/#Methods","page":"Optimization.jl","title":"Methods","text":"","category":"section"},{"location":"optimization_packages/optimization/","page":"Optimization.jl","title":"Optimization.jl","text":"LBFGS: The popular quasi-Newton method that leverages limited memory BFGS approximation of the inverse of the Hessian. Through a wrapper over the L-BFGS-B fortran routine accessed from the LBFGSB.jl package. It directly supports box-constraints.","category":"page"},{"location":"optimization_packages/optimization/","page":"Optimization.jl","title":"Optimization.jl","text":"This can also handle arbitrary non-linear constraints through a Augmented Lagrangian method with bounds constraints described in 17.4 of Numerical Optimization by Nocedal and Wright. Thus serving as a general-purpose nonlinear optimization solver available directly in Optimization.jl.","category":"page"},{"location":"optimization_packages/optimization/","page":"Optimization.jl","title":"Optimization.jl","text":"Sophia: Based on the recent paper https://arxiv.org/abs/2305.14342. It incorporates second order information in the form of the diagonal of the Hessian matrix hence avoiding the need to compute the complete hessian. It has been shown to converge faster than other first order methods such as Adam and SGD.\n+ `solve(problem, Sophia(; η, βs, ϵ, λ, k, ρ))`\n\n+ `η` is the learning rate\n+ `βs` are the decay of momentums\n+ `ϵ` is the epsilon value\n+ `λ` is the weight decay parameter\n+ `k` is the number of iterations to re-compute the diagonal of the Hessian matrix\n+ `ρ` is the momentum\n+ Defaults:\n\n    * `η = 0.001`\n    * `βs = (0.9, 0.999)`\n    * `ϵ = 1e-8`\n    * `λ = 0.1`\n    * `k = 10`\n    * `ρ = 0.04`","category":"page"},{"location":"optimization_packages/optimization/#Examples","page":"Optimization.jl","title":"Examples","text":"","category":"section"},{"location":"optimization_packages/optimization/#Unconstrained-rosenbrock-problem","page":"Optimization.jl","title":"Unconstrained rosenbrock problem","text":"","category":"section"},{"location":"optimization_packages/optimization/","page":"Optimization.jl","title":"Optimization.jl","text":"\nusing Optimization, Zygote\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\n\noptf = OptimizationFunction(rosenbrock, AutoZygote())\nprob = Optimization.OptimizationProblem(optf, x0, p)\nsol = solve(prob, Optimization.LBFGS())","category":"page"},{"location":"optimization_packages/optimization/#With-nonlinear-and-bounds-constraints","page":"Optimization.jl","title":"With nonlinear and bounds constraints","text":"","category":"section"},{"location":"optimization_packages/optimization/","page":"Optimization.jl","title":"Optimization.jl","text":"\nfunction con2_c(res, x, p)\n    res .= [x[1]^2 + x[2]^2, (x[2] * sin(x[1]) + x[1]) - 5]\nend\n\noptf = OptimizationFunction(rosenbrock, AutoZygote(), cons = con2_c)\nprob = OptimizationProblem(optf, x0, p, lcons = [1.0, -Inf],\n    ucons = [1.0, 0.0], lb = [-1.0, -1.0],\n    ub = [1.0, 1.0])\nres = solve(prob, Optimization.LBFGS(), maxiters = 100)","category":"page"},{"location":"optimization_packages/optimization/#Train-NN-with-Sophia","page":"Optimization.jl","title":"Train NN with Sophia","text":"","category":"section"},{"location":"optimization_packages/optimization/","page":"Optimization.jl","title":"Optimization.jl","text":"\nusing Optimization, Lux, Zygote, MLUtils, Statistics, Plots, Random, ComponentArrays\n\nx = rand(10000)\ny = sin.(x)\ndata = MLUtils.DataLoader((x, y), batchsize = 100)\n\n# Define the neural network\nmodel = Chain(Dense(1, 32, tanh), Dense(32, 1))\nps, st = Lux.setup(Random.default_rng(), model)\nps_ca = ComponentArray(ps)\nsmodel = StatefulLuxLayer{true}(model, nothing, st)\n\nfunction callback(state, l)\n    state.iter % 25 == 1 && @show \"Iteration: %5d, Loss: %.6e\\n\" state.iter l\n    return l < 1e-1 ## Terminate if loss is small\nend\n\nfunction loss(ps, data)\n    ypred = [smodel([data[1][i]], ps)[1] for i in eachindex(data[1])]\n    return sum(abs2, ypred .- data[2])\nend\n\noptf = OptimizationFunction(loss, AutoZygote())\nprob = OptimizationProblem(optf, ps_ca, data)\n\nres = Optimization.solve(prob, Optimization.Sophia(), callback = callback)","category":"page"},{"location":"optimization_packages/quaddirect/#QuadDIRECT.jl","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"QuadDIRECT is a Julia package implementing QuadDIRECT algorithm (inspired by DIRECT and MCS).","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The QuadDIRECT algorithm is called using QuadDirect().","category":"page"},{"location":"optimization_packages/quaddirect/#Installation:-OptimizationQuadDIRECT.jl","page":"QuadDIRECT.jl","title":"Installation: OptimizationQuadDIRECT.jl","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"To use this package, install the OptimizationQuadDIRECT package as:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"import Pkg;\nPkg.add(url = \"https://github.com/SciML/Optimization.jl\",\n    subdir = \"lib/OptimizationQuadDIRECT\");","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Also note that QuadDIRECT should (for now) be installed by doing:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"] add https://github.com/timholy/QuadDIRECT.jl.git","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Since QuadDIRECT is not a registered package in General registry, OptimizationQuadDIRECT is not registered as well, and hence it can't be installed with the traditional command.","category":"page"},{"location":"optimization_packages/quaddirect/#Global-Optimizer","page":"QuadDIRECT.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"optimization_packages/quaddirect/#Without-Constraint-Equations","page":"QuadDIRECT.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The algorithm in QuadDIRECT is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Furthermore, QuadDirect requires splits which is a list of 3-vectors with initial locations at which to evaluate the function (the values must be in strictly increasing order and lie within the specified bounds) such that solve(problem, QuadDirect(), splits).","category":"page"},{"location":"optimization_packages/quaddirect/#Example","page":"QuadDIRECT.jl","title":"Example","text":"","category":"section"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The Rosenbrock function can be optimized using the QuadDirect() as follows:","category":"page"},{"location":"optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"rosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0, -1.0], ub = [1.0, 1.0])\nsolve(prob, QuadDirect(), splits = ([-0.9, 0, 0.9], [-0.8, 0, 0.8]))","category":"page"},{"location":"tutorials/ensemble/#Multistart-optimization-with-EnsembleProblem","page":"Multistart optimization with EnsembleProblem","title":"Multistart optimization with EnsembleProblem","text":"","category":"section"},{"location":"tutorials/ensemble/","page":"Multistart optimization with EnsembleProblem","title":"Multistart optimization with EnsembleProblem","text":"The EnsembleProblem in SciML serves as a common interface for running a problem on multiple sets of initializations. In the context of optimization, this is useful for performing multistart optimization.","category":"page"},{"location":"tutorials/ensemble/","page":"Multistart optimization with EnsembleProblem","title":"Multistart optimization with EnsembleProblem","text":"This can be useful for complex, low dimensional problems. We demonstrate this, again, on the rosenbrock function.","category":"page"},{"location":"tutorials/ensemble/","page":"Multistart optimization with EnsembleProblem","title":"Multistart optimization with EnsembleProblem","text":"using Optimization, OptimizationOptimJL, Random\n\nRandom.seed!(100)\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n\noptf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(optf, x0, [1.0, 100.0])\n@time sol1 = Optimization.solve(prob, OptimizationOptimJL.BFGS(), maxiters = 5)\n\n@show sol1.objective\n\nensembleprob = Optimization.EnsembleProblem(\n    prob, [x0, x0 .+ rand(2), x0 .+ rand(2), x0 .+ rand(2)])\n\n@time sol = Optimization.solve(ensembleprob, OptimizationOptimJL.BFGS(),\n    EnsembleThreads(), trajectories = 4, maxiters = 5)\n@show findmin(i -> sol[i].objective, 1:4)[1]","category":"page"},{"location":"tutorials/ensemble/","page":"Multistart optimization with EnsembleProblem","title":"Multistart optimization with EnsembleProblem","text":"With the same number of iterations (5) we get a much lower (1/100th) objective value by using multiple initial points. The initialization strategy used here was a pretty trivial one but approaches based on Quasi-Monte Carlo sampling should be typically more effective.","category":"page"},{"location":"#Optimization.jl:-A-Unified-Optimization-Package","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Optimization.jl provides the easiest way to create an optimization problem and solve it. It enables rapid prototyping and experimentation with minimal syntax overhead by providing a uniform interface to >25 optimization libraries, hence 100+ optimization solvers encompassing almost all classes of optimization algorithms such as global, mixed-integer, non-convex, second-order local, constrained, etc. It allows you to choose an Automatic Differentiation (AD) backend by simply passing an argument to indicate the package to use and automatically generates the efficient derivatives of the objective and constraints while giving you the flexibility to switch between different AD engines as per your problem. Additionally, Optimization.jl takes care of passing problem specific information to solvers that can leverage it such as the sparsity pattern of the hessian or constraint jacobian and the expression graph.","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"It extends the common SciML interface making it very easy to use for anyone familiar with the SciML ecosystem. It is also very easy to extend to new solvers and new problem types. The package is actively maintained and new features are added regularly.","category":"page"},{"location":"#Installation","page":"Optimization.jl: A Unified Optimization Package","title":"Installation","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Assuming that you already have Julia correctly installed, it suffices to import Optimization.jl in the standard way:","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"import Pkg\nPkg.add(\"Optimization\")","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"The packages relevant to the core functionality of Optimization.jl will be imported accordingly and, in most cases, you do not have to worry about the manual installation of dependencies. Optimization.jl natively offers a LBFGS solver but for more solver choices (discussed below in Optimization Packages), you will need to add the specific wrapper packages.","category":"page"},{"location":"#Contributing","page":"Optimization.jl: A Unified Optimization Package","title":"Contributing","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"#Overview-of-the-solver-packages-in-alphabetical-order","page":"Optimization.jl: A Unified Optimization Package","title":"Overview of the solver packages in alphabetical order","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"<details>\n  <summary><strong>BlackBoxOptim</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>CMAEvolutionaryStrategy</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>Evolutionary</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n    - Non-linear Constraints\n</details>\n<details>\n  <summary><strong>GCMAES</strong></summary>\n  - <strong>Global Methods</strong>\n    - First order\n    - Box Constraints\n    - Unconstrained\n</details>\n<details>\n  <summary><strong>Manopt</strong></summary>\n  - <strong>Local Methods</strong>\n    - First order\n    - Second order\n    - Zeroth order\n    - Box Constraints\n    - Constrained 🟡\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n</details>\n<details>\n  <summary><strong>MathOptInterface</strong></summary>\n  - <strong>Local Methods</strong>\n    - First order\n    - Second order\n    - Box Constraints\n    - Constrained\n  - <strong>Global Methods</strong>\n    - First order\n    - Second order\n    - Constrained\n</details>\n<details>\n  <summary><strong>MultistartOptimization</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - First order\n    - Second order\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>Metaheuristics</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>NOMAD</strong></summary>\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n    - Constrained 🟡\n</details>\n<details>\n  <summary><strong>NLopt</strong></summary>\n  - <strong>Local Methods</strong>\n    - First order\n    - Zeroth order\n    - Second order 🟡\n    - Box Constraints\n    - Local Constrained 🟡\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - First order\n    - Unconstrained\n    - Constrained 🟡\n</details>\n<details>\n  <summary><strong>Optim</strong></summary>\n  - <strong>Local Methods</strong>\n    - Zeroth order\n    - First order\n    - Second order\n    - Box Constraints\n    - Constrained\n  - <strong>Global Methods</strong>\n    - Zeroth order\n    - Unconstrained\n    - Box Constraints\n</details>\n<details>\n  <summary><strong>PRIMA</strong></summary>\n  - <strong>Local Methods</strong>\n    - Derivative-Free: ✅\n  - **Constraints**\n    - Box Constraints: ✅\n    - Local Constrained: ✅\n</details>\n<details>\n  <summary><strong>QuadDIRECT</strong></summary>\n  - **Constraints**\n    - Box Constraints: ✅\n  - <strong>Global Methods</strong>\n    - Unconstrained: ✅\n</details>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"🟡 = supported in downstream library but not yet implemented in Optimization.jl; PR to add this functionality are welcome","category":"page"},{"location":"#Citation","page":"Optimization.jl: A Unified Optimization Package","title":"Citation","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"@software{vaibhav_kumar_dixit_2023_7738525,\n\tauthor = {Vaibhav Kumar Dixit and Christopher Rackauckas},\n\tmonth = mar,\n\tpublisher = {Zenodo},\n\ttitle = {Optimization.jl: A Unified Optimization Package},\n\tversion = {v3.12.1},\n\tdoi = {10.5281/zenodo.7738525},\n  \turl = {https://doi.org/10.5281/zenodo.7738525},\n\tyear = 2023}","category":"page"},{"location":"#Reproducibility","page":"Optimization.jl: A Unified Optimization Package","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"</details>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"</details>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"</details>","category":"page"},{"location":"","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"},{"location":"tutorials/constraints/#constraints","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"","category":"section"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Multiple optimization packages available with the MathOptInterface and Optim's IPNewton solver can handle non-linear constraints. Optimization.jl provides a simple interface to define the constraint as a Julia function and then specify the bounds for the output in OptimizationFunction to indicate if it's an equality or inequality constraint.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Let's define the rosenbrock function as our objective function and consider the below inequalities as our constraints.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"beginaligned\n\nx_1^2 + x_2^2 leq 08 \n\n-10 leq x_1 * x_2 leq 20\nendaligned","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"using Optimization, OptimizationMOI, OptimizationOptimJL, Ipopt\nusing ForwardDiff, ModelingToolkit\n\nrosenbrock(x, p) = (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p = [1.0, 1.0]","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Next, we define the sum of squares and the product of the optimization variables as our constraint functions.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"cons(res, x, p) = (res .= [x[1]^2 + x[2]^2, x[1] * x[2]])","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"We'll use the IPNewton solver from Optim to solve the problem.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"optprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff(), cons = cons)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [-Inf, -1.0], ucons = [0.8, 2.0])\nsol = solve(prob, IPNewton())","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Let's check that the constraints are satisfied, and that the objective is lower than at initial values.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"res = zeros(2)\ncons(res, sol.u, _p)\nres","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"prob.f(sol.u, _p)","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"We can also use the Ipopt library with the OptimizationMOI package.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"sol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"res = zeros(2)\ncons(res, sol.u, _p)\nres","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"prob.f(sol.u, _p)","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"We can also use ModelingToolkit as our AD backend and generate symbolic derivatives and expression graph for the objective and constraints.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Let's modify the bounds to use the function as an equality constraint. The constraint now becomes -","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"beginaligned\n\nx_1^2 + x_2^2 = 10 \n\nx_1 * x_2 = 05\nendaligned","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"optprob = OptimizationFunction(rosenbrock, Optimization.AutoModelingToolkit(), cons = cons)\nprob = OptimizationProblem(optprob, x0, _p, lcons = [1.0, 0.5], ucons = [1.0, 0.5])","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"Below, the AmplNLWriter.jl package is used with to use the Ipopt library to solve the problem.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"using AmplNLWriter, Ipopt_jll\nsol = solve(prob, AmplNLWriter.Optimizer(Ipopt_jll.amplexe))","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"The constraints evaluate to 1.0 and 0.5 respectively, as expected.","category":"page"},{"location":"tutorials/constraints/","page":"Using Equality and Inequality Constraints","title":"Using Equality and Inequality Constraints","text":"res = zeros(2)\ncons(res, sol.u, _p)\nprintln(res)","category":"page"},{"location":"tutorials/linearandinteger/#Linear-and-Integer-Optimization-Problems","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"","category":"section"},{"location":"tutorials/linearandinteger/#Example:-Short-Term-Financing","page":"Linear and Integer Optimization Problems","title":"Example: Short-Term Financing","text":"","category":"section"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"Below we show how to solve a linear optimization problem using the HiGHS optimizer. This example has been taken from the JuMP documentation.","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"Short-term cash commitments present an ongoing challenge for corporations. Let's explore an example scenario to understand this better:","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"Consider the following monthly net cash flow requirements, presented in thousands of dollars:","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"Month Jan Feb Mar Apr May Jun\nNet Cash Flow -150 -100 200 -200 50 300","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"To address these financial needs, our hypothetical company has access to various funding sources:","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"A line of credit: The company can utilize a line of credit of up to $100,000, subject to a monthly interest rate of 1%.\nCommercial paper issuance: In any of the first three months, the company has the option to issue 90-day commercial paper with a cumulative interest rate of 2% for the three-month period.\nSurplus fund investment: Any excess funds can be invested, earning a monthly interest rate of 0.3%.","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"The objective is to determine the most cost-effective utilization of these funding sources, aiming to maximize the company's available funds by the end of June.","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"To model this problem, we introduce the following decision variables:","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"u_i: The amount drawn from the line of credit in month i.\nv_i: The amount of commercial paper issued in month i.\nw_i: The surplus funds in month i.","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"We need to consider the following constraints:","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"Cash inflow must equal cash outflow for each month.\nUpper bounds must be imposed on u_i to ensure compliance with the line of credit limit.\nThe decision variables u_i, v_i, and w_i must be non-negative.","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"The ultimate objective is to maximize the company's wealth in June, denoted by the variable m.","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"using Optimization, OptimizationMOI, ModelingToolkit, HiGHS, LinearAlgebra\n\n@variables u[1:5] [bounds = (0.0, 100.0)]\n@variables v[1:3] [bounds = (0.0, Inf)]\n@variables w[1:5] [bounds = (0.0, Inf)]\n@variables m [bounds = (0.0, Inf)]\n\ncons = [u[1] + v[1] - w[1] ~ 150 # January\n        u[2] + v[2] - w[2] - 1.01u[1] + 1.003w[1] ~ 100 # February\n        u[3] + v[3] - w[3] - 1.01u[2] + 1.003w[2] ~ -200 # March\n        u[4] - w[4] - 1.02v[1] - 1.01u[3] + 1.003w[3] ~ 200 # April\n        u[5] - w[5] - 1.02v[2] - 1.01u[4] + 1.003w[4] ~ -50 # May\n        -m - 1.02v[3] - 1.01u[5] + 1.003w[5] ~ -300]\n\n@named optsys = OptimizationSystem(m, [u..., v..., w..., m], [], constraints = cons)\noptsys = complete(optsys)\noptprob = OptimizationProblem(optsys,\n    vcat(fill(0.0, 13), 300.0);\n    grad = true,\n    hess = true,\n    sense = Optimization.MaxSense)\nsol = solve(optprob, HiGHS.Optimizer())","category":"page"},{"location":"tutorials/linearandinteger/#Mixed-Integer-Nonlinear-Optimization","page":"Linear and Integer Optimization Problems","title":"Mixed Integer Nonlinear Optimization","text":"","category":"section"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"We choose an example from the Juniper.jl readme to demonstrate mixed integer nonlinear optimization with Optimization.jl. The problem can be stated as follows:","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"beginaligned\n\nv = 1020122342 \nw = 1245122221 \n\ntextmaximize quad  sum_i=1^5 v_i u_i \n\ntextsubject to quad  sum_i=1^5 w_i u_i^2 leq 45 \n\n u_i in 01 quad forall i in 12345\n\nendaligned","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"which implies a maximization problem of binary variables u_i with the objective as the dot product of v and u subject to a quadratic constraint on u.","category":"page"},{"location":"tutorials/linearandinteger/","page":"Linear and Integer Optimization Problems","title":"Linear and Integer Optimization Problems","text":"using Juniper, Ipopt\n\nv = [10, 20, 12, 23, 42]\nw = [12, 45, 12, 22, 21]\n\nobjective = (u, p) -> (v = p[1:5]; dot(v, u))\n\ncons = (res, u, p) -> (w = p[6:10]; res .= [sum(w[i] * u[i]^2 for i in 1:5)])\n\noptf = OptimizationFunction(objective, Optimization.AutoModelingToolkit(), cons = cons)\noptprob = OptimizationProblem(optf,\n    zeros(5),\n    vcat(v, w);\n    sense = Optimization.MaxSense,\n    lb = zeros(5),\n    ub = ones(5),\n    lcons = [-Inf],\n    ucons = [45.0],\n    int = fill(true, 5))\n\nnl_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Ipopt.Optimizer,\n    \"print_level\" => 0)\nminlp_solver = OptimizationMOI.MOI.OptimizerWithAttributes(Juniper.Optimizer,\n    \"nl_solver\" => nl_solver)\n\nsol = solve(optprob, minlp_solver)","category":"page"}]
}
